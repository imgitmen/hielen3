{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HIELEN Hielen (HIerarchical ELaboration ENgine) \u00e8 una suite di api REST dedicata alla rappresentazione e alla gestione delle evoluzioni temporali di fenomeni dotati di caratteristiche spaziali. Essa \u00e8 stata modellata sulle esigenze del monitoraggio strutturale, ambientale e geognostico, con l'obiettivo di astrarre lo strato fisico degli acquisitori installati sul campo e fornire un ambiente omogeneo per l'analisi dei dati relativi all'evoluzione dei fenomeni monitorati. Note generali sulle API 1. Costruzione della URL In questo documento si far\u00e0 riferimento alle specifiche api in questo modo: PROTOCOLLO /{nomeapi} intendendo con questa scrittura il protocollo da utilizzare per la chiamata (vedi punto 2) e il punto d'ingresso della specifica api che dovr\u00e0 essere utlizzato nella url , accodandolo allo hostname e all' endpoint specifici. es.: supponedo hostname = www.hostname.com endopoint = api/hielen nomeapi = features la costruzione della url sar\u00e0 la seguente www.hostname.com/api/hielen/features dove la parte www.hostname.com/api/hielen sar\u00e0 il punto d'ingresso per tutte le api della specifica installazione e dipender\u00e0 esclusivamente dalla configurazione del webserver che ospita la suite 2. Utilizzo dei potocolli standard HTTP Le API seguno le direttive REST e dunque ognuna di esse sfrutta i diversi protocolli http per svolgere azioni differenti. In generale: POST per la creazione di un nuovo elemento GET per il recupero di informazioni di uno o pi\u00f9 elementi PUT per la modifica di un elemento DELETE per l'eliminazione di un elemento ad esempio POST www.hostname.com/api/hielen/features?... potr\u00e0 essere utilizzato per creare un elemento di tipo feature. mentre GET www.hostname.com/api/hielen/features/uuid_feature servir\u00e0 a recuperare le informazioni della feature individuata da uuid_feature 3. Risposta standard delle API Dove non diversamente specificato, le api rispondono con un json in questo formato: { \"meta\": { \"response\": ..., \"message\": ..., \"data_type\": ..., }, \"data\": ... } dove: il campo meta contine informazioni relative all'esecuzione della richiesta . il sottocampo response pu\u00f2 assumere i valori error oppure ok . il sottocampo message contiene l'eventuale messaggio di errore. il sottocampo data_type contiene la marcatura dell'api richiesta (es.: \"GET /api/hielen/features\"). il campo data contiene la risposta prodotta dall'esecuzione, generalmente un json, se essa \u00e8 andata a buon fine. Struttura generale delle API Protocollo Nome API Descrizione GET /prototypes informazioni sulle tipologie di feature implementate GET /actionschemata schemi di base per agire sulle features POST /features creazione di una nuova feature GET /features recupero di informazioni sulle features PUT /features modifica di una feature DELETE /features eliminazione di una feature POST /actions azione specifica su una featrue GET /actions recupero di informazioni sulla feature eseguita PUT /actions modifica di un'azione precedentemente eseguita su una feature DELETE /actions eliminazione di un'azione precedemente eseguita su una feature GET /query interfaccia di interrogazione dei dati","title":"Home"},{"location":"#hielen","text":"Hielen (HIerarchical ELaboration ENgine) \u00e8 una suite di api REST dedicata alla rappresentazione e alla gestione delle evoluzioni temporali di fenomeni dotati di caratteristiche spaziali. Essa \u00e8 stata modellata sulle esigenze del monitoraggio strutturale, ambientale e geognostico, con l'obiettivo di astrarre lo strato fisico degli acquisitori installati sul campo e fornire un ambiente omogeneo per l'analisi dei dati relativi all'evoluzione dei fenomeni monitorati.","title":"HIELEN"},{"location":"#note-generali-sulle-api","text":"","title":"Note generali sulle API"},{"location":"#1-costruzione-della-url","text":"In questo documento si far\u00e0 riferimento alle specifiche api in questo modo: PROTOCOLLO /{nomeapi} intendendo con questa scrittura il protocollo da utilizzare per la chiamata (vedi punto 2) e il punto d'ingresso della specifica api che dovr\u00e0 essere utlizzato nella url , accodandolo allo hostname e all' endpoint specifici. es.: supponedo hostname = www.hostname.com endopoint = api/hielen nomeapi = features la costruzione della url sar\u00e0 la seguente www.hostname.com/api/hielen/features dove la parte www.hostname.com/api/hielen sar\u00e0 il punto d'ingresso per tutte le api della specifica installazione e dipender\u00e0 esclusivamente dalla configurazione del webserver che ospita la suite","title":"1. Costruzione della URL"},{"location":"#2-utilizzo-dei-potocolli-standard-http","text":"Le API seguno le direttive REST e dunque ognuna di esse sfrutta i diversi protocolli http per svolgere azioni differenti. In generale: POST per la creazione di un nuovo elemento GET per il recupero di informazioni di uno o pi\u00f9 elementi PUT per la modifica di un elemento DELETE per l'eliminazione di un elemento ad esempio POST www.hostname.com/api/hielen/features?... potr\u00e0 essere utilizzato per creare un elemento di tipo feature. mentre GET www.hostname.com/api/hielen/features/uuid_feature servir\u00e0 a recuperare le informazioni della feature individuata da uuid_feature","title":"2.  Utilizzo dei potocolli standard HTTP"},{"location":"#3-risposta-standard-delle-api","text":"Dove non diversamente specificato, le api rispondono con un json in questo formato: { \"meta\": { \"response\": ..., \"message\": ..., \"data_type\": ..., }, \"data\": ... } dove: il campo meta contine informazioni relative all'esecuzione della richiesta . il sottocampo response pu\u00f2 assumere i valori error oppure ok . il sottocampo message contiene l'eventuale messaggio di errore. il sottocampo data_type contiene la marcatura dell'api richiesta (es.: \"GET /api/hielen/features\"). il campo data contiene la risposta prodotta dall'esecuzione, generalmente un json, se essa \u00e8 andata a buon fine.","title":"3.  Risposta standard delle API"},{"location":"#struttura-generale-delle-api","text":"Protocollo Nome API Descrizione GET /prototypes informazioni sulle tipologie di feature implementate GET /actionschemata schemi di base per agire sulle features POST /features creazione di una nuova feature GET /features recupero di informazioni sulle features PUT /features modifica di una feature DELETE /features eliminazione di una feature POST /actions azione specifica su una featrue GET /actions recupero di informazioni sulla feature eseguita PUT /actions modifica di un'azione precedentemente eseguita su una feature DELETE /actions eliminazione di un'azione precedemente eseguita su una feature GET /query interfaccia di interrogazione dei dati","title":"Struttura generale delle API"},{"location":"CHANGELOG/","text":"CHANGELOG v2.0.10 10 Maggio 2021 Integrazione di ColorMap, e Config Time Operands 7 Maggio 2021 Introduzione della classe marshmallow \"ColorMap\" per la serializzazione delle informazioni custom di colorazione dei dati: tra i vari campi che possono essere ritornati da actionschemata ora ne esiste uno chiamato ColorMap . Es.: PhotoMonitoring actionschemata Come funziona ColorMap : Incontrando il campo definito come \"ColorMap\" all'interno di una risposta di actionschemata , il front-end aprir\u00e0 l'interfaccia di scelta dei colori. Il risultato dell'interazione dovr\u00e0 essere sintetizzato in un json da fronire come parametro all'azione corrispondente. Il json dovr\u00e0 essere nella forma di un array di lunghezza variabile di COPPIE (valore,colore): [ [ valore, colore ], [ valore, colore, ] ... ] dove: valore \u00e8 un numero di qualsiasi genere con punto decimale colore \u00e8 una stringa di colore hex esempio: [ [ -0.25, '#FFFF00' ], [ -0.125, '#00FF00' ], [ 0, '#0000FF' ], [ 0.5, '#FF00FF' ], [ 1, '#AEBD00' ], ] Un array del genere verrebbe inteso in questo modo: [-inf,-0.25) : [-0.25,-0.125) : --> [-0.125,0.0) : --> [0.0,0.5) : --> [0.5,1.0) : --> [1.0,inf) : L'informazione sulla colormap pu\u00f2 essere associata ad ongi singola serire dati e pu\u00f2 essere fornita in front-end su richiesta: allo scopo L'API features \u00e8 stata modificata in modo da fornire la colormap insieme con i parametri delle features specificando l'opzione info=parameters,... esempio (vedi chiamata) : { ..., \"parameters\": [ { \"series\": \"2b6c9efb4e83f64e757ce862f8b6c2e0\", \"param\": \"East-West_Displacement\", \"unit\": \"mm\", \"cmap\": [ [ -0.25, \"#FFFF00\", 0 ], [ -0.125, \"#00FF00\", 10 ], [ 0, \"#0000FF\", 20 ], [ 0.5, \"#FF00FF\", 60 ], [ 1, \"#AEBD00\", 100 ] ] }, ... ], ... } dove ogni cmap \u00e8 un array ordinato di triplette utile alla creazione della relativa colorbar. Ogni tipletta fornisce questa infromazione: cmap[x][0] : etichetta del valore, possibilmente da piazzare sulla colorbar alla giusta posizione. cmap[x][1] : colore in esadecimale. cmap[x][2] : posizione dell'ancora del gradiente per il rispettivo colore, nonch\u00e9 per l'eventuale etichetta del valore. La posizione \u00e8 espressa in percentuale sull'intera colorbar. 30 Aprile 2021 Gestione generalizzata degli operandi \"config time\" per i parametri: Ora la classe Source espone dei metodi per dare la possibilit\u00e0 alle sotto classi di definire operandi di elaborazione custom. v2.0.9 22 Aprile 2021 implementata l'interrogazione tramite GeoJson Correzione di molti bugs Aggancio della query dati v2.0.8 2 Aprile 2021 implementato il modello di cache per la gestione dei dati prodotti debug delle nuove funzionalit\u00e0 31 Marzo 2021 inserita la nuova entit\u00e0 db \"feaures_info\" riviste le api /features/ /actions/ /query/ rivisto il codice di hielen2.source hielen2.query introdotto il modulo hielen2.mapmanager per la gestione della generazione dei mapfile rivisto il codice di hielen2.ext.source_photomonitoring 29 Marzo 2021 inserito il concetto di \"info\" nelle richieste a feature: Con questo parametro si riescono a centralizzare le chiamate che si focalizzano sulle feature e si separano le informazioni di secondo livello ad esse legate. In questo modo la risposta di default risulta piuttosto leggera ma diventa uno strumento potente e versatile specificando esplicitamente l'estrazione di iformazioni accessorie. Attualmente il parametro \"info\" accetta un array in cui pu\u00f2 essere richiesta l'estrazione di queste info: geometry : il GeoJson della geometria della feature capabilities : le possibili interrogazioni effetuabili sulla feature \u00e8 un array che contiene uno o pi\u00f9 di questi valori: \"data\",\"map\",\"cloud\". la feature risponder\u00e0 a chiamate del tipo /query/{capability} . Nel caso l'array fosse vuoto la feature non risponderebbe ad alcuna interrogazione. parameters : l'elenco dei parametri associati alla feature come riportati dal'API GET /parametes/ . Quest'ultima API diviene inutile e sar\u00e0 eliminata in futuro timeline : la timeline dei dati associati ai parametri della feature. Utile per lo pi\u00f9 per le query map e cloud data : informazioni specifiche di per la capability \"data\" map : informazioni specifiche per la capability \"map\" (il formato \u00e8 esattamente quello del nodo \"map\" del backbone di geoframe) cloud : informazioni specifiche per la capability \"cloud\" 23 Marzo 2021 unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per distingure tra [\"data\",\"map\",\"cloud\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/map GET /query/cloud/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\" 19 Marzo 2021 Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard) v2.0.7 15 Marzo 2021 API: GET /maps/ per la generazione delle mappe. 11 Marzo 2011 Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache) 3 Marzo 2021 API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati 25 Febbraio 2021 Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis. 18 Febbraio 2021 Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe 12 Febbraio 2021 Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds v2.0.6 7 Febbraio 2021 Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter 27 Gennaio 2021 Inserita la validazione dei campi delle action 25 Gennaio 2021 Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati. 22 Gennaio 2021 Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0 20 Gennaio 2021 modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False ) 18 Gennaio 2021 Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] } 15 Gennaio 2021 modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False) 13 Gennaio 2021 rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla 10 Gennaio 2021 Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\" 30 Dicembre 2020 sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug) 22 Dicembre 20202 Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli. 20 Dicembre 2020 Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr . 15 Dicembre 2020 Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata. v2.0.5 9 Dicembre 2020 Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } } 7 Dicembre 2020 Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare. 2 Dicembre 2020 Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere) 24 Novembre 2020 Implementate dummy /actions/{feature}/ e /actions/{feature}/{form} 23 Novembre 2020 Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale 19 Novembre 2020 riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ . 17 Novembre 2020 Implementata dummy POST /actions/{feature}/{form} : v2.0.4 16 Novembre 2020 per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature 13 Novembre 2020 rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature. 12 Novembre 2020 ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] } v2.0.3 11 Novembre 2020 Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata. 9 Novembre 2020 Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink 6 Novembre 2020 L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db) v2.0.2 4 Novembre 2020 Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"CHANGELOG"},{"location":"CHANGELOG/#changelog","text":"","title":"CHANGELOG"},{"location":"CHANGELOG/#v2010","text":"","title":"v2.0.10"},{"location":"CHANGELOG/#10-maggio-2021","text":"Integrazione di ColorMap, e Config Time Operands","title":"10 Maggio 2021"},{"location":"CHANGELOG/#7-maggio-2021","text":"Introduzione della classe marshmallow \"ColorMap\" per la serializzazione delle informazioni custom di colorazione dei dati: tra i vari campi che possono essere ritornati da actionschemata ora ne esiste uno chiamato ColorMap . Es.: PhotoMonitoring actionschemata Come funziona ColorMap : Incontrando il campo definito come \"ColorMap\" all'interno di una risposta di actionschemata , il front-end aprir\u00e0 l'interfaccia di scelta dei colori. Il risultato dell'interazione dovr\u00e0 essere sintetizzato in un json da fronire come parametro all'azione corrispondente. Il json dovr\u00e0 essere nella forma di un array di lunghezza variabile di COPPIE (valore,colore): [ [ valore, colore ], [ valore, colore, ] ... ] dove: valore \u00e8 un numero di qualsiasi genere con punto decimale colore \u00e8 una stringa di colore hex esempio: [ [ -0.25, '#FFFF00' ], [ -0.125, '#00FF00' ], [ 0, '#0000FF' ], [ 0.5, '#FF00FF' ], [ 1, '#AEBD00' ], ] Un array del genere verrebbe inteso in questo modo: [-inf,-0.25) : [-0.25,-0.125) : --> [-0.125,0.0) : --> [0.0,0.5) : --> [0.5,1.0) : --> [1.0,inf) : L'informazione sulla colormap pu\u00f2 essere associata ad ongi singola serire dati e pu\u00f2 essere fornita in front-end su richiesta: allo scopo L'API features \u00e8 stata modificata in modo da fornire la colormap insieme con i parametri delle features specificando l'opzione info=parameters,... esempio (vedi chiamata) : { ..., \"parameters\": [ { \"series\": \"2b6c9efb4e83f64e757ce862f8b6c2e0\", \"param\": \"East-West_Displacement\", \"unit\": \"mm\", \"cmap\": [ [ -0.25, \"#FFFF00\", 0 ], [ -0.125, \"#00FF00\", 10 ], [ 0, \"#0000FF\", 20 ], [ 0.5, \"#FF00FF\", 60 ], [ 1, \"#AEBD00\", 100 ] ] }, ... ], ... } dove ogni cmap \u00e8 un array ordinato di triplette utile alla creazione della relativa colorbar. Ogni tipletta fornisce questa infromazione: cmap[x][0] : etichetta del valore, possibilmente da piazzare sulla colorbar alla giusta posizione. cmap[x][1] : colore in esadecimale. cmap[x][2] : posizione dell'ancora del gradiente per il rispettivo colore, nonch\u00e9 per l'eventuale etichetta del valore. La posizione \u00e8 espressa in percentuale sull'intera colorbar.","title":"7 Maggio 2021"},{"location":"CHANGELOG/#30-aprile-2021","text":"Gestione generalizzata degli operandi \"config time\" per i parametri: Ora la classe Source espone dei metodi per dare la possibilit\u00e0 alle sotto classi di definire operandi di elaborazione custom.","title":"30 Aprile 2021"},{"location":"CHANGELOG/#v209","text":"","title":"v2.0.9"},{"location":"CHANGELOG/#22-aprile-2021","text":"implementata l'interrogazione tramite GeoJson Correzione di molti bugs Aggancio della query dati","title":"22 Aprile 2021"},{"location":"CHANGELOG/#v208","text":"","title":"v2.0.8"},{"location":"CHANGELOG/#2-aprile-2021","text":"implementato il modello di cache per la gestione dei dati prodotti debug delle nuove funzionalit\u00e0","title":"2 Aprile 2021"},{"location":"CHANGELOG/#31-marzo-2021","text":"inserita la nuova entit\u00e0 db \"feaures_info\" riviste le api /features/ /actions/ /query/ rivisto il codice di hielen2.source hielen2.query introdotto il modulo hielen2.mapmanager per la gestione della generazione dei mapfile rivisto il codice di hielen2.ext.source_photomonitoring","title":"31 Marzo 2021"},{"location":"CHANGELOG/#29-marzo-2021","text":"inserito il concetto di \"info\" nelle richieste a feature: Con questo parametro si riescono a centralizzare le chiamate che si focalizzano sulle feature e si separano le informazioni di secondo livello ad esse legate. In questo modo la risposta di default risulta piuttosto leggera ma diventa uno strumento potente e versatile specificando esplicitamente l'estrazione di iformazioni accessorie. Attualmente il parametro \"info\" accetta un array in cui pu\u00f2 essere richiesta l'estrazione di queste info: geometry : il GeoJson della geometria della feature capabilities : le possibili interrogazioni effetuabili sulla feature \u00e8 un array che contiene uno o pi\u00f9 di questi valori: \"data\",\"map\",\"cloud\". la feature risponder\u00e0 a chiamate del tipo /query/{capability} . Nel caso l'array fosse vuoto la feature non risponderebbe ad alcuna interrogazione. parameters : l'elenco dei parametri associati alla feature come riportati dal'API GET /parametes/ . Quest'ultima API diviene inutile e sar\u00e0 eliminata in futuro timeline : la timeline dei dati associati ai parametri della feature. Utile per lo pi\u00f9 per le query map e cloud data : informazioni specifiche di per la capability \"data\" map : informazioni specifiche per la capability \"map\" (il formato \u00e8 esattamente quello del nodo \"map\" del backbone di geoframe) cloud : informazioni specifiche per la capability \"cloud\"","title":"29 Marzo 2021"},{"location":"CHANGELOG/#23-marzo-2021","text":"unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per distingure tra [\"data\",\"map\",\"cloud\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/map GET /query/cloud/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\"","title":"23 Marzo 2021"},{"location":"CHANGELOG/#19-marzo-2021","text":"Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard)","title":"19 Marzo 2021"},{"location":"CHANGELOG/#v207","text":"","title":"v2.0.7"},{"location":"CHANGELOG/#15-marzo-2021","text":"API: GET /maps/ per la generazione delle mappe.","title":"15 Marzo 2021"},{"location":"CHANGELOG/#11-marzo-2011","text":"Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache)","title":"11 Marzo 2011"},{"location":"CHANGELOG/#3-marzo-2021","text":"API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati","title":"3 Marzo 2021"},{"location":"CHANGELOG/#25-febbraio-2021","text":"Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis.","title":"25 Febbraio 2021"},{"location":"CHANGELOG/#18-febbraio-2021","text":"Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe","title":"18 Febbraio 2021"},{"location":"CHANGELOG/#12-febbraio-2021","text":"Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds","title":"12 Febbraio 2021"},{"location":"CHANGELOG/#v206","text":"","title":"v2.0.6"},{"location":"CHANGELOG/#7-febbraio-2021","text":"Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter","title":"7 Febbraio 2021"},{"location":"CHANGELOG/#27-gennaio-2021","text":"Inserita la validazione dei campi delle action","title":"27 Gennaio 2021"},{"location":"CHANGELOG/#25-gennaio-2021","text":"Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati.","title":"25 Gennaio 2021"},{"location":"CHANGELOG/#22-gennaio-2021","text":"Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0","title":"22 Gennaio 2021"},{"location":"CHANGELOG/#20-gennaio-2021","text":"modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False )","title":"20 Gennaio 2021"},{"location":"CHANGELOG/#18-gennaio-2021","text":"Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] }","title":"18 Gennaio 2021"},{"location":"CHANGELOG/#15-gennaio-2021","text":"modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False)","title":"15 Gennaio 2021"},{"location":"CHANGELOG/#13-gennaio-2021","text":"rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla","title":"13 Gennaio 2021"},{"location":"CHANGELOG/#10-gennaio-2021","text":"Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\"","title":"10 Gennaio 2021"},{"location":"CHANGELOG/#30-dicembre-2020","text":"sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug)","title":"30 Dicembre 2020"},{"location":"CHANGELOG/#22-dicembre-20202","text":"Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli.","title":"22 Dicembre 20202"},{"location":"CHANGELOG/#20-dicembre-2020","text":"Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr .","title":"20 Dicembre 2020"},{"location":"CHANGELOG/#15-dicembre-2020","text":"Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata.","title":"15 Dicembre 2020"},{"location":"CHANGELOG/#v205","text":"","title":"v2.0.5"},{"location":"CHANGELOG/#9-dicembre-2020","text":"Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } }","title":"9 Dicembre 2020"},{"location":"CHANGELOG/#7-dicembre-2020","text":"Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare.","title":"7 Dicembre 2020"},{"location":"CHANGELOG/#2-dicembre-2020","text":"Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere)","title":"2 Dicembre 2020"},{"location":"CHANGELOG/#24-novembre-2020","text":"Implementate dummy /actions/{feature}/ e /actions/{feature}/{form}","title":"24 Novembre 2020"},{"location":"CHANGELOG/#23-novembre-2020","text":"Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale","title":"23 Novembre 2020"},{"location":"CHANGELOG/#19-novembre-2020","text":"riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ .","title":"19 Novembre 2020"},{"location":"CHANGELOG/#17-novembre-2020","text":"Implementata dummy POST /actions/{feature}/{form} :","title":"17 Novembre 2020"},{"location":"CHANGELOG/#v204","text":"","title":"v2.0.4"},{"location":"CHANGELOG/#16-novembre-2020","text":"per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature","title":"16 Novembre 2020"},{"location":"CHANGELOG/#13-novembre-2020","text":"rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature.","title":"13 Novembre 2020"},{"location":"CHANGELOG/#12-novembre-2020","text":"ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] }","title":"12 Novembre 2020"},{"location":"CHANGELOG/#v203","text":"","title":"v2.0.3"},{"location":"CHANGELOG/#11-novembre-2020","text":"Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata.","title":"11 Novembre 2020"},{"location":"CHANGELOG/#9-novembre-2020","text":"Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink","title":"9 Novembre 2020"},{"location":"CHANGELOG/#6-novembre-2020","text":"L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db)","title":"6 Novembre 2020"},{"location":"CHANGELOG/#v202","text":"","title":"v2.0.2"},{"location":"CHANGELOG/#4-novembre-2020","text":"Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"4 Novembre 2020"},{"location":"MODELLO/","text":"Con Priorit\u00e0 Structure gestore della configurazione di base: modulo utilizzo stato datalink.py livello di astrazione db, interfacce json completo, integrabile utils.py strumenti accessori completo, integrabile source.py astrazione dei moduli di gestione completo, integrabile modello db: tabella descrizione stato features_proto prototipi features info sui moduli completa features persistenza delle features completa actions persistenza delle azioni completa series_proto prototipi serie dati per configurazione dinamica implementazione series peristenza info di elaborazione serie dati avanzato series_cache persistenza serie dati elaborate runtime json utilizzato per mockup modello api: Configurazione Abstraction layer: Produzione Interrogazione First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column Configurazione hielen2.ext.PhotoMonitoring (netCDF) definizione array dimensionali X,Y: 1- creo gli array di dimensione adeguata, 2- applico la matrice di trasformazione affine, 3- applico la proiezione da crs in input a EPSG:3857 salvare file in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) salvare il primo tile a risoluzione adeguata: filecache/{uid}/{map}/base.png salvataggio (stoccaggio) dell'immagine di base in filecache/{uid} (eventualmente compressa) Feed hielen2.ext.PhotoMonitoring analisi dei file csv in ingresso (NS, EW, Correlation se esiste) aggirnamento di filecache/{uid}/multidim.nc Configurazione hielen2.ext.TinSAR analisi della formato della master cloud salvataggio (stoccaggio) della nuvola di base recupero info geografiche in caso non esistano info di proiezione geografica si considera spazio cartesiano con coordinate con adeguate alla nuvola base (da verificare) configurare file netCDF e salvarlo in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) configurare cartella di cache per potree filecache/{uid}/{cloud} (potree) Feed hielen2.ext.TinSAR Analisi file in ingresso aggiornamento filecache/{uid}/multidim.nc aggiornamento filecache/{uid}/{cloud} v2.0.6 Interfacce delle Informazioni con risposta mockup. Intento: agganciare lavoro Daniele GET /bases GET /bases/{feature} GET /timelines GET /timelines/{feature} GET /data/ estensione del modello di datamap per accettare GeoGeson v2.0.7 Rivistazione del modulo PhotMonitoring come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione Photmonitoring alle interfacce v2.0.8 Implementazione del modulo TinSar come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione TinSar alle interfacce v2.0.9 Implementazione delle chiamate di mappa GET /maps/[/z/x/y] GET /maps/{feature}/[z/x/y] v2.0.10 Implementazione chiamate cloud GET /cloud/{feature} Senza priorit\u00e0 Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. ~~ Moduli HielenSource : Definire in backend le form come Marshmallow.Schema in modo da condividere la struttura tra moduli e api~~ Obiettivo: assegnare una timestamp ad ogni informazione: le properties degli ogetti dovranno essere delle serie dati. Concetto di informazione minima. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"MODELLO"},{"location":"MODELLO/#con-priorita","text":"","title":"Con Priorit\u00e0"},{"location":"MODELLO/#structure","text":"gestore della configurazione di base: modulo utilizzo stato datalink.py livello di astrazione db, interfacce json completo, integrabile utils.py strumenti accessori completo, integrabile source.py astrazione dei moduli di gestione completo, integrabile modello db: tabella descrizione stato features_proto prototipi features info sui moduli completa features persistenza delle features completa actions persistenza delle azioni completa series_proto prototipi serie dati per configurazione dinamica implementazione series peristenza info di elaborazione serie dati avanzato series_cache persistenza serie dati elaborate runtime json utilizzato per mockup modello api:","title":"Structure"},{"location":"MODELLO/#configurazione","text":"Abstraction layer:","title":"Configurazione"},{"location":"MODELLO/#produzione","text":"","title":"Produzione"},{"location":"MODELLO/#interrogazione","text":"First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column","title":"Interrogazione"},{"location":"MODELLO/#configurazione-hielen2extphotomonitoring-netcdf","text":"definizione array dimensionali X,Y: 1- creo gli array di dimensione adeguata, 2- applico la matrice di trasformazione affine, 3- applico la proiezione da crs in input a EPSG:3857 salvare file in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) salvare il primo tile a risoluzione adeguata: filecache/{uid}/{map}/base.png salvataggio (stoccaggio) dell'immagine di base in filecache/{uid} (eventualmente compressa)","title":"Configurazione hielen2.ext.PhotoMonitoring (netCDF)"},{"location":"MODELLO/#feed-hielen2extphotomonitoring","text":"analisi dei file csv in ingresso (NS, EW, Correlation se esiste) aggirnamento di filecache/{uid}/multidim.nc","title":"Feed hielen2.ext.PhotoMonitoring"},{"location":"MODELLO/#configurazione-hielen2exttinsar","text":"analisi della formato della master cloud salvataggio (stoccaggio) della nuvola di base recupero info geografiche in caso non esistano info di proiezione geografica si considera spazio cartesiano con coordinate con adeguate alla nuvola base (da verificare) configurare file netCDF e salvarlo in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) configurare cartella di cache per potree filecache/{uid}/{cloud} (potree)","title":"Configurazione hielen2.ext.TinSAR"},{"location":"MODELLO/#feed-hielen2exttinsar","text":"Analisi file in ingresso aggiornamento filecache/{uid}/multidim.nc aggiornamento filecache/{uid}/{cloud}","title":"Feed hielen2.ext.TinSAR"},{"location":"MODELLO/#v206-interfacce-delle-informazioni-con-risposta-mockup-intento-agganciare-lavoro-daniele","text":"GET /bases GET /bases/{feature} GET /timelines GET /timelines/{feature} GET /data/ estensione del modello di datamap per accettare GeoGeson","title":"v2.0.6 Interfacce delle Informazioni con risposta mockup. Intento: agganciare lavoro Daniele"},{"location":"MODELLO/#v207-rivistazione-del-modulo-photmonitoring-come-source-intento-agganciare-le-serie-dati-prodotte-dallelaborazione-photmonitoring-alle-interfacce","text":"","title":"v2.0.7 Rivistazione del modulo PhotMonitoring come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione Photmonitoring alle interfacce"},{"location":"MODELLO/#v208-implementazione-del-modulo-tinsar-come-source-intento-agganciare-le-serie-dati-prodotte-dallelaborazione-tinsar-alle-interfacce","text":"","title":"v2.0.8 Implementazione del modulo TinSar come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione TinSar alle interfacce"},{"location":"MODELLO/#v209-implementazione-delle-chiamate-di-mappa","text":"GET /maps/[/z/x/y] GET /maps/{feature}/[z/x/y]","title":"v2.0.9 Implementazione delle chiamate di mappa"},{"location":"MODELLO/#v2010-implementazione-chiamate-cloud","text":"GET /cloud/{feature}","title":"v2.0.10 Implementazione chiamate cloud"},{"location":"MODELLO/#senza-priorita","text":"Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. ~~ Moduli HielenSource : Definire in backend le form come Marshmallow.Schema in modo da condividere la struttura tra moduli e api~~ Obiettivo: assegnare una timestamp ad ogni informazione: le properties degli ogetti dovranno essere delle serie dati. Concetto di informazione minima. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"Senza priorit\u00e0"},{"location":"TODO/","text":"MODULO PRICIPALE: Documentazione API online Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx alta bassa completo Start-up sistema di documentazione xx alta bassa alta Sistemazione documentazione online.","title":"TODO"},{"location":"TODO/#modulo-pricipale","text":"","title":"MODULO PRICIPALE:"},{"location":"TODO/#documentazione-api-online","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx alta bassa completo Start-up sistema di documentazione xx alta bassa alta Sistemazione documentazione online.","title":"Documentazione API online"},{"location":"docs/API%20Reference/actions/","text":"Actions /actions/{feature} GET params : feature : Basic text / string value actions : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione /actions/{feature}/{action} GET params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Recupero dello stato corrente per una specifica azione di una specifica feature** DELETE params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Eliminazione di una determinata azione di una specifica feature** POST params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. PUT params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default.","title":"Actions"},{"location":"docs/API%20Reference/actions/#actions","text":"","title":"Actions"},{"location":"docs/API%20Reference/actions/#actionsfeature","text":"","title":"/actions/{feature}"},{"location":"docs/API%20Reference/actions/#get","text":"params : feature : Basic text / string value actions : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione","title":"GET"},{"location":"docs/API%20Reference/actions/#actionsfeatureaction","text":"","title":"/actions/{feature}/{action}"},{"location":"docs/API%20Reference/actions/#get_1","text":"params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Recupero dello stato corrente per una specifica azione di una specifica feature**","title":"GET"},{"location":"docs/API%20Reference/actions/#delete","text":"params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Eliminazione di una determinata azione di una specifica feature**","title":"DELETE"},{"location":"docs/API%20Reference/actions/#post","text":"params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default.","title":"POST"},{"location":"docs/API%20Reference/actions/#put","text":"params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default.","title":"PUT"},{"location":"docs/API%20Reference/actionschemata/","text":"Actionschemata /actionschemata/ GET params : prototypes : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, /actionschemata/{prototype} GET params : prototype : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni di uno specifico prototipo /actionschemata/{prototype}/{action} GET params : prototype : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo","title":"ActionSchemata"},{"location":"docs/API%20Reference/actionschemata/#actionschemata","text":"","title":"Actionschemata"},{"location":"docs/API%20Reference/actionschemata/#actionschemata_1","text":"","title":"/actionschemata/"},{"location":"docs/API%20Reference/actionschemata/#get","text":"params : prototypes : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... },","title":"GET"},{"location":"docs/API%20Reference/actionschemata/#actionschemataprototype","text":"","title":"/actionschemata/{prototype}"},{"location":"docs/API%20Reference/actionschemata/#get_1","text":"params : prototype : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni di uno specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/actionschemata/#actionschemataprototypeaction","text":"","title":"/actionschemata/{prototype}/{action}"},{"location":"docs/API%20Reference/actionschemata/#get_2","text":"params : prototype : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/features/","text":"Features /features/ POST params : prototype : Basic text / string value properties : JSON Schema { context : str|bytes, style : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, location : str|bytes, label : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Creazione delle Features. Ogni feature deve avere il suo il suo prototipo prototype ed in fase di creazione viene creato il campo uid . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. GET params : uids : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri /features/{uid} GET params : uid : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di recupero informazioni della specifica feature** PUT params : uid : Basic text / string value properties : JSON Schema { context : str|bytes, style : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, location : str|bytes, label : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. DELETE params : uid : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente.","title":"Features"},{"location":"docs/API%20Reference/features/#features","text":"","title":"Features"},{"location":"docs/API%20Reference/features/#features_1","text":"","title":"/features/"},{"location":"docs/API%20Reference/features/#post","text":"params : prototype : Basic text / string value properties : JSON Schema { context : str|bytes, style : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, location : str|bytes, label : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Creazione delle Features. Ogni feature deve avere il suo il suo prototipo prototype ed in fase di creazione viene creato il campo uid . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente.","title":"POST"},{"location":"docs/API%20Reference/features/#get","text":"params : uids : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri","title":"GET"},{"location":"docs/API%20Reference/features/#featuresuid","text":"","title":"/features/{uid}"},{"location":"docs/API%20Reference/features/#get_1","text":"params : uid : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di recupero informazioni della specifica feature**","title":"GET"},{"location":"docs/API%20Reference/features/#put","text":"params : uid : Basic text / string value properties : JSON Schema { context : str|bytes, style : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, location : str|bytes, label : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente.","title":"PUT"},{"location":"docs/API%20Reference/features/#delete","text":"params : uid : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente.","title":"DELETE"},{"location":"docs/API%20Reference/parameters/","text":"Parameters /parameters/ GET params : uids : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : ** Ricerca dei parametri associati alle features ** . __nota__ : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo : { \"<fetUID>\" :[ { \"series\" : \"<series_UID>\" , \"param\" : \"<param_name>\" , \"um\" : \"<mearurement_unit>\" } ... ] ... } Possibili risposte : - _404 Not Found_ : Nel caso in cui nessun parametro risponda ai criteri /parameters/{uid} GET params : uid : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dei Parametri della specifica Feature** /parameters/{uid}/{param} GET params : uid : Basic text / string value param : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**","title":"Parameters"},{"location":"docs/API%20Reference/parameters/#parameters","text":"","title":"Parameters"},{"location":"docs/API%20Reference/parameters/#parameters_1","text":"","title":"/parameters/"},{"location":"docs/API%20Reference/parameters/#get","text":"params : uids : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : ** Ricerca dei parametri associati alle features ** . __nota__ : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo : { \"<fetUID>\" :[ { \"series\" : \"<series_UID>\" , \"param\" : \"<param_name>\" , \"um\" : \"<mearurement_unit>\" } ... ] ... } Possibili risposte : - _404 Not Found_ : Nel caso in cui nessun parametro risponda ai criteri","title":"GET"},{"location":"docs/API%20Reference/parameters/#parametersuid","text":"","title":"/parameters/{uid}"},{"location":"docs/API%20Reference/parameters/#get_1","text":"params : uid : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dei Parametri della specifica Feature**","title":"GET"},{"location":"docs/API%20Reference/parameters/#parametersuidparam","text":"","title":"/parameters/{uid}/{param}"},{"location":"docs/API%20Reference/parameters/#get_2","text":"params : uid : Basic text / string value param : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**","title":"GET"},{"location":"docs/API%20Reference/prototypes/","text":"Prototypes /prototypes/ GET result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Ritorna l'elenco dei prototipi disponibili come array json /prototypes/{prototype} GET params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Ritorna informazioni dettagliate sullo specifico prototipo","title":"Prototypes"},{"location":"docs/API%20Reference/prototypes/#prototypes","text":"","title":"Prototypes"},{"location":"docs/API%20Reference/prototypes/#prototypes_1","text":"","title":"/prototypes/"},{"location":"docs/API%20Reference/prototypes/#get","text":"result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Ritorna l'elenco dei prototipi disponibili come array json","title":"GET"},{"location":"docs/API%20Reference/prototypes/#prototypesprototype","text":"","title":"/prototypes/{prototype}"},{"location":"docs/API%20Reference/prototypes/#get_1","text":"params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Ritorna informazioni dettagliate sullo specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/query/","text":"Query /query/{capability} GET params : capability : Basic text / string value datamap : JSON Schema [{ geometry : [], times : , refresh : bool, series : [str|bytes], timeref : str|bytes}] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /query/{capability}/{feature}/ GET params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value geometry : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /query/{capability}/{feature}/{par} GET params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value geometry : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"Query"},{"location":"docs/API%20Reference/query/#query","text":"","title":"Query"},{"location":"docs/API%20Reference/query/#querycapability","text":"","title":"/query/{capability}"},{"location":"docs/API%20Reference/query/#get","text":"params : capability : Basic text / string value datamap : JSON Schema [{ geometry : [], times : , refresh : bool, series : [str|bytes], timeref : str|bytes}] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/query/#querycapabilityfeature","text":"","title":"/query/{capability}/{feature}/"},{"location":"docs/API%20Reference/query/#get_1","text":"params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value geometry : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/query/#querycapabilityfeaturepar","text":"","title":"/query/{capability}/{feature}/{par}"},{"location":"docs/API%20Reference/query/#get_2","text":"params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value geometry : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"reference/hielen3/","text":"Module hielen3 View Source # coding=utf-8 __name__ = 'hielen3' __version__ = '3.0.0' __author__ = 'Alessandro Modesti' __email__ = 'it@img-srl.com' __description__ = 'Multidimention Hierarichical Elaboration Engine' __license__ = 'MIT' __uri__ = '' import warnings import json from .datalink import dbinit # , cacheinit def _initconf ( confile , envfile ): env = None with open ( envfile ) as ef : env = json . load ( ef ) with open ( confile ) as cf : confstr = cf . read () for k , w in env . items (): placeholder = \"{{\" + k + \"}}\" confstr = confstr . replace ( placeholder , w ) return json . loads ( confstr ) conf = _initconf ( \"./conf/hielen.json\" , \"./conf/env.json\" ) db = dbinit ( conf ) def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"conf\" , \"db\" ] Sub-modules hielen3.api hielen3.cloudmanager hielen3.datalink hielen3.ext hielen3.mapmanager hielen3.query hielen3.source hielen3.sourcestorage hielen3.tools hielen3.utils Variables conf db","title":"Index"},{"location":"reference/hielen3/#module-hielen3","text":"View Source # coding=utf-8 __name__ = 'hielen3' __version__ = '3.0.0' __author__ = 'Alessandro Modesti' __email__ = 'it@img-srl.com' __description__ = 'Multidimention Hierarichical Elaboration Engine' __license__ = 'MIT' __uri__ = '' import warnings import json from .datalink import dbinit # , cacheinit def _initconf ( confile , envfile ): env = None with open ( envfile ) as ef : env = json . load ( ef ) with open ( confile ) as cf : confstr = cf . read () for k , w in env . items (): placeholder = \"{{\" + k + \"}}\" confstr = confstr . replace ( placeholder , w ) return json . loads ( confstr ) conf = _initconf ( \"./conf/hielen.json\" , \"./conf/env.json\" ) db = dbinit ( conf ) def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"conf\" , \"db\" ]","title":"Module hielen3"},{"location":"reference/hielen3/#sub-modules","text":"hielen3.api hielen3.cloudmanager hielen3.datalink hielen3.ext hielen3.mapmanager hielen3.query hielen3.source hielen3.sourcestorage hielen3.tools hielen3.utils","title":"Sub-modules"},{"location":"reference/hielen3/#variables","text":"conf db","title":"Variables"},{"location":"reference/hielen3/cloudmanager/","text":"Module hielen3.cloudmanager View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 #!/usr/bin/env python # coding=utf-8 from hielen3 import conf from abc import ABC , abstractmethod from pathlib import Path , os from hielen3.sourcestorage import SourceStorage from glob import glob import re import json class Cloudmanager ( ABC ): def __init__ ( self , feature , basepath , * args , ** kwargs ): basepath = Path ( feature ) / basepath self . cloudbaseurl = Path ( conf [ 'cloudurl' ] ) / 'viewer.html' self . cloudcache = SourceStorage ( conf [ 'syscache' ][ 'cloudcache' ], str ( basepath )) self . basepath = basepath \"\"\" @property def mapfile(self): return self.mapcache / \"mapfile.map\" @property def mapurl(self): return self.mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams(): pass \"\"\" @abstractmethod def geturl (): pass class PotreeCM ( Cloudmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \" { conf [ 'potreeconverter' ] } { lazfile } -o { targhetpath } \" ) def geturl ( self , subpath , cloud = None ): if cloud is None : cloud = \"*\" sub = self . cloudcache / subpath clouds = [] clswitch = {} #basepath = self.cloudcache / 'base' / 'metadata.json' #metto la base se esiste #if basepath.exists(): # clouds['base']=str(basepath).replace(conf['syscache']['cloudcache'],\"resources\") on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ) . exists (): relpath = str ( p / 'metadata.json' ) . replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 on = 1 #cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ) . exists (): relpath = str ( p / 'metadata.json' ) . replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 url = str ( self . cloudbaseurl ) + \"?clouds=\" + json . dumps ( clouds ) return url Variables conf Classes Cloudmanager class Cloudmanager ( feature , basepath , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Cloudmanager ( ABC ) : def __init__ ( self , feature , basepath , * args , ** kwargs ) : basepath = Path ( feature ) / basepath self . cloudbaseurl = Path ( conf [ 'cloudurl' ] ) / 'viewer.html' self . cloudcache = SourceStorage ( conf [ 'syscache' ][ 'cloudcache' ] , str ( basepath )) self . basepath = basepath \"\"\" @property def mapfile(self): return self.mapcache / \" mapfile . map \" @property def mapurl(self): return self.mapbaseurl / \" mapfile . map \" @abstractmethod def setMFparams(): pass \"\"\" @abstractmethod def geturl () : pass Ancestors (in MRO) abc.ABC Descendants hielen3.cloudmanager.PotreeCM Methods geturl def geturl ( ) View Source @abstractmethod def geturl () : pass PotreeCM class PotreeCM ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class PotreeCM ( Cloudmanager ): def __init__ ( self ,* args ,** kwargs ): super (). __init__ (* args ,** kwargs ) def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \"{conf['potreeconverter']} {lazfile} -o {targhetpath}\" ) def geturl ( self , subpath , cloud = None ): if cloud is None: cloud = \"*\" sub = self . cloudcache / subpath clouds =[] clswitch ={} #basepath = self.cloudcache / 'base' / 'metadata.json' #metto la base se esiste #if basepath.exists(): # clouds['base']=str(basepath).replace(conf['syscache']['cloudcache'],\"resources\") on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 on = 1 #cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 url = str ( self . cloudbaseurl )+ \"?clouds=\" + json . dumps ( clouds ) return url Ancestors (in MRO) hielen3.cloudmanager.Cloudmanager abc.ABC Methods geturl def geturl ( self , subpath , cloud = None ) View Source def geturl ( self , subpath , cloud = None ): if cloud is None : cloud = \"*\" sub = self . cloudcache / subpath clouds = [] clswitch = {} # basepath = self . cloudcache / 'base' / 'metadata.json' # metto la base se esiste # if basepath . exists (): # clouds [ 'base' ] = str ( basepath ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ( { \"name\" : p . name , \"path\" : relpath , \"switch\" : on } ) on = 0 on = 1 # cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ( { \"name\" : p . name , \"path\" : relpath , \"switch\" : on } ) on = 0 url = str ( self . cloudbaseurl ) + \"?clouds=\" + json . dumps ( clouds ) return url makePotree def makePotree ( self , lazfile , cloudname , subpath = None ) View Source def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \"{conf['potreeconverter']} {lazfile} -o {targhetpath}\" )","title":"Cloudmanager"},{"location":"reference/hielen3/cloudmanager/#module-hielen3cloudmanager","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 #!/usr/bin/env python # coding=utf-8 from hielen3 import conf from abc import ABC , abstractmethod from pathlib import Path , os from hielen3.sourcestorage import SourceStorage from glob import glob import re import json class Cloudmanager ( ABC ): def __init__ ( self , feature , basepath , * args , ** kwargs ): basepath = Path ( feature ) / basepath self . cloudbaseurl = Path ( conf [ 'cloudurl' ] ) / 'viewer.html' self . cloudcache = SourceStorage ( conf [ 'syscache' ][ 'cloudcache' ], str ( basepath )) self . basepath = basepath \"\"\" @property def mapfile(self): return self.mapcache / \"mapfile.map\" @property def mapurl(self): return self.mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams(): pass \"\"\" @abstractmethod def geturl (): pass class PotreeCM ( Cloudmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \" { conf [ 'potreeconverter' ] } { lazfile } -o { targhetpath } \" ) def geturl ( self , subpath , cloud = None ): if cloud is None : cloud = \"*\" sub = self . cloudcache / subpath clouds = [] clswitch = {} #basepath = self.cloudcache / 'base' / 'metadata.json' #metto la base se esiste #if basepath.exists(): # clouds['base']=str(basepath).replace(conf['syscache']['cloudcache'],\"resources\") on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ) . exists (): relpath = str ( p / 'metadata.json' ) . replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 on = 1 #cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ) . exists (): relpath = str ( p / 'metadata.json' ) . replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 url = str ( self . cloudbaseurl ) + \"?clouds=\" + json . dumps ( clouds ) return url","title":"Module hielen3.cloudmanager"},{"location":"reference/hielen3/cloudmanager/#variables","text":"conf","title":"Variables"},{"location":"reference/hielen3/cloudmanager/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/cloudmanager/#cloudmanager","text":"class Cloudmanager ( feature , basepath , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Cloudmanager ( ABC ) : def __init__ ( self , feature , basepath , * args , ** kwargs ) : basepath = Path ( feature ) / basepath self . cloudbaseurl = Path ( conf [ 'cloudurl' ] ) / 'viewer.html' self . cloudcache = SourceStorage ( conf [ 'syscache' ][ 'cloudcache' ] , str ( basepath )) self . basepath = basepath \"\"\" @property def mapfile(self): return self.mapcache / \" mapfile . map \" @property def mapurl(self): return self.mapbaseurl / \" mapfile . map \" @abstractmethod def setMFparams(): pass \"\"\" @abstractmethod def geturl () : pass","title":"Cloudmanager"},{"location":"reference/hielen3/cloudmanager/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/cloudmanager/#descendants","text":"hielen3.cloudmanager.PotreeCM","title":"Descendants"},{"location":"reference/hielen3/cloudmanager/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/cloudmanager/#geturl","text":"def geturl ( ) View Source @abstractmethod def geturl () : pass","title":"geturl"},{"location":"reference/hielen3/cloudmanager/#potreecm","text":"class PotreeCM ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class PotreeCM ( Cloudmanager ): def __init__ ( self ,* args ,** kwargs ): super (). __init__ (* args ,** kwargs ) def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \"{conf['potreeconverter']} {lazfile} -o {targhetpath}\" ) def geturl ( self , subpath , cloud = None ): if cloud is None: cloud = \"*\" sub = self . cloudcache / subpath clouds =[] clswitch ={} #basepath = self.cloudcache / 'base' / 'metadata.json' #metto la base se esiste #if basepath.exists(): # clouds['base']=str(basepath).replace(conf['syscache']['cloudcache'],\"resources\") on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 on = 1 #cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ({ \"name\" : p . name , \"path\" : relpath , \"switch\" : on }) on = 0 url = str ( self . cloudbaseurl )+ \"?clouds=\" + json . dumps ( clouds ) return url","title":"PotreeCM"},{"location":"reference/hielen3/cloudmanager/#ancestors-in-mro_1","text":"hielen3.cloudmanager.Cloudmanager abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/cloudmanager/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/cloudmanager/#geturl_1","text":"def geturl ( self , subpath , cloud = None ) View Source def geturl ( self , subpath , cloud = None ): if cloud is None : cloud = \"*\" sub = self . cloudcache / subpath clouds = [] clswitch = {} # basepath = self . cloudcache / 'base' / 'metadata.json' # metto la base se esiste # if basepath . exists (): # clouds [ 'base' ] = str ( basepath ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) on = 1 for p in self . cloudcache . glob ( '*' ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ( { \"name\" : p . name , \"path\" : relpath , \"switch\" : on } ) on = 0 on = 1 # cerco le altre clouds for p in sub . glob ( cloud ): if p . is_dir () and ( p / 'metadata.json' ). exists (): relpath = str ( p / 'metadata.json' ). replace ( conf [ 'syscache' ][ 'cloudcache' ], \"resources\" ) clouds . append ( { \"name\" : p . name , \"path\" : relpath , \"switch\" : on } ) on = 0 url = str ( self . cloudbaseurl ) + \"?clouds=\" + json . dumps ( clouds ) return url","title":"geturl"},{"location":"reference/hielen3/cloudmanager/#makepotree","text":"def makePotree ( self , lazfile , cloudname , subpath = None ) View Source def makePotree ( self , lazfile , cloudname , subpath = None ): targhetpath = self . cloudcache / ( subpath or \"\" ) / cloudname return os . system ( f \"{conf['potreeconverter']} {lazfile} -o {targhetpath}\" )","title":"makePotree"},{"location":"reference/hielen3/datalink/","text":"Module hielen3.datalink View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series , read_json , NaT , read_csv from abc import ABC , abstractmethod from hielen3.utils import loadjsonfile , savejsonfile , newinstanceof , hashfile from filelock import Timeout , FileLock from numpy import nan from pathlib import Path from hashlib import md5 from shutil import rmtree import os def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ] . items () } class DB ( ABC ): @abstractmethod def __init__ ( self , connection ): pass @abstractmethod def __getitem__ ( self , key ): pass @abstractmethod def __setitem__ ( self , key , value ): pass @abstractmethod def pop ( self , key ): pass class JsonDB ( DB ): def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ): self . jsonfile = connection self . lock = FileLock ( f \" { connection } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { connection } .md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ): try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ({}, columns = self . schema [ 'columns' ]) self . db = self . db . set_index ( self . schema [ 'primary_key' ]) def __chk_and_reload_jsondb ( self , force = False ): \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ): \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key, raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key { key } to remove does not exist\" ) else : # Request to insert key, raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )): key = [ key ] if key . __len__ () < primarykey . __len__ (): raise ValueError ( f \"key { key !r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ], key )) value . update ( keydict ) df = DataFrame ([ value . values ()]) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ]) try : self . db = self . db . append ( df , verify_integrity = True ) . sort_index () except ValueError : raise ValueError ( f \"key { key } to insert exists\" ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ): out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ): out = out . to_frame () . T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index () . to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ): self . __chk_and_reload_jsondb () if isinstance ( key , list ): try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ): return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ): self . __write_jsondb ( key , value ) ''' class JsonCache(DB): def __init__(self, connection): self.cache = ( read_json(connection, convert_dates=False) .set_index([\"uid\", \"timestamp\"])[\"value\"] .sort_index() ) self.filename = connection def __getitem__(self, key): return self.cache[key] def __setitem__(self, key, value): pass def pop(self, key): pass def save(self): self.cache.reset_index().to_json(self.filename, orient=\"records\") ''' class seriescode (): def __init__ ( self , * args , ** kwargs ): self . h = [ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f ' { self . h } ' . encode () ) . hexdigest () def __repr__ ( self ): return self . h class fsHielenCache ( JsonDB ): def __init__ ( self , connection , lock_timeout_seconds = 10 ): self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" :[ \"uid\" , \"info\" ], \"primary_key\" :[ \"uid\" ]} connfile = str ( Path ( connection ) / \"index.json\" ) super () . __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ): info = super () . __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ) . get ( force_reload = True ) def __setitem__ ( self , key , value ): if value is not None and not isinstance ( value , Series ): raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key { key } doesn't seems to match requirement format\" ) #testing existence (stops if exits) if value is not None : super () . __setitem__ ( key ,{}) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics else : super () . __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ) . drop () except FileNotFoundError as e : pass def update ( self , key , value ): if value is not None and not isinstance ( value , Series ): #if value is not None and not isinstance(value,DataFrame): raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super () . __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \" { item } .csv\" ) self . lock = FileLock ( f \" { self . csv } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { self . csv } .md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try : self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e : self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e : ## refershing hash try : self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) except FileNotFoundError as e : pass self . __brute_load_cache () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ) . sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db Variables nan Functions dbinit def dbinit ( conf ) View Source def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ]. items () } Classes CsvCache class CsvCache ( cachepath , item , lock_timeout_seconds = 10 ) View Source class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \"{item}.csv\" ) self . lock = FileLock ( f \"{self.csv}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{self.csv}.md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try: self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e: self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try: self . lock . acquire () try: if force: raise FileNotFoundError () with open ( self . md5file ) as o: md5 = o . read () if not md5 == self . md5: self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e: ## refershing hash try: self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) except FileNotFoundError as e: pass self . __brute_load_cache () finally: self . lock . release () except Timeout: pass def save ( self ): try: self . lock . acquire () try: self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def drop ( self ): try: self . lock . acquire () try: os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def update ( self , value:Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try: self . lock . acquire () try: self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e: error = e finally: self . lock . release () except Timeout as e: error = e if error is not None: raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db Methods drop def drop ( self ) View Source def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e get def get ( self , force_reload = False ) View Source def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e update def update ( self , value : pandas . core . series . Series ) Needs to lock for writing json-database View Source def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error DB class DB ( connection ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DB ( ABC ) : @abstractmethod def __init__ ( self , connection ) : pass @abstractmethod def __getitem__ ( self , key ) : pass @abstractmethod def __setitem__ ( self , key , value ) : pass @abstractmethod def pop ( self , key ) : pass Ancestors (in MRO) abc.ABC Descendants hielen3.datalink.JsonDB Methods pop def pop ( self , key ) View Source @abstractmethod def pop ( self , key ) : pass JsonDB class JsonDB ( connection , schema , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class JsonDB ( DB ) : def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ) : self . jsonfile = connection self . lock = FileLock ( f \"{connection}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{connection}.md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ) : try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ( {} , columns = self . schema [ 'columns' ] ) self . db = self . db . set_index ( self . schema [ 'primary_key' ] ) def __chk_and_reload_jsondb ( self , force = False ) : \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ) : try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ) : \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key , raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key {key} to remove does not exist\" ) else : # Request to insert key , raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )) : key =[ key ] if key . __len__ () < primarykey . __len__ () : raise ValueError ( f \"key {key!r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ] , key )) value . update ( keydict ) df = DataFrame ( [ value.values() ] ) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ] ) try : self . db = self . db . append ( df , verify_integrity = True ). sort_index () except ValueError : raise ValueError ( f \"key {key} to insert exists\" ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ) : out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ) : out = out . to_frame (). T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index (). to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ) : self . __chk_and_reload_jsondb () if isinstance ( key , list ) : try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ) : return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ) : self . __write_jsondb ( key , value ) Ancestors (in MRO) hielen3.datalink.DB abc.ABC Descendants hielen3.datalink.fsHielenCache Methods pop def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None ) save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e fsHielenCache class fsHielenCache ( connection , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class fsHielenCache ( JsonDB ) : def __init__ ( self , connection , lock_timeout_seconds = 10 ) : self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" : [ \"uid\",\"info\" ] , \"primary_key\" : [ \"uid\" ] } connfile = str ( Path ( connection ) / \"index.json\" ) super (). __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ) : info = super (). __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ). get ( force_reload = True ) def __setitem__ ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key {key} doesn't seems to match requirement format\" ) #testing existence ( stops if exits ) if value is not None : super (). __setitem__ ( key , {} ) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics else : super (). __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ). drop () except FileNotFoundError as e : pass def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics Ancestors (in MRO) hielen3.datalink.JsonDB hielen3.datalink.DB abc.ABC Methods pop def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None ) save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e update def update ( self , key , value ) View Source def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics seriescode class seriescode ( * args , ** kwargs ) View Source class seriescode (): def __init__ ( self ,* args ,** kwargs ): self . h =[ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f' { self . h }'. encode () ). hexdigest () def __repr__ ( self ): return self . h","title":"Datalink"},{"location":"reference/hielen3/datalink/#module-hielen3datalink","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series , read_json , NaT , read_csv from abc import ABC , abstractmethod from hielen3.utils import loadjsonfile , savejsonfile , newinstanceof , hashfile from filelock import Timeout , FileLock from numpy import nan from pathlib import Path from hashlib import md5 from shutil import rmtree import os def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ] . items () } class DB ( ABC ): @abstractmethod def __init__ ( self , connection ): pass @abstractmethod def __getitem__ ( self , key ): pass @abstractmethod def __setitem__ ( self , key , value ): pass @abstractmethod def pop ( self , key ): pass class JsonDB ( DB ): def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ): self . jsonfile = connection self . lock = FileLock ( f \" { connection } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { connection } .md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ): try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ({}, columns = self . schema [ 'columns' ]) self . db = self . db . set_index ( self . schema [ 'primary_key' ]) def __chk_and_reload_jsondb ( self , force = False ): \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ): \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key, raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key { key } to remove does not exist\" ) else : # Request to insert key, raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )): key = [ key ] if key . __len__ () < primarykey . __len__ (): raise ValueError ( f \"key { key !r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ], key )) value . update ( keydict ) df = DataFrame ([ value . values ()]) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ]) try : self . db = self . db . append ( df , verify_integrity = True ) . sort_index () except ValueError : raise ValueError ( f \"key { key } to insert exists\" ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ): out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ): out = out . to_frame () . T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index () . to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ): self . __chk_and_reload_jsondb () if isinstance ( key , list ): try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ): return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ): self . __write_jsondb ( key , value ) ''' class JsonCache(DB): def __init__(self, connection): self.cache = ( read_json(connection, convert_dates=False) .set_index([\"uid\", \"timestamp\"])[\"value\"] .sort_index() ) self.filename = connection def __getitem__(self, key): return self.cache[key] def __setitem__(self, key, value): pass def pop(self, key): pass def save(self): self.cache.reset_index().to_json(self.filename, orient=\"records\") ''' class seriescode (): def __init__ ( self , * args , ** kwargs ): self . h = [ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f ' { self . h } ' . encode () ) . hexdigest () def __repr__ ( self ): return self . h class fsHielenCache ( JsonDB ): def __init__ ( self , connection , lock_timeout_seconds = 10 ): self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" :[ \"uid\" , \"info\" ], \"primary_key\" :[ \"uid\" ]} connfile = str ( Path ( connection ) / \"index.json\" ) super () . __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ): info = super () . __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ) . get ( force_reload = True ) def __setitem__ ( self , key , value ): if value is not None and not isinstance ( value , Series ): raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key { key } doesn't seems to match requirement format\" ) #testing existence (stops if exits) if value is not None : super () . __setitem__ ( key ,{}) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics else : super () . __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ) . drop () except FileNotFoundError as e : pass def update ( self , key , value ): if value is not None and not isinstance ( value , Series ): #if value is not None and not isinstance(value,DataFrame): raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super () . __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \" { item } .csv\" ) self . lock = FileLock ( f \" { self . csv } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { self . csv } .md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try : self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e : self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e : ## refershing hash try : self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) except FileNotFoundError as e : pass self . __brute_load_cache () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ) . sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"Module hielen3.datalink"},{"location":"reference/hielen3/datalink/#variables","text":"nan","title":"Variables"},{"location":"reference/hielen3/datalink/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/datalink/#dbinit","text":"def dbinit ( conf ) View Source def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ]. items () }","title":"dbinit"},{"location":"reference/hielen3/datalink/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/datalink/#csvcache","text":"class CsvCache ( cachepath , item , lock_timeout_seconds = 10 ) View Source class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \"{item}.csv\" ) self . lock = FileLock ( f \"{self.csv}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{self.csv}.md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try: self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e: self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try: self . lock . acquire () try: if force: raise FileNotFoundError () with open ( self . md5file ) as o: md5 = o . read () if not md5 == self . md5: self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e: ## refershing hash try: self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) except FileNotFoundError as e: pass self . __brute_load_cache () finally: self . lock . release () except Timeout: pass def save ( self ): try: self . lock . acquire () try: self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def drop ( self ): try: self . lock . acquire () try: os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def update ( self , value:Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try: self . lock . acquire () try: self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e: error = e finally: self . lock . release () except Timeout as e: error = e if error is not None: raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"CsvCache"},{"location":"reference/hielen3/datalink/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/datalink/#drop","text":"def drop ( self ) View Source def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"drop"},{"location":"reference/hielen3/datalink/#get","text":"def get ( self , force_reload = False ) View Source def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"get"},{"location":"reference/hielen3/datalink/#save","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen3/datalink/#update","text":"def update ( self , value : pandas . core . series . Series ) Needs to lock for writing json-database View Source def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error","title":"update"},{"location":"reference/hielen3/datalink/#db","text":"class DB ( connection ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DB ( ABC ) : @abstractmethod def __init__ ( self , connection ) : pass @abstractmethod def __getitem__ ( self , key ) : pass @abstractmethod def __setitem__ ( self , key , value ) : pass @abstractmethod def pop ( self , key ) : pass","title":"DB"},{"location":"reference/hielen3/datalink/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/datalink/#descendants","text":"hielen3.datalink.JsonDB","title":"Descendants"},{"location":"reference/hielen3/datalink/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/datalink/#pop","text":"def pop ( self , key ) View Source @abstractmethod def pop ( self , key ) : pass","title":"pop"},{"location":"reference/hielen3/datalink/#jsondb","text":"class JsonDB ( connection , schema , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class JsonDB ( DB ) : def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ) : self . jsonfile = connection self . lock = FileLock ( f \"{connection}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{connection}.md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ) : try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ( {} , columns = self . schema [ 'columns' ] ) self . db = self . db . set_index ( self . schema [ 'primary_key' ] ) def __chk_and_reload_jsondb ( self , force = False ) : \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ) : try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ) : \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key , raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key {key} to remove does not exist\" ) else : # Request to insert key , raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )) : key =[ key ] if key . __len__ () < primarykey . __len__ () : raise ValueError ( f \"key {key!r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ] , key )) value . update ( keydict ) df = DataFrame ( [ value.values() ] ) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ] ) try : self . db = self . db . append ( df , verify_integrity = True ). sort_index () except ValueError : raise ValueError ( f \"key {key} to insert exists\" ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ) : out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ) : out = out . to_frame (). T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index (). to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ) : self . __chk_and_reload_jsondb () if isinstance ( key , list ) : try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ) : return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ) : self . __write_jsondb ( key , value )","title":"JsonDB"},{"location":"reference/hielen3/datalink/#ancestors-in-mro_1","text":"hielen3.datalink.DB abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/datalink/#descendants_1","text":"hielen3.datalink.fsHielenCache","title":"Descendants"},{"location":"reference/hielen3/datalink/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/datalink/#pop_1","text":"def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None )","title":"pop"},{"location":"reference/hielen3/datalink/#save_1","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen3/datalink/#fshielencache","text":"class fsHielenCache ( connection , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class fsHielenCache ( JsonDB ) : def __init__ ( self , connection , lock_timeout_seconds = 10 ) : self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" : [ \"uid\",\"info\" ] , \"primary_key\" : [ \"uid\" ] } connfile = str ( Path ( connection ) / \"index.json\" ) super (). __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ) : info = super (). __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ). get ( force_reload = True ) def __setitem__ ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key {key} doesn't seems to match requirement format\" ) #testing existence ( stops if exits ) if value is not None : super (). __setitem__ ( key , {} ) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics else : super (). __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ). drop () except FileNotFoundError as e : pass def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics","title":"fsHielenCache"},{"location":"reference/hielen3/datalink/#ancestors-in-mro_2","text":"hielen3.datalink.JsonDB hielen3.datalink.DB abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/datalink/#methods_3","text":"","title":"Methods"},{"location":"reference/hielen3/datalink/#pop_2","text":"def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None )","title":"pop"},{"location":"reference/hielen3/datalink/#save_2","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen3/datalink/#update_1","text":"def update ( self , key , value ) View Source def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics","title":"update"},{"location":"reference/hielen3/datalink/#seriescode","text":"class seriescode ( * args , ** kwargs ) View Source class seriescode (): def __init__ ( self ,* args ,** kwargs ): self . h =[ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f' { self . h }'. encode () ). hexdigest () def __repr__ ( self ): return self . h","title":"seriescode"},{"location":"reference/hielen3/mapmanager/","text":"Module hielen3.mapmanager View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 #!/usr/bin/env python # coding=utf-8 import mappyfile import re from hielen3 import conf from abc import ABC , abstractmethod from pathlib import Path from hielen3.sourcestorage import SourceStorage class Mapmanager ( ABC ): def __init__ ( self , feature , mapname , * args , ** kwargs ): subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ], str ( subpath )) @property def mapfile ( self ): return self . mapcache / \"mapfile.map\" @property def mapurl ( self ): return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams (): pass @abstractmethod def geturl (): pass class Multiraster ( Mapmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 4 , scale = [ '0,255' , '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ): inmapf = conf [ 'maptemplates' ][ self . maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ): scale = [ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ] = [ f 'BANDS= { tbands } ' ] for i in range ( 0 , bands ): layer [ 'processing' ] . append ( f \"SCALE_ { i + 1 } = { scale [ i ] } \" ) layer [ \"projection\" ] = f \"init= { str ( crs ) . lower () } \" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ]: um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ) . upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer[\"composite\"][\"opacity\"] = opacity mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ): url = [ str ( self . mapbaseurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile= {x} + {y} + {z} \" , ] #return urllib.parse.quote(\"\".join(url)) return \"\" . join ( url ) Variables conf Classes Mapmanager class Mapmanager ( feature , mapname , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Mapmanager ( ABC ) : def __init__ ( self , feature , mapname , * args , ** kwargs ) : subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ] , str ( subpath )) @property def mapfile ( self ) : return self . mapcache / \"mapfile.map\" @property def mapurl ( self ) : return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams () : pass @abstractmethod def geturl () : pass Ancestors (in MRO) abc.ABC Descendants hielen3.mapmanager.Multiraster Instance variables mapfile mapurl Methods geturl def geturl ( ) View Source @abstractmethod def geturl () : pass setMFparams def setMFparams ( ) View Source @abstractmethod def setMFparams () : pass Multiraster class Multiraster ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Multiraster ( Mapmanager ) : def __init__ ( self , * args , ** kwargs ) : super (). __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 4 , scale =[ '0,255','0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ] : um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer [ \"composite\" ][ \"opacity\" ] = opacity mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ) : url =[ str(self.mapbaseurl), \"?SERVICE=WMS&VERSION=1.1.1\", \"&imgfile=\"+ str(imgname), \"&layers=imglyr\", \"&transparent=true\", \"&format=image/png\", \"&mode=tile\", \"&tilemode=gmap\", \"&tile={x}+{y}+{z}\", ] #return urllib . parse . quote ( \"\" . join ( url )) return \"\" . join ( url ) Ancestors (in MRO) hielen3.mapmanager.Mapmanager abc.ABC Instance variables mapfile mapurl Methods geturl def geturl ( self , imgname ) View Source def geturl ( self , imgname ): url = [ str ( self . mapbaseurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile={x}+{y}+{z}\" , ] # return urllib . parse . quote ( \"\" . join ( url )) return \"\" . join ( url ) setMFparams def setMFparams ( self , bands = 4 , scale = [ '0,255' , '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = 'http://pippo&' ) View Source def setMFparams ( self , bands = 4 , scale =[ '0,255','0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ] : um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer [ \"composite\" ][ \"opacity\" ] = opacity mappyfile . save ( mapfile , self . mapfile , 2 )","title":"Mapmanager"},{"location":"reference/hielen3/mapmanager/#module-hielen3mapmanager","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 #!/usr/bin/env python # coding=utf-8 import mappyfile import re from hielen3 import conf from abc import ABC , abstractmethod from pathlib import Path from hielen3.sourcestorage import SourceStorage class Mapmanager ( ABC ): def __init__ ( self , feature , mapname , * args , ** kwargs ): subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ], str ( subpath )) @property def mapfile ( self ): return self . mapcache / \"mapfile.map\" @property def mapurl ( self ): return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams (): pass @abstractmethod def geturl (): pass class Multiraster ( Mapmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 4 , scale = [ '0,255' , '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ): inmapf = conf [ 'maptemplates' ][ self . maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ): scale = [ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ] = [ f 'BANDS= { tbands } ' ] for i in range ( 0 , bands ): layer [ 'processing' ] . append ( f \"SCALE_ { i + 1 } = { scale [ i ] } \" ) layer [ \"projection\" ] = f \"init= { str ( crs ) . lower () } \" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ]: um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ) . upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer[\"composite\"][\"opacity\"] = opacity mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ): url = [ str ( self . mapbaseurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile= {x} + {y} + {z} \" , ] #return urllib.parse.quote(\"\".join(url)) return \"\" . join ( url )","title":"Module hielen3.mapmanager"},{"location":"reference/hielen3/mapmanager/#variables","text":"conf","title":"Variables"},{"location":"reference/hielen3/mapmanager/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/mapmanager/#mapmanager","text":"class Mapmanager ( feature , mapname , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Mapmanager ( ABC ) : def __init__ ( self , feature , mapname , * args , ** kwargs ) : subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ] , str ( subpath )) @property def mapfile ( self ) : return self . mapcache / \"mapfile.map\" @property def mapurl ( self ) : return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams () : pass @abstractmethod def geturl () : pass","title":"Mapmanager"},{"location":"reference/hielen3/mapmanager/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/mapmanager/#descendants","text":"hielen3.mapmanager.Multiraster","title":"Descendants"},{"location":"reference/hielen3/mapmanager/#instance-variables","text":"mapfile mapurl","title":"Instance variables"},{"location":"reference/hielen3/mapmanager/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/mapmanager/#geturl","text":"def geturl ( ) View Source @abstractmethod def geturl () : pass","title":"geturl"},{"location":"reference/hielen3/mapmanager/#setmfparams","text":"def setMFparams ( ) View Source @abstractmethod def setMFparams () : pass","title":"setMFparams"},{"location":"reference/hielen3/mapmanager/#multiraster","text":"class Multiraster ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Multiraster ( Mapmanager ) : def __init__ ( self , * args , ** kwargs ) : super (). __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 4 , scale =[ '0,255','0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ] : um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer [ \"composite\" ][ \"opacity\" ] = opacity mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ) : url =[ str(self.mapbaseurl), \"?SERVICE=WMS&VERSION=1.1.1\", \"&imgfile=\"+ str(imgname), \"&layers=imglyr\", \"&transparent=true\", \"&format=image/png\", \"&mode=tile\", \"&tilemode=gmap\", \"&tile={x}+{y}+{z}\", ] #return urllib . parse . quote ( \"\" . join ( url )) return \"\" . join ( url )","title":"Multiraster"},{"location":"reference/hielen3/mapmanager/#ancestors-in-mro_1","text":"hielen3.mapmanager.Mapmanager abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/mapmanager/#instance-variables_1","text":"mapfile mapurl","title":"Instance variables"},{"location":"reference/hielen3/mapmanager/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/mapmanager/#geturl_1","text":"def geturl ( self , imgname ) View Source def geturl ( self , imgname ): url = [ str ( self . mapbaseurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile={x}+{y}+{z}\" , ] # return urllib . parse . quote ( \"\" . join ( url )) return \"\" . join ( url )","title":"geturl"},{"location":"reference/hielen3/mapmanager/#setmfparams_1","text":"def setMFparams ( self , bands = 4 , scale = [ '0,255' , '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = 'http://pippo&' ) View Source def setMFparams ( self , bands = 4 , scale =[ '0,255','0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" try : um = um . upper () except Exception as e : pass if um is None or not um or um in [ 'UNKNOWN' ] : um = \"METERS\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext #layer [ \"composite\" ][ \"opacity\" ] = opacity mappyfile . save ( mapfile , self . mapfile , 2 )","title":"setMFparams"},{"location":"reference/hielen3/query/","text":"Module hielen3.query View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique , round from importlib import import_module from hielen3 import db from hielen3.utils import isot2ut , ut2isot , agoodtime from hielen3.source import sourceFactory import traceback def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class HSeries : def __init__ ( self , uid , orient = \"data\" ): if uid is None : raise ValueError series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ): return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ): timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ): cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ): try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ): out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(timefrom2,timefrom or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen . columns [ 0 ]] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ): try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self . uid ] = out if cache == \"refresh\" : try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ): cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ): raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError as e : pass if cache not in ( \"no\" ): try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () out . index . name = \"timestamp\" return out def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ): cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ): raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError as e : pass if cache not in ( \"no\" ): try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ): self . orient = orient try : self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source). { self . orient } (**operands)\" except Exception as e : self . operator = Series ([]) self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items (): \"\"\" trying to extract a series \"\"\" try : self . operands [ key ] = HSeries ( value , self . orient ) continue except Exception as e : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]] continue except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ): operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , HSeries )} ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } operands . update ({ k : w . result () for k , w in runners . items ()}) #operands.update( { k:w.data(**kwargs) for k,w in self.operands.items() if isinstance(w,HSeries) } ) return eval ( self . operator ) Variables db nan Classes Generator class Generator ( source = None , modules = None , operator = None , operands = None , orient = 'data' ) View Source class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ) : self . orient = orient try : self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source).{self.orient}(**operands)\" except Exception as e : self . operator = Series ( [] ) self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items () : \"\"\" trying to extract a series \"\"\" try : self . operands [ key ]= HSeries ( value , self . orient ) continue except Exception as e : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] continue except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ) : operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , HSeries ) } ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } operands . update ( { k : w . result () for k , w in runners . items () } ) #operands . update ( { k : w . data ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } ) return eval ( self . operator ) HSeries class HSeries ( uid , orient = 'data' ) View Source class HSeries : def __init__ ( self , uid , orient = \"data\" ) : if uid is None : raise ValueError series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ) : cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ) : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( timefrom2 , timefrom or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen.columns[0 ] ] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ) : try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out if cache == \"refresh\" : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ) : cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ) : cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out Methods cloud def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ) : cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out data def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ) : cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ) : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( timefrom2 , timefrom or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen.columns[0 ] ] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ) : try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out if cache == \"refresh\" : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () return out map def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ) : cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out thdata def thdata ( self , ** kwargs ) View Source @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs )","title":"Query"},{"location":"reference/hielen3/query/#module-hielen3query","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique , round from importlib import import_module from hielen3 import db from hielen3.utils import isot2ut , ut2isot , agoodtime from hielen3.source import sourceFactory import traceback def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class HSeries : def __init__ ( self , uid , orient = \"data\" ): if uid is None : raise ValueError series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ): return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ): timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ): cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ): try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ): out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(timefrom2,timefrom or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen . columns [ 0 ]] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ): try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self . uid ] = out if cache == \"refresh\" : try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ): cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ): raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError as e : pass if cache not in ( \"no\" ): try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () out . index . name = \"timestamp\" return out def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ): cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ): cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ): raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError as e : pass if cache not in ( \"no\" ): try : db [ \"datacache\" ][ self . uid ] = None except KeyError as e : pass finally : db [ \"datacache\" ][ self . uid ] = out except Exception as e : out = Series () out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ): self . orient = orient try : self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source). { self . orient } (**operands)\" except Exception as e : self . operator = Series ([]) self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items (): \"\"\" trying to extract a series \"\"\" try : self . operands [ key ] = HSeries ( value , self . orient ) continue except Exception as e : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]] continue except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ): operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , HSeries )} ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } operands . update ({ k : w . result () for k , w in runners . items ()}) #operands.update( { k:w.data(**kwargs) for k,w in self.operands.items() if isinstance(w,HSeries) } ) return eval ( self . operator )","title":"Module hielen3.query"},{"location":"reference/hielen3/query/#variables","text":"db nan","title":"Variables"},{"location":"reference/hielen3/query/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/query/#generator","text":"class Generator ( source = None , modules = None , operator = None , operands = None , orient = 'data' ) View Source class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ) : self . orient = orient try : self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source).{self.orient}(**operands)\" except Exception as e : self . operator = Series ( [] ) self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items () : \"\"\" trying to extract a series \"\"\" try : self . operands [ key ]= HSeries ( value , self . orient ) continue except Exception as e : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] continue except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ) : operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , HSeries ) } ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } operands . update ( { k : w . result () for k , w in runners . items () } ) #operands . update ( { k : w . data ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , HSeries ) } ) return eval ( self . operator )","title":"Generator"},{"location":"reference/hielen3/query/#hseries","text":"class HSeries ( uid , orient = 'data' ) View Source class HSeries : def __init__ ( self , uid , orient = \"data\" ) : if uid is None : raise ValueError series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ) : cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ) : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( timefrom2 , timefrom or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen.columns[0 ] ] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ) : try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out if cache == \"refresh\" : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ) : cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ) : cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out","title":"HSeries"},{"location":"reference/hielen3/query/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/query/#cloud","text":"def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"cloud\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"cloud\" ) : cache = \"refresh\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError : try : out = self . generator . _generate ( times = times , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out","title":"cloud"},{"location":"reference/hielen3/query/#data","text":"def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : timeref = agoodtime ( timeref ) try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"data\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"data\" ) : cache = \"refresh\" try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first times = slice ( timefrom , timeto , None ) cache = \"no\" if cache in ( \"active\" , \"data\" ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] if timefrom is not None and isot2ut ( out . index . max ()) < isot2ut ( timefrom ) : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = Series () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( timefrom2 , timefrom or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) times = slice ( timefrom2 , timeto ) else : out = Series () try : gen = self . generator . _generate ( times = times , timeref = timeref , geometry = geometry , ** kwargs ) try : gen = gen [ gen.columns[0 ] ] except AttributeError as e : pass try : gen = round ( gen , 4 ) except Exception as e : pass out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" if cache in ( \"active\" , \"data\" ) : try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out if cache == \"refresh\" : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () return out","title":"data"},{"location":"reference/hielen3/query/#map","text":"def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : cache = self . cache except Exception as e : cache = \"no\" if cache is None or cache not in ( \"active\" , \"map\" ) : cache = \"no\" if refresh is not None and refresh and cache in ( \"active\" , \"map\" ) : cache = \"refresh\" timeref = agoodtime ( timeref ) if timeref is not None : cache = \"no\" try : if cache in ( \"refresh\" , \"no\" ) : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] if out . empty : raise KeyError except KeyError as e : try : out = self . generator . _generate ( times = times , timeref = timeref , ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError as e : pass if cache not in ( \"no\" ) : try : db [ \"datacache\" ][ self.uid ]= None except KeyError as e : pass finally : db [ \"datacache\" ][ self.uid ]= out except Exception as e : out = Series () out . index . name = \"timestamp\" return out","title":"map"},{"location":"reference/hielen3/query/#thdata","text":"def thdata ( self , ** kwargs ) View Source @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs )","title":"thdata"},{"location":"reference/hielen3/source/","text":"Module hielen3.source View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 #!/usr/bin/env python # coding=utf-8 from glob import glob from pathlib import Path , os from inspect import ismodule from abc import ABC , abstractmethod from importlib import import_module from hielen3 import db , conf from hielen3.mapmanager import Multiraster from hielen3.sourcestorage import SourceStorage from hielen3.utils import getSchemaDict , LocalFile , FTPPath , hasher from marshmallow import Schema , fields , ValidationError , INCLUDE from numpy import datetime64 , isnat , full , log import rasterio from rasterio.warp import transform_bounds , transform_geom import magic import re import traceback def loadModule ( proto ): if ismodule ( proto ): return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : return proto def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ) . lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \" { action . capitalize () } Schema\" ) def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]) . Source ( feature = feat ) class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' class Meta : unknown = INCLUDE _self_hints = { \"Base\" : { 0 : [ \"timestamp\" , \"Reference time\" , 0 ] } } @property def hints ( self ): out = self . __class__ . _self_hints for c in self . __class__ . __bases__ : try : out . update ( c () . hints ) except AttributeError as e : pass return out timestamp = StringTime ( required = True , allow_none = False ) class GeoInfoSchema ( ActionSchema ): ''' Minimal map based ActionSchema object. Used to define geo-info ''' _self_hints = { \"Geo Info\" : { 0 : [ \"master_image\" , \"The base image used as reference grid for elaboration or basemap. It can be any image format managed by rasterio pyhton library (GeoTIFF, jp eg, ...). Colometric interpretation will be RGB whit Black alpha mask. Any elaboration image based on the 'master_image' will share geometry and reference system with it.\" , False ], 1 : [ \"geo_reference_file\" , \"Reference file for the geolocalization of the 'grid' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). NOTE: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image'\" , False ], 2 :[ \"crs\" , \"the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). NOTE: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image'\" , False ], 3 :[ \"extent_easting\" , \"Easting map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ], 4 :[ \"extent_northing\" , \"Northing map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ] } } master_image = FTPPath ( required = False , allow_none = True ) geo_reference_file = FTPPath ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) extent_easting = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) extent_northing = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) def _agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception as e : t = None return t class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class HielenSource ( ABC ): def __init__ ( self , feature ): if isinstance ( feature , str ): feature = db [ 'features' ][ feature ] self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) self . incomepath = conf [ 'incomepath' ] #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ], self . uid ) def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass () . load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e #raise ValueError(e) def updateAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ])[ 0 ][ 'value' ] for k , w in kwargs . items (): if w is not None : out [ k ] = w kwargs = aclass () . load ( out ) return self . __getattribute__ ( f \"update { action . capitalize () } \" )( ** kwargs ) except Exception as e : raise e #raise ValueError(e) def getFeatureInfo ( self , info ): return db [ \"features_info\" ][ self . uid ][ info ] def setFeatureInfo ( self , info , value ): feat_info = db [ \"features_info\" ][ self . uid ] feat_info [ info ] = value db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info def cleanFeatureCache ( self , params = None ): fpars = list ( db [ \"features_info\" ][ self . uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ): params = [ params ] params = [ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ] = None except KeyError as e : pass def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ): if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self . uid , action , timestamp ] if not isinstance ( out , list ): out = [ out ] except KeyError : return [] return out def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None def deleteActionValues ( self , action = None , timestamp = None ): out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ): out = [ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean { a . capitalize () } \" )( t ) except Exception as e : #traceback.print_exc() pass try : db [ 'actions' ][ self . uid , a , t ] = None except Exception as e : raise ValueError ( e ) return out def retriveSeries ( self , parameters ): ft = db [ \"features_info\" ][ self . uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ parameters ]] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series def addParamSeries ( self , param , struct ): suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ] = self . uid db [ 'series' ][ suid ] = struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ({ param : suid }) self . setFeatureInfo ( 'parameters' , params ) def setParamOperand ( self , param , operand , value ): serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ] = value db [ 'series' ][ serid ] = None db [ 'series' ][ serid ] = ser db [ 'series' ] . save () def setParamOperands ( self , param , ** kwargs ): serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items (): ser [ 'operands' ][ k ] = w db [ 'series' ][ serid ] = None db [ 'series' ][ serid ] = ser db [ 'series' ] . save () def _timeline_add ( self , timestamp ): timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) try : timeline = set ( self . getFeatureInfo ( 'timeline' )) if timeline is None : raise KeyError except Exception as e : timeline = set ([]) timeline . add ( timestamp ) timeline = list ( timeline ) timeline . sort () self . setFeatureInfo ( 'timeline' , timeline ) def _timeline_remove ( self , timestamp ): timestamp = _agoodtime ( value ) if timestamp is not None : try : timeline = self . getFeatureInfo ( 'timeline' ) timeline . pop ( timeline . index ( timestamp )) self . setFeatureInfo ( 'timeline' , timeline ) except Exception as e : #traceback.print_exc() pass class DataSource ( HielenSource ): @abstractmethod def data ( ** kwargs ): pass class MapSource ( DataSource ): mapbasename = \"basemap.tif\" def _set_map_info ( self , map_info ): try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : #traceback.print_exc() pass def config ( self , ** kwargs ): timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ) . split ( \".\" ) #Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 : - 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback.print_exc() pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta = { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback.print_exc() try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp' : timestamp , 'master_image' : None , 'meta' : None } # raise ValueError('Unable to define map extention: not \"master_image\" nor \"extentions\" defined') h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype = 'uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , ** defaultmeta ) as dst : for i in range ( 0 , count ): dst . write ( imgout [:,:, i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ] . to_string () except AttributeError : geographic = False meta [ 'crs' ] = 'EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ) . copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ): rgb . append ( src . read ( i + 1 )) if rgb . __len__ () == 3 : rgb . append ( full ( rgb [ 0 ] . shape , dtype = \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , ** meta ) as dst : for i in range ( 0 , rgb . __len__ ()): dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN' : outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass #Master_image is ok. Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _set_map_info ({ \"extent\" :{ \"minlon\" : minlon , \"minlat\" : minlat , \"maxlon\" : maxlon , \"maxlat\" : maxlat , }, \"center\" :{ \"lon\" :( maxlon + minlon ) / 2 , \"lat\" :( maxlat + minlat ) / 2 }, \"zoom\" :{ \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out = {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass class CloudSource ( MapSource ): @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass Variables INCLUDE conf db isnat log Functions getActionSchema def getActionSchema ( proto , action ) View Source def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) getActionSchemaClass def getActionSchemaClass ( proto , action ) View Source def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \"{action.capitalize()}Schema\" ) loadModule def loadModule ( proto ) View Source def loadModule ( proto ) : if ismodule ( proto ) : return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : return proto moduleActions def moduleActions ( proto ) View Source def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ). lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] sourceFactory def sourceFactory ( feat ) View Source def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]). Source ( feature = feat ) Classes ActionSchema class ActionSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ActionSchema ( Schema ) : ''' Minimal ActionSchema object. Used to define at least a timestamp ''' class Meta : unknown = INCLUDE _self_hints = { \"Base\" : { 0 : [ \"timestamp\",\"Reference time\" ,0 ] } } @property def hints ( self ) : out = self . __class__ . _self_hints for c in self . __class__ . __bases__ : try : out . update ( c (). hints ) except AttributeError as e : pass return out timestamp = StringTime ( required = True , allow_none = False ) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Descendants hielen3.source.GeoInfoSchema hielen3.ext.davedere_hotspot_multiseries.hotspot.ConfigSchema hielen3.ext.source_logger.logger.ConfigSchema hielen3.ext.source_photomonitoring.phm.FeedSchema hielen3.ext.source_rawsource.rawsource.ConfigSchema hielen3.ext.source_rawsource.rawsource.FeedSchema hielen3.ext.source_rawsource.rawsource_.ConfigSchema hielen3.ext.source_rawsource.rawsource_.FeedSchema hielen3.ext.source_tinsar.tin.FeedSchema Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts timestamp Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} CloudSource class CloudSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class CloudSource ( MapSource ) : @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass Ancestors (in MRO) hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Descendants hielen3.ext.source_tinsar.tin.Source Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cloud def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass config def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) DataSource class DataSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DataSource ( HielenSource ) : @abstractmethod def data ( ** kwargs ) : pass Ancestors (in MRO) hielen3.source.HielenSource abc.ABC Descendants hielen3.source.MapSource hielen3.ext.davedere_hotspot_multiseries.hotspot.Source hielen3.ext.source_logger.logger.Source hielen3.ext.source_rawsource.rawsource.Source hielen3.ext.source_rawsource.rawsource_.Source Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) GeoInfoSchema class GeoInfoSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class GeoInfoSchema ( ActionSchema ): ''' Minimal map based ActionSchema object. Used to define geo-info ''' _self_hints = { \"Geo Info\" : { 0 : [ \"master_image\" , \"The base image used as reference grid for elaboration or basemap. It can be any image format managed by rasterio pyhton library (GeoTIFF, jp eg, ...). Colometric interpretation will be RGB whit Black alpha mask. Any elaboration image based on the 'master_image' will share geometry and reference system with it.\" , False ], 1 : [ \"geo_reference_file\" , \"Reference file for the geolocalization of the 'grid' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). NOTE: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image'\" , False ], 2 :[ \"crs\" , \"the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). NOTE: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image'\" , False ], 3 :[ \"extent_easting\" , \"Easting map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ], 4 :[ \"extent_northing\" , \"Northing map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ] } } master_image = FTPPath ( required = False , allow_none = True ) geo_reference_file = FTPPath ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) extent_easting = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) extent_northing = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Descendants hielen3.ext.source_photomonitoring.phm.ConfigSchema hielen3.ext.source_tinsar.tin.ConfigSchema Class variables Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages extent_easting extent_northing geo_reference_file master_image opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} HielenSource class HielenSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class HielenSource ( ABC ) : def __init__ ( self , feature ) : if isinstance ( feature , str ) : feature = db [ 'features' ][ feature ] self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) self . incomepath = conf [ 'incomepath' ] #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ] , self . uid ) def hasher ( self , * args , ** kwargs ) : h =[ *args ] h . extend ( list ( kwargs . values ())) h = '' . join ( [ str(a) for a in h ] ) return re . sub ( \"[^\\d]\" , \"\" , h ) def execAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass def getActionSchema ( self , action ) : return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out def lastActionBefore ( self , action , timestamp = None ) : c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ -1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () def _timeline_add ( self , timestamp ) : timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) try : timeline = set ( self . getFeatureInfo ( 'timeline' )) if timeline is None : raise KeyError except Exception as e : timeline = set ( [] ) timeline . add ( timestamp ) timeline = list ( timeline ) timeline . sort () self . setFeatureInfo ( 'timeline' , timeline ) def _timeline_remove ( self , timestamp ) : timestamp = _agoodtime ( value ) if timestamp is not None : try : timeline = self . getFeatureInfo ( 'timeline' ) timeline . pop ( timeline . index ( timestamp )) self . setFeatureInfo ( 'timeline' , timeline ) except Exception as e : #traceback . print_exc () pass Ancestors (in MRO) abc.ABC Descendants hielen3.source.DataSource Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) MapSource class MapSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class MapSource ( DataSource ) : mapbasename= \"basemap.tif\" def _ set_map_info ( self , map_info ) : try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : #traceback . print_exc () pass def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs @abstractmethod def map ( timefrom = None , timeto = None , geom = None , **kwargs ) : pass Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Descendants hielen3.source.CloudSource hielen3.ext.source_photomonitoring.phm.Source Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass config def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) StringTime class StringTime ( format : Union [ str , NoneType ] = None , ** kwargs ) A formatted datetime string. Example: '2014-12-22T03:12:58.019077+00:00' :param format: Either \"rfc\" (for RFC822), \"iso\" (for ISO8601), or a date format string. If None , defaults to \"iso\". :param kwargs: The same keyword arguments that :class: Field receives. .. versionchanged:: 3.0.0rc9 Does not modify timezone information on (de)serialization. View Source class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super (). _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) Ancestors (in MRO) marshmallow.fields.DateTime marshmallow.fields.Field marshmallow.base.FieldABC Class variables DEFAULT_FORMAT DESERIALIZATION_FUNCS OBJ_TYPE SCHEMA_OPTS_VAR_NAME SERIALIZATION_FUNCS default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"Source"},{"location":"reference/hielen3/source/#module-hielen3source","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 #!/usr/bin/env python # coding=utf-8 from glob import glob from pathlib import Path , os from inspect import ismodule from abc import ABC , abstractmethod from importlib import import_module from hielen3 import db , conf from hielen3.mapmanager import Multiraster from hielen3.sourcestorage import SourceStorage from hielen3.utils import getSchemaDict , LocalFile , FTPPath , hasher from marshmallow import Schema , fields , ValidationError , INCLUDE from numpy import datetime64 , isnat , full , log import rasterio from rasterio.warp import transform_bounds , transform_geom import magic import re import traceback def loadModule ( proto ): if ismodule ( proto ): return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : return proto def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ) . lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \" { action . capitalize () } Schema\" ) def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]) . Source ( feature = feat ) class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' class Meta : unknown = INCLUDE _self_hints = { \"Base\" : { 0 : [ \"timestamp\" , \"Reference time\" , 0 ] } } @property def hints ( self ): out = self . __class__ . _self_hints for c in self . __class__ . __bases__ : try : out . update ( c () . hints ) except AttributeError as e : pass return out timestamp = StringTime ( required = True , allow_none = False ) class GeoInfoSchema ( ActionSchema ): ''' Minimal map based ActionSchema object. Used to define geo-info ''' _self_hints = { \"Geo Info\" : { 0 : [ \"master_image\" , \"The base image used as reference grid for elaboration or basemap. It can be any image format managed by rasterio pyhton library (GeoTIFF, jp eg, ...). Colometric interpretation will be RGB whit Black alpha mask. Any elaboration image based on the 'master_image' will share geometry and reference system with it.\" , False ], 1 : [ \"geo_reference_file\" , \"Reference file for the geolocalization of the 'grid' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). NOTE: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image'\" , False ], 2 :[ \"crs\" , \"the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). NOTE: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image'\" , False ], 3 :[ \"extent_easting\" , \"Easting map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ], 4 :[ \"extent_northing\" , \"Northing map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ] } } master_image = FTPPath ( required = False , allow_none = True ) geo_reference_file = FTPPath ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) extent_easting = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) extent_northing = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) def _agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception as e : t = None return t class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class HielenSource ( ABC ): def __init__ ( self , feature ): if isinstance ( feature , str ): feature = db [ 'features' ][ feature ] self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) self . incomepath = conf [ 'incomepath' ] #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ], self . uid ) def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass () . load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e #raise ValueError(e) def updateAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ])[ 0 ][ 'value' ] for k , w in kwargs . items (): if w is not None : out [ k ] = w kwargs = aclass () . load ( out ) return self . __getattribute__ ( f \"update { action . capitalize () } \" )( ** kwargs ) except Exception as e : raise e #raise ValueError(e) def getFeatureInfo ( self , info ): return db [ \"features_info\" ][ self . uid ][ info ] def setFeatureInfo ( self , info , value ): feat_info = db [ \"features_info\" ][ self . uid ] feat_info [ info ] = value db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info def cleanFeatureCache ( self , params = None ): fpars = list ( db [ \"features_info\" ][ self . uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ): params = [ params ] params = [ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ] = None except KeyError as e : pass def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ): if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self . uid , action , timestamp ] if not isinstance ( out , list ): out = [ out ] except KeyError : return [] return out def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None def deleteActionValues ( self , action = None , timestamp = None ): out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ): out = [ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean { a . capitalize () } \" )( t ) except Exception as e : #traceback.print_exc() pass try : db [ 'actions' ][ self . uid , a , t ] = None except Exception as e : raise ValueError ( e ) return out def retriveSeries ( self , parameters ): ft = db [ \"features_info\" ][ self . uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ parameters ]] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series def addParamSeries ( self , param , struct ): suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ] = self . uid db [ 'series' ][ suid ] = struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ({ param : suid }) self . setFeatureInfo ( 'parameters' , params ) def setParamOperand ( self , param , operand , value ): serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ] = value db [ 'series' ][ serid ] = None db [ 'series' ][ serid ] = ser db [ 'series' ] . save () def setParamOperands ( self , param , ** kwargs ): serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items (): ser [ 'operands' ][ k ] = w db [ 'series' ][ serid ] = None db [ 'series' ][ serid ] = ser db [ 'series' ] . save () def _timeline_add ( self , timestamp ): timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) try : timeline = set ( self . getFeatureInfo ( 'timeline' )) if timeline is None : raise KeyError except Exception as e : timeline = set ([]) timeline . add ( timestamp ) timeline = list ( timeline ) timeline . sort () self . setFeatureInfo ( 'timeline' , timeline ) def _timeline_remove ( self , timestamp ): timestamp = _agoodtime ( value ) if timestamp is not None : try : timeline = self . getFeatureInfo ( 'timeline' ) timeline . pop ( timeline . index ( timestamp )) self . setFeatureInfo ( 'timeline' , timeline ) except Exception as e : #traceback.print_exc() pass class DataSource ( HielenSource ): @abstractmethod def data ( ** kwargs ): pass class MapSource ( DataSource ): mapbasename = \"basemap.tif\" def _set_map_info ( self , map_info ): try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : #traceback.print_exc() pass def config ( self , ** kwargs ): timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ) . split ( \".\" ) #Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 : - 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback.print_exc() pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta = { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback.print_exc() try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp' : timestamp , 'master_image' : None , 'meta' : None } # raise ValueError('Unable to define map extention: not \"master_image\" nor \"extentions\" defined') h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype = 'uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , ** defaultmeta ) as dst : for i in range ( 0 , count ): dst . write ( imgout [:,:, i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ] . to_string () except AttributeError : geographic = False meta [ 'crs' ] = 'EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ) . copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ): rgb . append ( src . read ( i + 1 )) if rgb . __len__ () == 3 : rgb . append ( full ( rgb [ 0 ] . shape , dtype = \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , ** meta ) as dst : for i in range ( 0 , rgb . __len__ ()): dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN' : outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass #Master_image is ok. Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _set_map_info ({ \"extent\" :{ \"minlon\" : minlon , \"minlat\" : minlat , \"maxlon\" : maxlon , \"maxlat\" : maxlat , }, \"center\" :{ \"lon\" :( maxlon + minlon ) / 2 , \"lat\" :( maxlat + minlat ) / 2 }, \"zoom\" :{ \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out = {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass class CloudSource ( MapSource ): @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass","title":"Module hielen3.source"},{"location":"reference/hielen3/source/#variables","text":"INCLUDE conf db isnat log","title":"Variables"},{"location":"reference/hielen3/source/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/source/#getactionschema","text":"def getActionSchema ( proto , action ) View Source def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )())","title":"getActionSchema"},{"location":"reference/hielen3/source/#getactionschemaclass","text":"def getActionSchemaClass ( proto , action ) View Source def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \"{action.capitalize()}Schema\" )","title":"getActionSchemaClass"},{"location":"reference/hielen3/source/#loadmodule","text":"def loadModule ( proto ) View Source def loadModule ( proto ) : if ismodule ( proto ) : return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : return proto","title":"loadModule"},{"location":"reference/hielen3/source/#moduleactions","text":"def moduleActions ( proto ) View Source def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ). lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return []","title":"moduleActions"},{"location":"reference/hielen3/source/#sourcefactory","text":"def sourceFactory ( feat ) View Source def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]). Source ( feature = feat )","title":"sourceFactory"},{"location":"reference/hielen3/source/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/source/#actionschema","text":"class ActionSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ActionSchema ( Schema ) : ''' Minimal ActionSchema object. Used to define at least a timestamp ''' class Meta : unknown = INCLUDE _self_hints = { \"Base\" : { 0 : [ \"timestamp\",\"Reference time\" ,0 ] } } @property def hints ( self ) : out = self . __class__ . _self_hints for c in self . __class__ . __bases__ : try : out . update ( c (). hints ) except AttributeError as e : pass return out timestamp = StringTime ( required = True , allow_none = False )","title":"ActionSchema"},{"location":"reference/hielen3/source/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants","text":"hielen3.source.GeoInfoSchema hielen3.ext.davedere_hotspot_multiseries.hotspot.ConfigSchema hielen3.ext.source_logger.logger.ConfigSchema hielen3.ext.source_photomonitoring.phm.FeedSchema hielen3.ext.source_rawsource.rawsource.ConfigSchema hielen3.ext.source_rawsource.rawsource.FeedSchema hielen3.ext.source_rawsource.rawsource_.ConfigSchema hielen3.ext.source_rawsource.rawsource_.FeedSchema hielen3.ext.source_tinsar.tin.FeedSchema","title":"Descendants"},{"location":"reference/hielen3/source/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts timestamp","title":"Class variables"},{"location":"reference/hielen3/source/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/source/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/source/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/source/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/source/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/source/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/source/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/source/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/source/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/source/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/source/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/source/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/source/#cloudsource","text":"class CloudSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class CloudSource ( MapSource ) : @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"CloudSource"},{"location":"reference/hielen3/source/#ancestors-in-mro_1","text":"hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants_1","text":"hielen3.ext.source_tinsar.tin.Source","title":"Descendants"},{"location":"reference/hielen3/source/#class-variables_1","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/source/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/source/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/source/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/source/#cloud","text":"def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"cloud"},{"location":"reference/hielen3/source/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs","title":"config"},{"location":"reference/hielen3/source/#data","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen3/source/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/source/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/source/#getactionschema_1","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/source/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/source/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/source/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/source/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/source/#map","text":"def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"map"},{"location":"reference/hielen3/source/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/source/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/source/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/source/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/source/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/source/#datasource","text":"class DataSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DataSource ( HielenSource ) : @abstractmethod def data ( ** kwargs ) : pass","title":"DataSource"},{"location":"reference/hielen3/source/#ancestors-in-mro_2","text":"hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants_2","text":"hielen3.source.MapSource hielen3.ext.davedere_hotspot_multiseries.hotspot.Source hielen3.ext.source_logger.logger.Source hielen3.ext.source_rawsource.rawsource.Source hielen3.ext.source_rawsource.rawsource_.Source","title":"Descendants"},{"location":"reference/hielen3/source/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/source/#addparamseries_1","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/source/#cleanfeaturecache_1","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/source/#data_1","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen3/source/#deleteactionvalues_1","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/source/#execaction_1","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/source/#getactionschema_2","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/source/#getactionvalues_1","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/source/#getfeatureinfo_1","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/source/#hasher_1","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/source/#lastactionbefore_1","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/source/#retriveseries_1","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/source/#setfeatureinfo_1","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/source/#setparamoperand_1","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/source/#setparamoperands_1","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/source/#updateaction_1","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/source/#geoinfoschema","text":"class GeoInfoSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class GeoInfoSchema ( ActionSchema ): ''' Minimal map based ActionSchema object. Used to define geo-info ''' _self_hints = { \"Geo Info\" : { 0 : [ \"master_image\" , \"The base image used as reference grid for elaboration or basemap. It can be any image format managed by rasterio pyhton library (GeoTIFF, jp eg, ...). Colometric interpretation will be RGB whit Black alpha mask. Any elaboration image based on the 'master_image' will share geometry and reference system with it.\" , False ], 1 : [ \"geo_reference_file\" , \"Reference file for the geolocalization of the 'grid' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). NOTE: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image'\" , False ], 2 :[ \"crs\" , \"the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). NOTE: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image'\" , False ], 3 :[ \"extent_easting\" , \"Easting map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ], 4 :[ \"extent_northing\" , \"Northing map extention, according with 'crs' and 'geo_reference_file'. Ignored if 'master_image' is provided\" , False ] } } master_image = FTPPath ( required = False , allow_none = True ) geo_reference_file = FTPPath ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) extent_easting = fields . Number ( required = False , default = None , allow_none = True , as_string = False ) extent_northing = fields . Number ( required = False , default = None , allow_none = True , as_string = False )","title":"GeoInfoSchema"},{"location":"reference/hielen3/source/#ancestors-in-mro_3","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants_3","text":"hielen3.ext.source_photomonitoring.phm.ConfigSchema hielen3.ext.source_tinsar.tin.ConfigSchema","title":"Descendants"},{"location":"reference/hielen3/source/#class-variables_2","text":"Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages extent_easting extent_northing geo_reference_file master_image opts","title":"Class variables"},{"location":"reference/hielen3/source/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/source/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/source/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/source/#methods_3","text":"","title":"Methods"},{"location":"reference/hielen3/source/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/source/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/source/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/source/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/source/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/source/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/source/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/source/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/source/#hielensource","text":"class HielenSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class HielenSource ( ABC ) : def __init__ ( self , feature ) : if isinstance ( feature , str ) : feature = db [ 'features' ][ feature ] self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) self . incomepath = conf [ 'incomepath' ] #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ] , self . uid ) def hasher ( self , * args , ** kwargs ) : h =[ *args ] h . extend ( list ( kwargs . values ())) h = '' . join ( [ str(a) for a in h ] ) return re . sub ( \"[^\\d]\" , \"\" , h ) def execAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass def getActionSchema ( self , action ) : return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out def lastActionBefore ( self , action , timestamp = None ) : c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ -1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () def _timeline_add ( self , timestamp ) : timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) try : timeline = set ( self . getFeatureInfo ( 'timeline' )) if timeline is None : raise KeyError except Exception as e : timeline = set ( [] ) timeline . add ( timestamp ) timeline = list ( timeline ) timeline . sort () self . setFeatureInfo ( 'timeline' , timeline ) def _timeline_remove ( self , timestamp ) : timestamp = _agoodtime ( value ) if timestamp is not None : try : timeline = self . getFeatureInfo ( 'timeline' ) timeline . pop ( timeline . index ( timestamp )) self . setFeatureInfo ( 'timeline' , timeline ) except Exception as e : #traceback . print_exc () pass","title":"HielenSource"},{"location":"reference/hielen3/source/#ancestors-in-mro_4","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants_4","text":"hielen3.source.DataSource","title":"Descendants"},{"location":"reference/hielen3/source/#methods_4","text":"","title":"Methods"},{"location":"reference/hielen3/source/#addparamseries_2","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/source/#cleanfeaturecache_2","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/source/#deleteactionvalues_2","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/source/#execaction_2","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/source/#getactionschema_3","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/source/#getactionvalues_2","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/source/#getfeatureinfo_2","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/source/#hasher_2","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/source/#lastactionbefore_2","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/source/#retriveseries_2","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/source/#setfeatureinfo_2","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/source/#setparamoperand_2","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/source/#setparamoperands_2","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/source/#updateaction_2","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/source/#mapsource","text":"class MapSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class MapSource ( DataSource ) : mapbasename= \"basemap.tif\" def _ set_map_info ( self , map_info ) : try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : #traceback . print_exc () pass def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs @abstractmethod def map ( timefrom = None , timeto = None , geom = None , **kwargs ) : pass","title":"MapSource"},{"location":"reference/hielen3/source/#ancestors-in-mro_5","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#descendants_5","text":"hielen3.source.CloudSource hielen3.ext.source_photomonitoring.phm.Source","title":"Descendants"},{"location":"reference/hielen3/source/#class-variables_3","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/source/#methods_5","text":"","title":"Methods"},{"location":"reference/hielen3/source/#addparamseries_3","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/source/#cleanfeaturecache_3","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/source/#config_1","text":"def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] extent = [ kwargs [ 'extent_northing' ], kwargs [ 'extent_easting' ] ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / MapSource . mapbasename mapmanager . mapcache . mkdir () try : opacity = int ( kwargs [ 'opacity' ] / 100 * 255 ) except Exception as e : opacity = 255 try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : #traceback . print_exc () pass try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None geographic = True defaultmeta= { \"driver\" : \"GTiff\" , \"count\" : 4 , \"compress\" : \"lzw\" , \"dtype\" : \"uint8\" } try : try : src = rasterio . open ( temp_base_file ) except Exception as e : #traceback . print_exc () try : src . close () except Exception : pass if extent [ 0 ] is None or extent [ 1 ] is None : return { 'timestamp': timestamp , 'master_image': None , 'meta': None } # raise ValueError ( 'Unable to define map extention: not \"master_image\" nor \"extentions\" defined' ) h = int ( extent [ 1 ]) w = int ( extent [ 0 ]) count = 4 imgout = full ([ w , h , count ], dtype='uint8' , fill_value = [ 255 , 255 , 255 , 0 ]) with rasterio . open ( temp_base_file , 'w' , height = h , width = w , **defaultmeta ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ : , : , i ], i + 1 ) src = rasterio . open ( temp_base_file ) meta = src . meta . copy () meta . update ( defaultmeta ) if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : geographic = False meta [ 'crs' ] ='EPSG:3857' if src . count == 1 : #trasformare da gray scale a rgba rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( \"uint8\" ) rgb = [ rgb , rgb , rgb ] else : rgb = [] for i in range ( 0 , src . count ) : rgb . append ( src . read ( i + 1 )) if rgb . __ len__ () == 3 : rgb . append ( full ( rgb [ 0 ]. shape , dtype= \"uint8\" , fill_value = opacity ) ) minlon , minlat , maxlon , maxlat = transform_bounds ( meta [ 'crs' ], 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] if outcrs is None or outcrs . linear_units == 'UNKNOWN': outum = 'METERS' else : outum = outcrs . linear_units except Exception as e : raise e finally : try : src . close () except Exception : pass # Master_image is ok . Making mapfile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : round ( log ( 40075017 / max ( maxlon - minlon , maxlat - minlat ) ) / log ( 2 )) - 15 }, \"basemapurl\" : mapmanager . geturl ( MapSource . mapbasename ), \"geographic\" : geographic }) out= {} out [ 'timestamp' ] = timestamp out [ 'meta' ] = meta kwargs . update ( out ) return kwargs","title":"config"},{"location":"reference/hielen3/source/#data_2","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen3/source/#deleteactionvalues_3","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/source/#execaction_3","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/source/#getactionschema_4","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/source/#getactionvalues_3","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/source/#getfeatureinfo_3","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/source/#hasher_3","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/source/#lastactionbefore_3","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/source/#map_1","text":"def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"map"},{"location":"reference/hielen3/source/#retriveseries_3","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/source/#setfeatureinfo_3","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/source/#setparamoperand_3","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/source/#setparamoperands_3","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/source/#updateaction_3","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/source/#stringtime","text":"class StringTime ( format : Union [ str , NoneType ] = None , ** kwargs ) A formatted datetime string. Example: '2014-12-22T03:12:58.019077+00:00' :param format: Either \"rfc\" (for RFC822), \"iso\" (for ISO8601), or a date format string. If None , defaults to \"iso\". :param kwargs: The same keyword arguments that :class: Field receives. .. versionchanged:: 3.0.0rc9 Does not modify timezone information on (de)serialization. View Source class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super (). _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value )","title":"StringTime"},{"location":"reference/hielen3/source/#ancestors-in-mro_6","text":"marshmallow.fields.DateTime marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/source/#class-variables_4","text":"DEFAULT_FORMAT DESERIALIZATION_FUNCS OBJ_TYPE SCHEMA_OPTS_VAR_NAME SERIALIZATION_FUNCS default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/source/#instance-variables_2","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/source/#methods_6","text":"","title":"Methods"},{"location":"reference/hielen3/source/#deserialize","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/source/#fail","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/source/#get_value","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/source/#make_error","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/source/#serialize","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/sourcestorage/","text":"Module hielen3.sourcestorage View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python # coding=utf-8 from pathlib import Path , os from shutil import rmtree import traceback class SourceStorage (): def __repr__ ( self ): return self . __str__ () def __str__ ( self ): return str ( self . cache ) def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ) . replace ( f \" { self . cache }{ os . sep } \" , \"\" ) return self . cache / other def glob ( self , * args , ** kwargs ): return self . cache . glob ( * args , ** kwargs ) def mkdir ( self , path = None ): if path is None : path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = None ): if path is None : path = '' outpath = self / path rmtree ( outpath ) Classes SourceStorage class SourceStorage ( syspath , subpath = '' ) View Source class SourceStorage (): def __repr__ ( self ): return self . __str__ () def __str__ ( self ): return str ( self . cache ) def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ). replace ( f \"{self.cache}{os.sep}\" , \"\" ) return self . cache / other def glob ( self ,* args ,** kwargs ): return self . cache . glob (* args ,** kwargs ) def mkdir ( self , path = None ): if path is None: path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = None ): if path is None: path = '' outpath = self / path rmtree ( outpath ) Methods glob def glob ( self , * args , ** kwargs ) View Source def glob ( self , * args , ** kwargs ): return self . cache . glob ( * args , ** kwargs ) mkdir def mkdir ( self , path = None ) View Source def mkdir ( self , path = None ): if path is None : path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath rmdir def rmdir ( self , path = None ) View Source def rmdir ( self , path = None ): if path is None : path = '' outpath = self / path rmtree ( outpath )","title":"Sourcestorage"},{"location":"reference/hielen3/sourcestorage/#module-hielen3sourcestorage","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #!/usr/bin/env python # coding=utf-8 from pathlib import Path , os from shutil import rmtree import traceback class SourceStorage (): def __repr__ ( self ): return self . __str__ () def __str__ ( self ): return str ( self . cache ) def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ) . replace ( f \" { self . cache }{ os . sep } \" , \"\" ) return self . cache / other def glob ( self , * args , ** kwargs ): return self . cache . glob ( * args , ** kwargs ) def mkdir ( self , path = None ): if path is None : path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = None ): if path is None : path = '' outpath = self / path rmtree ( outpath )","title":"Module hielen3.sourcestorage"},{"location":"reference/hielen3/sourcestorage/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/sourcestorage/#sourcestorage","text":"class SourceStorage ( syspath , subpath = '' ) View Source class SourceStorage (): def __repr__ ( self ): return self . __str__ () def __str__ ( self ): return str ( self . cache ) def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ). replace ( f \"{self.cache}{os.sep}\" , \"\" ) return self . cache / other def glob ( self ,* args ,** kwargs ): return self . cache . glob (* args ,** kwargs ) def mkdir ( self , path = None ): if path is None: path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = None ): if path is None: path = '' outpath = self / path rmtree ( outpath )","title":"SourceStorage"},{"location":"reference/hielen3/sourcestorage/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/sourcestorage/#glob","text":"def glob ( self , * args , ** kwargs ) View Source def glob ( self , * args , ** kwargs ): return self . cache . glob ( * args , ** kwargs )","title":"glob"},{"location":"reference/hielen3/sourcestorage/#mkdir","text":"def mkdir ( self , path = None ) View Source def mkdir ( self , path = None ): if path is None : path = '' outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath","title":"mkdir"},{"location":"reference/hielen3/sourcestorage/#rmdir","text":"def rmdir ( self , path = None ) View Source def rmdir ( self , path = None ): if path is None : path = '' outpath = self / path rmtree ( outpath )","title":"rmdir"},{"location":"reference/hielen3/utils/","text":"Module hielen3.utils View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 #!/usr/bin/env python # coding=utf-8 from datetime import datetime from re import split , sub , findall from time import mktime import json from importlib import import_module from falcon import HTTPNotAcceptable , HTTP_OK , Response , Request from hashlib import md5 from marshmallow import Schema , fields import geojson from pandas import DataFrame from numpy import datetime64 , isnat , array , sqrt , sum , where , amin , nan , round from matplotlib.colors import ColorConverter , Normalize , LinearSegmentedColormap , BoundaryNorm from collections.abc import Iterable from uuid import uuid4 def uuid (): return str ( uuid4 ()) def hug_output_format_conten_type ( handlers = [], error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ): \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ): try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items (): if par . split ( \";\" )[ 0 ] == k . split ( \";\" )[ 0 ]: handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0} \" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type def newinstanceof ( klass , * args , ** kwargs ): klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [: - 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , ** kwargs ) def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" try : dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , str ( t ))))) out = int ( mktime ( dt . timetuple ())) except Exception as e : print ( e , t ) return out def agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception : t = None return t def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f ' { h } ' . encode () ) . hexdigest () def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () ### MARSHMALLOW def getSchemaDict ( schema ): out = { \"fields\" :{}, \"required\" :[], \"hints\" : schema . hints } for k , w in schema . dump_fields . items (): out [ 'fields' ][ k ] = w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out class Style ( fields . String ): \"\"\" \"\"\" pass class FTPPath ( fields . String ): \"\"\" Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass class LoggerHeader ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String (), #Raw_mu fields . String (), #Ing_mu fields . String (), #Signal_cond fields . List ( fields . Number ()) #Poly coeff ) ), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return json . loads ( value ) except Exception as e : raise ValueError ( e ) class ParamsDefinition ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String () #Ing_mu ) ), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return json . loads ( value ) except Exception as e : raise ValueError ( e ) class ColorMap ( fields . List ): \"\"\" Colormap manager used to identify a colormap \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple (( fields . String (), fields . Number ())), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return ColorMap . make_colormap ( json . loads ( value )) except Exception as e : try : assert value [ 'f_cmap' ] return value except Exception as e : raise ValueError ( e ) def valorizeColor ( clmap , color ): c = ColorConverter () try : colframe = DataFrame ([ c . to_rgb ( x [ 1 ]) for x in clmap ]) except ValueError as e : colframe = DataFrame ([ x [ 1 ] for x in clmap ]) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns = [ 'r' , 'g' , 'b' ] colframe [ 'values' ] = [ x [ 0 ] for x in clmap ] colors = colframe [[ 'r' , 'g' , 'b' ]] . values colframe = colframe . set_index ([ 'r' , 'g' , 'b' ]) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ([ color ], columns = [ 'r' , 'g' , 'b' ]) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) . values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan def parse_colormap ( incmap ): if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ]) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ]) return { \"norm\" : norm , \"cmap\" : cmap } def make_colormap ( incmap = None ): if incmap is None : incmap = [[ - 0.25 , \"#FF0000\" ],[ 0 , \"#00FF00\" ],[ 0.25 , \"#0000FF\" ]] a = DataFrame ( incmap , columns = [ \"values\" , \"colors\" ]) . sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ], \"vmax\" : a [ \"values\" ] . iloc [ a . shape [ 0 ] - 1 ]}} n = Normalize ( ** out [ \"norm\" ]) a [ \"values\" ] = round ( a [ \"values\" ], 3 ) a [ \"idx\" ] = n ( a [ \"values\" ]) * 100 cc = a [[ \"idx\" , \"colors\" ]] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()): if i == 0 or i == cc . __len__ (): seq . append ( c . to_rgb ( cc [ i ][ 1 ])) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ])) seq . append ( cc [ i ][ 0 ] / 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ])) seq = [( None ,) * 3 , 0.0 ] + list ( seq ) + [ 1.0 , ( None ,) * 3 ] linsegcmap = { 'red' : [], 'green' : [], 'blue' : []} for i , item in enumerate ( seq ): if isinstance ( item , float ): r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ([ item , r1 , r2 ]) linsegcmap [ 'green' ] . append ([ item , g1 , g2 ]) linsegcmap [ 'blue' ] . append ([ item , b1 , b2 ]) out [ \"f_cmap\" ] = a . values . tolist () out [ \"b_cmap\" ] = linsegcmap return out class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \",\". \",\" presence is managed as: \"start,stop,step\" ie.: \"start,stop\" - extracts from start to stop \"start,\" - extracts from start to max \"start\" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try : if isinstance ( value , list ): value = \";\" . join ( value ) if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice ( * value [ 0 : 3 ]) #return value[0:3] except Exception as e : raise ValueError ( e ) class GeoJsonField ( fields . String ): def _deserialize ( self , value , attr , data , ** kwargs ): if isinstance ( value , list ): value = \",\" . join ( value ) try : if value is None or value == \"\" : return None return geojson . loads ( value ) except Exception as e : raise ValueError ( e ) class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ): required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field . __class__ ]) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[ { f } ]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \" {{ { kf } , { vf } }} \" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ): flds = [] for n , f in self . schema . fields . items (): types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds.append( f\"**{n}**{required}{allow_none}: {types}\") flds . append ( f \"** { n } **: { types } \" ) fields = \", \" . join ( flds ) fields = f \" {{ { fields } }} \" if self . schema . many : fields = f \"[ { fields } ]\" return f \"JSON Schema { fields } \" def __init__ ( self , schema ): self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items (): try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k ))[ 0 ]) except KeyError : self . TYPE_MAPPING [ w ] = [ findall ( r \"'(.*)'\" , str ( k ))[ 0 ]] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ): if type ( value ) is list : # If Falcon is set to comma-separate entries, this segment joins them again. fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value ) class ResponseFormatter (): def parse_status ( status ): try : if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else : return \"error\" except ValueError : return \"error\" def __init__ ( self , status = HTTP_OK , message = \"\" , data = \"\" ): self . status = status self . message = message self . data = data def format ( self , response : Response , request : Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \" { request . method } { request . path } \" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response Variables HTTP_OK isnat nan sqrt Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception : t = None return t eprint def eprint ( * args , fname = 'error' , ** kwargs ) View Source def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) getSchemaDict def getSchemaDict ( schema ) View Source def getSchemaDict ( schema ) : out = { \"fields\" :{} , \"required\" :[] , \"hints\" : schema . hints } for k , w in schema . dump_fields . items () : out [ 'fields' ][ k ]= w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out hasher def hasher ( * args , ** kwargs ) View Source def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f '{h}' . encode () ). hexdigest () hashfile def hashfile ( filename ) View Source def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () hug_output_format_conten_type def hug_output_format_conten_type ( handlers = [], error = 'The requested format does not match any of those allowed' , ctpar = 'content_type' ) Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised View Source def hug_output_format_conten_type ( handlers = [] , error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ) : \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ) : try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items () : if par . split ( \";\" ) [ 0 ] == k . split ( \";\" ) [ 0 ] : handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ) : handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0}\" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type isot2ut def isot2ut ( t = None ) View Source def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" try : dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , str ( t ))))) out = int ( mktime ( dt . timetuple ())) except Exception as e : print ( e , t ) return out loadjsonfile def loadjsonfile ( filename ) View Source def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) newinstanceof def newinstanceof ( klass , * args , ** kwargs ) View Source def newinstanceof ( klass , * args , **kwargs ) : klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [:- 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , **kwargs ) savejsonfile def savejsonfile ( filename , struct ) View Source def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) ut2isot def ut2isot ( u = None ) View Source def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) uuid def uuid ( ) View Source def uuid (): return str ( uuid4 ()) Classes ColorMap class ColorMap ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Colormap manager used to identify a colormap View Source class ColorMap ( fields . List ) : \"\"\" Colormap manager used to identify a colormap \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple (( fields . String (), fields . Number ())), ** kwargs ) : super (). __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ) : try : return ColorMap . make_colormap ( json . loads ( value )) except Exception as e : try : assert value [ 'f_cmap' ] return value except Exception as e : raise ValueError ( e ) def valorizeColor ( clmap , color ) : c = ColorConverter () try : colframe = DataFrame ( [ c.to_rgb(x[1 ] ) for x in clmap ] ) except ValueError as e : colframe = DataFrame ( [ x[1 ] for x in clmap ] ) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns =[ 'r','g','b' ] colframe [ 'values' ] = [ x[0 ] for x in clmap ] colors = colframe [ ['r','g','b' ] ] . values colframe = colframe . set_index ( [ 'r','g','b' ] ) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ( [ color ] , columns =[ 'r','g','b' ] ) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ). values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan def parse_colormap ( incmap ) : if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ] ) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ] ) return { \"norm\" : norm , \"cmap\" : cmap } def make_colormap ( incmap = None ) : if incmap is None : incmap =[ [-0.25,\"#FF0000\" ] , [ 0,\"#00FF00\" ] , [ 0.25,\"#0000FF\" ] ] a = DataFrame ( incmap , columns =[ \"values\",\"colors\" ] ). sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ] , \"vmax\" : a [ \"values\" ] . iloc [ a.shape[0 ]- 1 ]}} n = Normalize ( ** out [ \"norm\" ] ) a [ \"values\" ]= round ( a [ \"values\" ] , 3 ) a [ \"idx\" ]= n ( a [ \"values\" ] ) * 100 cc = a [ [\"idx\",\"colors\" ] ] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()) : if i == 0 or i == cc . __len__ () : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq . append ( cc [ i ][ 0 ]/ 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq = [ (None,) * 3, 0.0 ] + list ( seq ) + [ 1.0, (None,) * 3 ] linsegcmap = { 'red' : [] , 'green' : [] , 'blue' : []} for i , item in enumerate ( seq ) : if isinstance ( item , float ) : r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ( [ item, r1, r2 ] ) linsegcmap [ 'green' ] . append ( [ item, g1, g2 ] ) linsegcmap [ 'blue' ] . append ( [ item, b1, b2 ] ) out [ \"f_cmap\" ]= a . values . tolist () out [ \"b_cmap\" ]= linsegcmap return out Ancestors (in MRO) marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_colormap def make_colormap ( incmap = None ) View Source def make_colormap ( incmap = None ) : if incmap is None : incmap =[ [-0.25,\"#FF0000\" ] , [ 0,\"#00FF00\" ] , [ 0.25,\"#0000FF\" ] ] a = DataFrame ( incmap , columns =[ \"values\",\"colors\" ] ). sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ] , \"vmax\" : a [ \"values\" ] . iloc [ a.shape[0 ]- 1 ]}} n = Normalize ( ** out [ \"norm\" ] ) a [ \"values\" ]= round ( a [ \"values\" ] , 3 ) a [ \"idx\" ]= n ( a [ \"values\" ] ) * 100 cc = a [ [\"idx\",\"colors\" ] ] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()) : if i == 0 or i == cc . __len__ () : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq . append ( cc [ i ][ 0 ]/ 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq = [ (None,) * 3, 0.0 ] + list ( seq ) + [ 1.0, (None,) * 3 ] linsegcmap = { 'red' : [] , 'green' : [] , 'blue' : []} for i , item in enumerate ( seq ) : if isinstance ( item , float ) : r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ( [ item, r1, r2 ] ) linsegcmap [ 'green' ] . append ( [ item, g1, g2 ] ) linsegcmap [ 'blue' ] . append ( [ item, b1, b2 ] ) out [ \"f_cmap\" ]= a . values . tolist () out [ \"b_cmap\" ]= linsegcmap return out make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) parse_colormap def parse_colormap ( incmap ) View Source def parse_colormap ( incmap ): if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ]) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ]) return { \"norm\" : norm , \"cmap\" : cmap } serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) valorizeColor def valorizeColor ( clmap , color ) View Source def valorizeColor ( clmap , color ) : c = ColorConverter () try : colframe = DataFrame ( [ c.to_rgb(x[1 ] ) for x in clmap ] ) except ValueError as e : colframe = DataFrame ( [ x[1 ] for x in clmap ] ) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns =[ 'r','g','b' ] colframe [ 'values' ] = [ x[0 ] for x in clmap ] colors = colframe [ ['r','g','b' ] ] . values colframe = colframe . set_index ( [ 'r','g','b' ] ) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ( [ color ] , columns =[ 'r','g','b' ] ) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ). values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan FTPPath class FTPPath ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention View Source class FTPPath ( fields . String ): \"\"\" Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) GeoJsonField class GeoJsonField ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) A string field. :param kwargs: The same keyword arguments that :class: Field receives. View Source class GeoJsonField ( fields . String ): def _deserialize ( self , value , attr , data , ** kwargs ): if isinstance ( value , list ): value = \",\" . join ( value ) try: if value is None or value == \"\" : return None return geojson . loads ( value ) except Exception as e: raise ValueError ( e ) Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) JsonValidable class JsonValidable ( schema ) JSON Validator class. It is initailzed with a marshmallow.Schema instance. When call function is invoked, uses marshmallow facilities to validate the json and raise errors. Once initalized, changes doc in order to descibe the json accepted. View Source class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ) : required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field.__class__ ] ) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[{f}]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \"{{{kf},{vf}}}\" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ) : flds = [] for n , f in self . schema . fields . items () : types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds . append ( f \"**{n}**{required}{allow_none}: {types}\" ) flds . append ( f \"**{n}**: {types}\" ) fields = \", \" . join ( flds ) fields = f \"{{{fields}}}\" if self . schema . many : fields = f \"[{fields}]\" return f \"JSON Schema {fields}\" def __init__ ( self , schema ) : self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items () : try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k )) [ 0 ] ) except KeyError : self . TYPE_MAPPING [ w ] = [ findall(r\"'(.*)'\", str(k))[0 ] ] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ) : if type ( value ) is list : # If Falcon is set to comma - separate entries , this segment joins them again . fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value ) LocalFile class LocalFile ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention View Source class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) LoggerHeader class LoggerHeader ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Logger Header manager View Source class LoggerHeader ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String (), #Raw_mu fields . String (), #Ing_mu fields . String (), #Signal_cond fields . List ( fields . Number ()) #Poly coeff ) ),** kwargs ): super (). __init__ ( cls_or_instance = cls_or_instance ,** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try: return json . loads ( value ) except Exception as e: raise ValueError ( e ) Ancestors (in MRO) marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) ParamsDefinition class ParamsDefinition ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Logger Header manager View Source class ParamsDefinition ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String () #Ing_mu ) ),** kwargs ): super (). __init__ ( cls_or_instance = cls_or_instance ,** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try: return json . loads ( value ) except Exception as e: raise ValueError ( e ) Ancestors (in MRO) marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) ResponseFormatter class ResponseFormatter ( status = '200 OK' , message = '' , data = '' ) View Source class ResponseFormatter (): def parse_status ( status ): try: if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else: return \"error\" except ValueError: return \"error\" def __init__ ( self , status = HTTP_OK , message = \"\" , data = \"\" ): self . status = status self . message = message self . data = data def format ( self , response:Response , request:Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \"{request.method} {request.path}\" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response Methods format def format ( self , response : falcon . response . Response , request : falcon . request . Request = None ) View Source def format ( self , response : Response , request : Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \"{request.method} {request.path}\" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response parse_status def parse_status ( status ) View Source def parse_status ( status ): try : if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else : return \"error\" except ValueError : return \"error\" Selection class Selection ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Provides python object which pertims selection on narry. It axcept a three filed string separated by \",\". \",\" presence is managed as: \"start,stop,step\" ie.: \"start,stop\" - extracts from start to stop \"start,\" - extracts from start to max \"start\" - extract exactly start View Source class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \" , \". \" , \" presence is managed as: \" start , stop , step \" ie.: \" start , stop \" - extracts from start to stop \" start , \" - extracts from start to max \" start \" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try: if isinstance ( value , list ): value = \";\" . join ( value ) if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice (* value [ 0 : 3 ]) #return value[0:3] except Exception as e: raise ValueError ( e ) Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) Style class Style ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) View Source class Style ( fields . String ): \"\"\" \"\"\" pass Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"Utils"},{"location":"reference/hielen3/utils/#module-hielen3utils","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 #!/usr/bin/env python # coding=utf-8 from datetime import datetime from re import split , sub , findall from time import mktime import json from importlib import import_module from falcon import HTTPNotAcceptable , HTTP_OK , Response , Request from hashlib import md5 from marshmallow import Schema , fields import geojson from pandas import DataFrame from numpy import datetime64 , isnat , array , sqrt , sum , where , amin , nan , round from matplotlib.colors import ColorConverter , Normalize , LinearSegmentedColormap , BoundaryNorm from collections.abc import Iterable from uuid import uuid4 def uuid (): return str ( uuid4 ()) def hug_output_format_conten_type ( handlers = [], error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ): \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ): try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items (): if par . split ( \";\" )[ 0 ] == k . split ( \";\" )[ 0 ]: handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0} \" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type def newinstanceof ( klass , * args , ** kwargs ): klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [: - 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , ** kwargs ) def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" try : dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , str ( t ))))) out = int ( mktime ( dt . timetuple ())) except Exception as e : print ( e , t ) return out def agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception : t = None return t def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f ' { h } ' . encode () ) . hexdigest () def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () ### MARSHMALLOW def getSchemaDict ( schema ): out = { \"fields\" :{}, \"required\" :[], \"hints\" : schema . hints } for k , w in schema . dump_fields . items (): out [ 'fields' ][ k ] = w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out class Style ( fields . String ): \"\"\" \"\"\" pass class FTPPath ( fields . String ): \"\"\" Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass class LoggerHeader ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String (), #Raw_mu fields . String (), #Ing_mu fields . String (), #Signal_cond fields . List ( fields . Number ()) #Poly coeff ) ), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return json . loads ( value ) except Exception as e : raise ValueError ( e ) class ParamsDefinition ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String () #Ing_mu ) ), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return json . loads ( value ) except Exception as e : raise ValueError ( e ) class ColorMap ( fields . List ): \"\"\" Colormap manager used to identify a colormap \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple (( fields . String (), fields . Number ())), ** kwargs ): super () . __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try : return ColorMap . make_colormap ( json . loads ( value )) except Exception as e : try : assert value [ 'f_cmap' ] return value except Exception as e : raise ValueError ( e ) def valorizeColor ( clmap , color ): c = ColorConverter () try : colframe = DataFrame ([ c . to_rgb ( x [ 1 ]) for x in clmap ]) except ValueError as e : colframe = DataFrame ([ x [ 1 ] for x in clmap ]) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns = [ 'r' , 'g' , 'b' ] colframe [ 'values' ] = [ x [ 0 ] for x in clmap ] colors = colframe [[ 'r' , 'g' , 'b' ]] . values colframe = colframe . set_index ([ 'r' , 'g' , 'b' ]) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ([ color ], columns = [ 'r' , 'g' , 'b' ]) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) . values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan def parse_colormap ( incmap ): if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ]) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ]) return { \"norm\" : norm , \"cmap\" : cmap } def make_colormap ( incmap = None ): if incmap is None : incmap = [[ - 0.25 , \"#FF0000\" ],[ 0 , \"#00FF00\" ],[ 0.25 , \"#0000FF\" ]] a = DataFrame ( incmap , columns = [ \"values\" , \"colors\" ]) . sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ], \"vmax\" : a [ \"values\" ] . iloc [ a . shape [ 0 ] - 1 ]}} n = Normalize ( ** out [ \"norm\" ]) a [ \"values\" ] = round ( a [ \"values\" ], 3 ) a [ \"idx\" ] = n ( a [ \"values\" ]) * 100 cc = a [[ \"idx\" , \"colors\" ]] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()): if i == 0 or i == cc . __len__ (): seq . append ( c . to_rgb ( cc [ i ][ 1 ])) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ])) seq . append ( cc [ i ][ 0 ] / 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ])) seq = [( None ,) * 3 , 0.0 ] + list ( seq ) + [ 1.0 , ( None ,) * 3 ] linsegcmap = { 'red' : [], 'green' : [], 'blue' : []} for i , item in enumerate ( seq ): if isinstance ( item , float ): r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ([ item , r1 , r2 ]) linsegcmap [ 'green' ] . append ([ item , g1 , g2 ]) linsegcmap [ 'blue' ] . append ([ item , b1 , b2 ]) out [ \"f_cmap\" ] = a . values . tolist () out [ \"b_cmap\" ] = linsegcmap return out class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \",\". \",\" presence is managed as: \"start,stop,step\" ie.: \"start,stop\" - extracts from start to stop \"start,\" - extracts from start to max \"start\" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try : if isinstance ( value , list ): value = \";\" . join ( value ) if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice ( * value [ 0 : 3 ]) #return value[0:3] except Exception as e : raise ValueError ( e ) class GeoJsonField ( fields . String ): def _deserialize ( self , value , attr , data , ** kwargs ): if isinstance ( value , list ): value = \",\" . join ( value ) try : if value is None or value == \"\" : return None return geojson . loads ( value ) except Exception as e : raise ValueError ( e ) class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ): required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field . __class__ ]) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[ { f } ]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \" {{ { kf } , { vf } }} \" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ): flds = [] for n , f in self . schema . fields . items (): types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds.append( f\"**{n}**{required}{allow_none}: {types}\") flds . append ( f \"** { n } **: { types } \" ) fields = \", \" . join ( flds ) fields = f \" {{ { fields } }} \" if self . schema . many : fields = f \"[ { fields } ]\" return f \"JSON Schema { fields } \" def __init__ ( self , schema ): self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items (): try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k ))[ 0 ]) except KeyError : self . TYPE_MAPPING [ w ] = [ findall ( r \"'(.*)'\" , str ( k ))[ 0 ]] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ): if type ( value ) is list : # If Falcon is set to comma-separate entries, this segment joins them again. fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value ) class ResponseFormatter (): def parse_status ( status ): try : if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else : return \"error\" except ValueError : return \"error\" def __init__ ( self , status = HTTP_OK , message = \"\" , data = \"\" ): self . status = status self . message = message self . data = data def format ( self , response : Response , request : Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \" { request . method } { request . path } \" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response","title":"Module hielen3.utils"},{"location":"reference/hielen3/utils/#variables","text":"HTTP_OK isnat nan sqrt","title":"Variables"},{"location":"reference/hielen3/utils/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/utils/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen3/utils/#eprint","text":"def eprint ( * args , fname = 'error' , ** kwargs ) View Source def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs )","title":"eprint"},{"location":"reference/hielen3/utils/#getschemadict","text":"def getSchemaDict ( schema ) View Source def getSchemaDict ( schema ) : out = { \"fields\" :{} , \"required\" :[] , \"hints\" : schema . hints } for k , w in schema . dump_fields . items () : out [ 'fields' ][ k ]= w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out","title":"getSchemaDict"},{"location":"reference/hielen3/utils/#hasher","text":"def hasher ( * args , ** kwargs ) View Source def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f '{h}' . encode () ). hexdigest ()","title":"hasher"},{"location":"reference/hielen3/utils/#hashfile","text":"def hashfile ( filename ) View Source def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest ()","title":"hashfile"},{"location":"reference/hielen3/utils/#hug_output_format_conten_type","text":"def hug_output_format_conten_type ( handlers = [], error = 'The requested format does not match any of those allowed' , ctpar = 'content_type' ) Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised View Source def hug_output_format_conten_type ( handlers = [] , error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ) : \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ) : try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items () : if par . split ( \";\" ) [ 0 ] == k . split ( \";\" ) [ 0 ] : handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ) : handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0}\" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type","title":"hug_output_format_conten_type"},{"location":"reference/hielen3/utils/#isot2ut","text":"def isot2ut ( t = None ) View Source def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" try : dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , str ( t ))))) out = int ( mktime ( dt . timetuple ())) except Exception as e : print ( e , t ) return out","title":"isot2ut"},{"location":"reference/hielen3/utils/#loadjsonfile","text":"def loadjsonfile ( filename ) View Source def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf )","title":"loadjsonfile"},{"location":"reference/hielen3/utils/#newinstanceof","text":"def newinstanceof ( klass , * args , ** kwargs ) View Source def newinstanceof ( klass , * args , **kwargs ) : klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [:- 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , **kwargs )","title":"newinstanceof"},{"location":"reference/hielen3/utils/#savejsonfile","text":"def savejsonfile ( filename , struct ) View Source def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf )","title":"savejsonfile"},{"location":"reference/hielen3/utils/#ut2isot","text":"def ut2isot ( u = None ) View Source def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u ))","title":"ut2isot"},{"location":"reference/hielen3/utils/#uuid","text":"def uuid ( ) View Source def uuid (): return str ( uuid4 ())","title":"uuid"},{"location":"reference/hielen3/utils/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/utils/#colormap","text":"class ColorMap ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Colormap manager used to identify a colormap View Source class ColorMap ( fields . List ) : \"\"\" Colormap manager used to identify a colormap \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple (( fields . String (), fields . Number ())), ** kwargs ) : super (). __init__ ( cls_or_instance = cls_or_instance , ** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ) : try : return ColorMap . make_colormap ( json . loads ( value )) except Exception as e : try : assert value [ 'f_cmap' ] return value except Exception as e : raise ValueError ( e ) def valorizeColor ( clmap , color ) : c = ColorConverter () try : colframe = DataFrame ( [ c.to_rgb(x[1 ] ) for x in clmap ] ) except ValueError as e : colframe = DataFrame ( [ x[1 ] for x in clmap ] ) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns =[ 'r','g','b' ] colframe [ 'values' ] = [ x[0 ] for x in clmap ] colors = colframe [ ['r','g','b' ] ] . values colframe = colframe . set_index ( [ 'r','g','b' ] ) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ( [ color ] , columns =[ 'r','g','b' ] ) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ). values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan def parse_colormap ( incmap ) : if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ] ) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ] ) return { \"norm\" : norm , \"cmap\" : cmap } def make_colormap ( incmap = None ) : if incmap is None : incmap =[ [-0.25,\"#FF0000\" ] , [ 0,\"#00FF00\" ] , [ 0.25,\"#0000FF\" ] ] a = DataFrame ( incmap , columns =[ \"values\",\"colors\" ] ). sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ] , \"vmax\" : a [ \"values\" ] . iloc [ a.shape[0 ]- 1 ]}} n = Normalize ( ** out [ \"norm\" ] ) a [ \"values\" ]= round ( a [ \"values\" ] , 3 ) a [ \"idx\" ]= n ( a [ \"values\" ] ) * 100 cc = a [ [\"idx\",\"colors\" ] ] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()) : if i == 0 or i == cc . __len__ () : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq . append ( cc [ i ][ 0 ]/ 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq = [ (None,) * 3, 0.0 ] + list ( seq ) + [ 1.0, (None,) * 3 ] linsegcmap = { 'red' : [] , 'green' : [] , 'blue' : []} for i , item in enumerate ( seq ) : if isinstance ( item , float ) : r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ( [ item, r1, r2 ] ) linsegcmap [ 'green' ] . append ( [ item, g1, g2 ] ) linsegcmap [ 'blue' ] . append ( [ item, b1, b2 ] ) out [ \"f_cmap\" ]= a . values . tolist () out [ \"b_cmap\" ]= linsegcmap return out","title":"ColorMap"},{"location":"reference/hielen3/utils/#ancestors-in-mro","text":"marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_colormap","text":"def make_colormap ( incmap = None ) View Source def make_colormap ( incmap = None ) : if incmap is None : incmap =[ [-0.25,\"#FF0000\" ] , [ 0,\"#00FF00\" ] , [ 0.25,\"#0000FF\" ] ] a = DataFrame ( incmap , columns =[ \"values\",\"colors\" ] ). sort_values ( \"values\" ) out = { \"norm\" :{ \"vmin\" : a [ \"values\" ][ 0 ] , \"vmax\" : a [ \"values\" ] . iloc [ a.shape[0 ]- 1 ]}} n = Normalize ( ** out [ \"norm\" ] ) a [ \"values\" ]= round ( a [ \"values\" ] , 3 ) a [ \"idx\" ]= n ( a [ \"values\" ] ) * 100 cc = a [ [\"idx\",\"colors\" ] ] . values seq = [] c = ColorConverter () for i in range ( cc . __len__ ()) : if i == 0 or i == cc . __len__ () : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) else : seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq . append ( cc [ i ][ 0 ]/ 100 ) seq . append ( c . to_rgb ( cc [ i ][ 1 ] )) seq = [ (None,) * 3, 0.0 ] + list ( seq ) + [ 1.0, (None,) * 3 ] linsegcmap = { 'red' : [] , 'green' : [] , 'blue' : []} for i , item in enumerate ( seq ) : if isinstance ( item , float ) : r1 , g1 , b1 = seq [ i - 1 ] r2 , g2 , b2 = seq [ i + 1 ] linsegcmap [ 'red' ] . append ( [ item, r1, r2 ] ) linsegcmap [ 'green' ] . append ( [ item, g1, g2 ] ) linsegcmap [ 'blue' ] . append ( [ item, b1, b2 ] ) out [ \"f_cmap\" ]= a . values . tolist () out [ \"b_cmap\" ]= linsegcmap return out","title":"make_colormap"},{"location":"reference/hielen3/utils/#make_error","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#parse_colormap","text":"def parse_colormap ( incmap ) View Source def parse_colormap ( incmap ): if incmap is None : return ColorMap . parse_colormap ( ColorMap . make_colormap ()) try : norm = Normalize ( ** incmap [ \"norm\" ]) norm . clip = True except Exception : norm = None cmap = LinearSegmentedColormap ( 'CustomMap' , incmap [ 'b_cmap' ]) return { \"norm\" : norm , \"cmap\" : cmap }","title":"parse_colormap"},{"location":"reference/hielen3/utils/#serialize","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#valorizecolor","text":"def valorizeColor ( clmap , color ) View Source def valorizeColor ( clmap , color ) : c = ColorConverter () try : colframe = DataFrame ( [ c.to_rgb(x[1 ] ) for x in clmap ] ) except ValueError as e : colframe = DataFrame ( [ x[1 ] for x in clmap ] ) colframe = colframe / 255 colframe = colframe . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ) colframe . columns =[ 'r','g','b' ] colframe [ 'values' ] = [ x[0 ] for x in clmap ] colors = colframe [ ['r','g','b' ] ] . values colframe = colframe . set_index ( [ 'r','g','b' ] ) color = array ( color ) try : color = array ( c . to_rgb ( color )) except ValueError as e : color = DataFrame ( [ color ] , columns =[ 'r','g','b' ] ) / 255 color = color . apply ( c . to_rgb , axis = 1 , result_type = 'expand' ). values distances = sqrt ( sum (( colors - color ) ** 2 , axis = 1 )) index_of_smallest = where ( distances == amin ( distances )) try : return float ( colframe [ 'values' ] . iloc [ index_of_smallest ] . squeeze ()) except Exception as e : return nan","title":"valorizeColor"},{"location":"reference/hielen3/utils/#ftppath","text":"class FTPPath ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention View Source class FTPPath ( fields . String ): \"\"\" Local FTP Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass","title":"FTPPath"},{"location":"reference/hielen3/utils/#ancestors-in-mro_1","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_1","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_1","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_1","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_1","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_1","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_1","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_1","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#geojsonfield","text":"class GeoJsonField ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) A string field. :param kwargs: The same keyword arguments that :class: Field receives. View Source class GeoJsonField ( fields . String ): def _deserialize ( self , value , attr , data , ** kwargs ): if isinstance ( value , list ): value = \",\" . join ( value ) try: if value is None or value == \"\" : return None return geojson . loads ( value ) except Exception as e: raise ValueError ( e )","title":"GeoJsonField"},{"location":"reference/hielen3/utils/#ancestors-in-mro_2","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_2","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_2","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_2","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_2","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_2","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_2","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_2","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#jsonvalidable","text":"class JsonValidable ( schema ) JSON Validator class. It is initailzed with a marshmallow.Schema instance. When call function is invoked, uses marshmallow facilities to validate the json and raise errors. Once initalized, changes doc in order to descibe the json accepted. View Source class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ) : required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field.__class__ ] ) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[{f}]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \"{{{kf},{vf}}}\" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ) : flds = [] for n , f in self . schema . fields . items () : types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds . append ( f \"**{n}**{required}{allow_none}: {types}\" ) flds . append ( f \"**{n}**: {types}\" ) fields = \", \" . join ( flds ) fields = f \"{{{fields}}}\" if self . schema . many : fields = f \"[{fields}]\" return f \"JSON Schema {fields}\" def __init__ ( self , schema ) : self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items () : try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k )) [ 0 ] ) except KeyError : self . TYPE_MAPPING [ w ] = [ findall(r\"'(.*)'\", str(k))[0 ] ] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ) : if type ( value ) is list : # If Falcon is set to comma - separate entries , this segment joins them again . fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value )","title":"JsonValidable"},{"location":"reference/hielen3/utils/#localfile","text":"class LocalFile ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention View Source class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen3.HielenSource extention \"\"\" pass","title":"LocalFile"},{"location":"reference/hielen3/utils/#ancestors-in-mro_3","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_3","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_3","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_3","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_3","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_3","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_3","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_3","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_3","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#loggerheader","text":"class LoggerHeader ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Logger Header manager View Source class LoggerHeader ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String (), #Raw_mu fields . String (), #Ing_mu fields . String (), #Signal_cond fields . List ( fields . Number ()) #Poly coeff ) ),** kwargs ): super (). __init__ ( cls_or_instance = cls_or_instance ,** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try: return json . loads ( value ) except Exception as e: raise ValueError ( e )","title":"LoggerHeader"},{"location":"reference/hielen3/utils/#ancestors-in-mro_4","text":"marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_4","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_4","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_4","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_4","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_4","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_4","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_4","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_4","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#paramsdefinition","text":"class ParamsDefinition ( cls_or_instance =< fields . Tuple ( default =< marshmallow . missing > , attribute = None , validate = None , required = False , load_only = False , dump_only = False , missing =< marshmallow . missing > , allow_none = False , error_messages = { 'required' : 'Missing data for required field.' , 'null' : 'Field may not be null.' , 'validator_failed' : 'Invalid value.' , 'invalid' : 'Not a valid tuple.' }) > , ** kwargs ) Logger Header manager View Source class ParamsDefinition ( fields . List ): \"\"\" Logger Header manager \"\"\" def __init__ ( self , cls_or_instance = fields . Tuple ( ( fields . String (), #Param fields . Integer (), #Column fields . String () #Ing_mu ) ),** kwargs ): super (). __init__ ( cls_or_instance = cls_or_instance ,** kwargs ) def _deserialize ( self , value , attr , data , ** kwargs ): try: return json . loads ( value ) except Exception as e: raise ValueError ( e )","title":"ParamsDefinition"},{"location":"reference/hielen3/utils/#ancestors-in-mro_5","text":"marshmallow.fields.List marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_5","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_5","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_5","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_5","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_5","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_5","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_5","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_5","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#responseformatter","text":"class ResponseFormatter ( status = '200 OK' , message = '' , data = '' ) View Source class ResponseFormatter (): def parse_status ( status ): try: if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else: return \"error\" except ValueError: return \"error\" def __init__ ( self , status = HTTP_OK , message = \"\" , data = \"\" ): self . status = status self . message = message self . data = data def format ( self , response:Response , request:Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \"{request.method} {request.path}\" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response","title":"ResponseFormatter"},{"location":"reference/hielen3/utils/#methods_6","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#format","text":"def format ( self , response : falcon . response . Response , request : falcon . request . Request = None ) View Source def format ( self , response : Response , request : Request = None ): body = dict ( meta = dict ( response = ResponseFormatter . parse_status ( self . status ), message = isinstance ( self . message , Iterable ) and self . message . __len__ () == 1 and self . message [ 0 ] or self . message , data_type = request and f \"{request.method} {request.path}\" or \"\" , ), data = self . data ) response . status = self . status response . body = json . dumps ( body ) return response","title":"format"},{"location":"reference/hielen3/utils/#parse_status","text":"def parse_status ( status ) View Source def parse_status ( status ): try : if int ( status . rsplit ( \" \" )[ 0 ]) < 400 : return \"ok\" else : return \"error\" except ValueError : return \"error\"","title":"parse_status"},{"location":"reference/hielen3/utils/#selection","text":"class Selection ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Provides python object which pertims selection on narry. It axcept a three filed string separated by \",\". \",\" presence is managed as: \"start,stop,step\" ie.: \"start,stop\" - extracts from start to stop \"start,\" - extracts from start to max \"start\" - extract exactly start View Source class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \" , \". \" , \" presence is managed as: \" start , stop , step \" ie.: \" start , stop \" - extracts from start to stop \" start , \" - extracts from start to max \" start \" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try: if isinstance ( value , list ): value = \";\" . join ( value ) if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice (* value [ 0 : 3 ]) #return value[0:3] except Exception as e: raise ValueError ( e )","title":"Selection"},{"location":"reference/hielen3/utils/#ancestors-in-mro_6","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_6","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_6","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_7","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_6","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_6","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_6","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_6","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_6","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/utils/#style","text":"class Style ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) View Source class Style ( fields . String ): \"\"\" \"\"\" pass","title":"Style"},{"location":"reference/hielen3/utils/#ancestors-in-mro_7","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/utils/#class-variables_7","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen3/utils/#instance-variables_7","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen3/utils/#methods_8","text":"","title":"Methods"},{"location":"reference/hielen3/utils/#deserialize_7","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen3/utils/#fail_7","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen3/utils/#get_value_7","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen3/utils/#make_error_7","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen3/utils/#serialize_7","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen3/api/","text":"Module hielen3.api Sub-modules hielen3.api.actions hielen3.api.actionschemata hielen3.api.features hielen3.api.glob hielen3.api.prototypes hielen3.api.query","title":"Index"},{"location":"reference/hielen3/api/#module-hielen3api","text":"","title":"Module hielen3.api"},{"location":"reference/hielen3/api/#sub-modules","text":"hielen3.api.actions hielen3.api.actionschemata hielen3.api.features hielen3.api.glob hielen3.api.prototypes hielen3.api.query","title":"Sub-modules"},{"location":"reference/hielen3/api/actions/","text":"Module hielen3.api.actions View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 #!/usr/bin/env python # coding=utf-8 import hug import tempfile import falcon import os import time import json from hielen3 import db , conf import hielen3.source as sourceman from hielen3.utils import ResponseFormatter from streaming_form_data import StreamingFormDataParser from streaming_form_data.targets import FileTarget , ValueTarget from urllib.parse import unquote from importlib import import_module from pathlib import Path , PosixPath import traceback @hug . get ( \"/ {feature} \" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] ___nota 3___ :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . get ( \"/ {feature} / {action} \" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) @hug . delete ( \"/ {feature} / {action} \" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ): \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . post ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ): for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os.path.exists(w) and str(w) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ], v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema [ \"required\" ] if kwargs [ m ] is None ] if m . __len__ (): out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters { m } not supplied\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return @hug . put ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def update_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ): for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os.path.exists(w) and str(w) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ], v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . updateAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = None except Exception : pass try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return Variables conf db Functions feature_action_delete def feature_action_delete ( feature , action , timestamp , request = None , response = None ) Eliminazione di una determinata azione di una specifica feature View Source @hug . delete ( \"/{feature}/{action}\" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ) : \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return feature_action_values def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) Recupero dello stato corrente per una specifica azione di una specifica feature View Source @hug . get ( \"/{feature}/{action}\" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) : \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) features_actions_values def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ) Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione View Source @ hug . get ( \"/{feature}\" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, ... ] ___nota 3___ :(*) I campi \" feature \" e \" action \" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \" timestamp \" e \" value \" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return make_action def make_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . post ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ) : for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os . path . exists ( w ) and str ( w ) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ] , v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema[\"required\" ] if kwargs [ m ] is None ] if m . __len__ () : out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters {m} not supplied\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return update_action def update_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . put ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def update_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ) : for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os . path . exists ( w ) and str ( w ) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ] , v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . updateAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = None except Exception : pass try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return","title":"Actions"},{"location":"reference/hielen3/api/actions/#module-hielen3apiactions","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 #!/usr/bin/env python # coding=utf-8 import hug import tempfile import falcon import os import time import json from hielen3 import db , conf import hielen3.source as sourceman from hielen3.utils import ResponseFormatter from streaming_form_data import StreamingFormDataParser from streaming_form_data.targets import FileTarget , ValueTarget from urllib.parse import unquote from importlib import import_module from pathlib import Path , PosixPath import traceback @hug . get ( \"/ {feature} \" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] ___nota 3___ :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . get ( \"/ {feature} / {action} \" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) @hug . delete ( \"/ {feature} / {action} \" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ): \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . post ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ): for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os.path.exists(w) and str(w) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ], v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema [ \"required\" ] if kwargs [ m ] is None ] if m . __len__ (): out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters { m } not supplied\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return @hug . put ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def update_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ): for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os.path.exists(w) and str(w) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ], v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . updateAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = None except Exception : pass try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return","title":"Module hielen3.api.actions"},{"location":"reference/hielen3/api/actions/#variables","text":"conf db","title":"Variables"},{"location":"reference/hielen3/api/actions/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/actions/#feature_action_delete","text":"def feature_action_delete ( feature , action , timestamp , request = None , response = None ) Eliminazione di una determinata azione di una specifica feature View Source @hug . delete ( \"/{feature}/{action}\" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ) : \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"feature_action_delete"},{"location":"reference/hielen3/api/actions/#feature_action_values","text":"def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) Recupero dello stato corrente per una specifica azione di una specifica feature View Source @hug . get ( \"/{feature}/{action}\" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) : \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response )","title":"feature_action_values"},{"location":"reference/hielen3/api/actions/#features_actions_values","text":"def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ) Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione View Source @ hug . get ( \"/{feature}\" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, ... ] ___nota 3___ :(*) I campi \" feature \" e \" action \" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \" timestamp \" e \" value \" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"features_actions_values"},{"location":"reference/hielen3/api/actions/#make_action","text":"def make_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . post ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ) : for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os . path . exists ( w ) and str ( w ) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ] , v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema[\"required\" ] if kwargs [ m ] is None ] if m . __len__ () : out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters {m} not supplied\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return","title":"make_action"},{"location":"reference/hielen3/api/actions/#update_action","text":"def update_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . put ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def update_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} toremove = [] # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath toremove . append ( filepath ) else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target def removetempfiles ( toremove ) : for v in toremove : try : os . unlink ( v ) except FileNotFoundError as e : pass while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : model = schema [ \"fields\" ][ k ] if model == \"LocalFile\" : #v = os . path . exists ( w ) and str ( w ) or None v = str ( w ) elif model == \"FTPPath\" : v = unquote ( w . value . decode ( \"utf8\" )) or None if v is not None : v = str ( Path ( conf [ 'ftproot' ] , v )) else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . updateAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return except Exception as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) removetempfiles ( toremove ) return try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = None except Exception : pass try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } out . format ( request = request , response = response ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) removetempfiles ( toremove ) return","title":"update_action"},{"location":"reference/hielen3/api/actionschemata/","text":"Module hielen3.api.actionschemata View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db , source from hielen3.utils import ResponseFormatter @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ): \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions = [ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ): protos = [ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ] = {} for a in [ act for act in source . moduleActions ( uid ) if actions is None or act in actions ]: out . data [ uid ][ a ] = source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) @hug . get ( \"/ {prototype} / {action} \" ) def get_proto_schema ( prototype , action , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response ) Variables db Functions get_proto_schema def get_proto_schema ( prototype , action , request = None , response = None ) Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo View Source @hug . get ( \"/{prototype}/{action}\" ) def get_proto_schema ( prototype , action , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response ) get_proto_schemata def get_proto_schemata ( prototype , actions = None , request = None , response = None ) Alias per il recupero di tutte le informazioni di uno specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) get_protos_schemata def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, View Source @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) : \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \" NomePrototipo1 \": { \" action1 \": { \" args \": { \" arg1 .1 \": \" type_arg1 .1 \", \" arg1 .2 \": \" type_arg1 .2 \", ... }, \" mandatory \": [ args keys sublist ] }, \" action2 \": { \" args \": { \" arg2 .1 \": \" type_arg2 .1 \", \" arg2 .2 \": \" type_arg2 .2 \", ... }, }, ... }, \" NomePrototipo3 \": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions =[ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ) : protos =[ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ]= {} for a in [ act for act in source.moduleActions(uid) if actions is None or act in actions ] : out . data [ uid ][ a ]= source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request )","title":"Actionschemata"},{"location":"reference/hielen3/api/actionschemata/#module-hielen3apiactionschemata","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db , source from hielen3.utils import ResponseFormatter @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ): \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions = [ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ): protos = [ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ] = {} for a in [ act for act in source . moduleActions ( uid ) if actions is None or act in actions ]: out . data [ uid ][ a ] = source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) @hug . get ( \"/ {prototype} / {action} \" ) def get_proto_schema ( prototype , action , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response )","title":"Module hielen3.api.actionschemata"},{"location":"reference/hielen3/api/actionschemata/#variables","text":"db","title":"Variables"},{"location":"reference/hielen3/api/actionschemata/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/actionschemata/#get_proto_schema","text":"def get_proto_schema ( prototype , action , request = None , response = None ) Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo View Source @hug . get ( \"/{prototype}/{action}\" ) def get_proto_schema ( prototype , action , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response )","title":"get_proto_schema"},{"location":"reference/hielen3/api/actionschemata/#get_proto_schemata","text":"def get_proto_schemata ( prototype , actions = None , request = None , response = None ) Alias per il recupero di tutte le informazioni di uno specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response )","title":"get_proto_schemata"},{"location":"reference/hielen3/api/actionschemata/#get_protos_schemata","text":"def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, View Source @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) : \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \" NomePrototipo1 \": { \" action1 \": { \" args \": { \" arg1 .1 \": \" type_arg1 .1 \", \" arg1 .2 \": \" type_arg1 .2 \", ... }, \" mandatory \": [ args keys sublist ] }, \" action2 \": { \" args \": { \" arg2 .1 \": \" type_arg2 .1 \", \" arg2 .2 \": \" type_arg2 .2 \", ... }, }, ... }, \" NomePrototipo3 \": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions =[ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ) : protos =[ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ]= {} for a in [ act for act in source.moduleActions(uid) if actions is None or act in actions ] : out . data [ uid ][ a ]= source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request )","title":"get_protos_schemata"},{"location":"reference/hielen3/api/features/","text":"Module hielen3.api.features View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db from hielen3.utils import JsonValidable , hasher , ResponseFormatter , uuid import hielen3.source as sourceman from marshmallow import Schema , fields from marshmallow_geojson import GeoJSONSchema import traceback class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) def mkpmaponthefly ( geometry ): try : lon = geometry [ 'coordinates' ][ 0 ] lat = geometry [ 'coordinates' ][ 1 ] span = 0.005 maptempl = { \"extent\" : { \"minlon\" : min ( lon - span , lon + span ), \"minlat\" : min ( lat - span , lat + span ), \"maxlon\" : max ( lon - span , lon + span ), \"maxlat\" : max ( lat - span , lat + span ) }, \"center\" : { \"lon\" : lon , \"lat\" : lat }, \"zoom\" : { \"default\" : 14 }, \"basemapurl\" : None , \"geographic\" : True , \"features\" : None } except Exception as e : raise e return None return maptempl @hug . post ( \"/\" ) def create_feature ( prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0 , 0 ]}, request = None , response = None , ): \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo il suo prototipo `prototype` ed in fase di creazione viene \\ creato il campo `uid`. Questi due campi sono immutabli (vedi PUT `/feature/{uid}`). \\ Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" uid = uuid () out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ] = feature_info . pop ( \"classification\" ) try : feature [ \"inmap\" ] = feature_info . pop ( \"inmap\" ) except Exception as e : feature [ \"inmap\" ] = None db [ \"features\" ][ uid ] = feature feature_info [ \"geometry\" ] = geometry feature_info . update ({ \"data\" : None , \"map\" : None , \"cloud\" : None }) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ) . items (): try : struct [ 'operands' ][ k ] = eval ( w . replace ( '{{new}}' , 'feature' )) except AttributeError as e : struct [ 'operands' ][ k ] = None db [ 'series' ][ suid ] = struct params [ param ] = suid feature_info [ \"parameters\" ] = params db [ \"features_info\" ][ uid ] = feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . message = f \"prototype ' { prototype } ' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : out . message = str ( e ) out . status = falcon . HTTP_CONFLICT try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info = [ \"geometry\" , \"capabilities\" ], request = None , response = None ): \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ): if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ): if info == \"\" : info = None else : info = [ info ] info . append ( \"capabilities\" ) if 'map' in info : info . append ( 'subitemsfrommap' ) try : # out.data = {\"features\":[]} out . data = { \"features\" :{}} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ): extract = [ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v [ 'uid' ]] subitems = { \"features\" :{}} for i in info : if i == 'parameters' : f [ i ] = [] try : for p , s in infos [ i ] . items (): if s is not None : try : cmap = db [ \"series\" ][ s ][ 'operands' ][ 'cmap' ][ 'f_cmap' ] cmap = [ [ round ( a [ 0 ], 3 ), a [ 1 ], a [ 2 ]] for a in cmap ] except Exception as e : cmap = None f [ i ] . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ], \"cmap\" : cmap }) except AttributeError as e : pass elif i in [ 'subitems' , 'subitemsfrommap' ]: try : if infos [ 'subitems' ] is not None : subitems = features_info ( infos [ 'subitems' ]) . data except Exception as e : subitems = { \"features\" :{}} elif i == 'map' : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None if f [ i ] is None : try : if 'map' in infos [ 'capabilities' ]: f [ i ] = mkpmaponthefly ( infos [ 'geometry' ]) except Exception as e : f [ i ] = None else : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None try : f [ 'map' ] . update ( subitems ) except Exception as e : pass if 'subitems' in info : try : f [ 'subitems' ] = subitems except Exception as e : f [ 'subitems' ] = { \"features\" :{}} try : if f [ 'properties' ][ 'inmap' ] == 'Y' : f [ 'properties' ][ 'inmap' ] = infos [ 'map' ][ 'basemapurl' ] else : f [ 'properties' ][ 'inmap' ] = None except Exception as e : f [ 'properties' ][ 'inmap' ] = None out . data [ 'features' ][ v [ 'uid' ]] = f except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . get ( \"/ {uid} \" ) def feature_info ( uid , cntxt = None , info = [ \"geometry\" , \"capabilities\" ], request = None , response = None ): \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) @hug . put ( \"/ {uid} \" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = {}, request = None , response = None , ): \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . delete ( \"/ {uid} \" ) def del_feature ( uid , request = None , response = None ): \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] subits = info [ 'subitems' ] if subits is not None : for v in info [ 'subitems' ]: try : del_feature ( v ) except Exception as e : pass for v in info [ 'parameters' ] . values (): if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ) . deleteActionValues () except Exception as e : #traceback.print_exc() pass try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : #traceback.print_exc() out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return Variables db Functions create_feature def create_feature ( prototype , properties : < hielen3 . utils . JsonValidable object at 0x7f951f5eac10 > = {}, geometry : < hielen3 . utils . JsonValidable object at 0x7f951f5eafd0 > = { 'type' : 'Point' , 'coordinates' : [ 0 , 0 ]}, request = None , response = None ) Creazione delle Features. Ogni feature deve avere il suo il suo prototipo prototype ed in fase di creazione viene creato il campo uid . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. View Source @hug . post ( \"/\" ) def create_feature ( prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0, 0 ] } , request = None , response = None , ) : \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo il suo prototipo `prototype` ed in fase di creazione viene \\ creato il campo `uid`. Questi due campi sono immutabli (vedi PUT `/feature/{uid}`). \\ Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" uid = uuid () out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ]= feature_info . pop ( \"classification\" ) try : feature [ \"inmap\" ]= feature_info . pop ( \"inmap\" ) except Exception as e : feature [ \"inmap\" ]= None db [ \"features\" ][ uid ]= feature feature_info [ \"geometry\" ] = geometry feature_info . update ( { \"data\" : None , \"map\" : None , \"cloud\" : None } ) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ). items () : try : struct [ 'operands' ][ k ]= eval ( w . replace ( '{{new}}' , 'feature' )) except AttributeError as e : struct [ 'operands' ][ k ] = None db [ 'series' ][ suid ]= struct params [ param ]= suid feature_info [ \"parameters\" ]= params db [ \"features_info\" ][ uid ]= feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . message = f \"prototype '{prototype}' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : out . message = str ( e ) out . status = falcon . HTTP_CONFLICT try : response = out . format ( response = response , request = request ) except Exception as e : return out return del_feature def del_feature ( uid , request = None , response = None ) Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente. View Source @hug . delete ( \"/{uid}\" ) def del_feature ( uid , request = None , response = None ) : \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] subits = info [ 'subitems' ] if subits is not None : for v in info [ 'subitems' ] : try : del_feature ( v ) except Exception as e : pass for v in info [ 'parameters' ] . values () : if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ). deleteActionValues () except Exception as e : #traceback . print_exc () pass try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : #traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return feature_info def feature_info ( uid , cntxt = None , info = [ 'geometry' , 'capabilities' ], request = None , response = None ) Alias di recupero informazioni della specifica feature View Source @hug . get ( \"/{uid}\" ) def feature_info ( uid , cntxt = None , info =[ \"geometry\",\"capabilities\" ] , request = None , response = None ) : \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) features_info def features_info ( uids = None , cntxt = None , info = [ 'geometry' , 'capabilities' ], request = None , response = None ) Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri View Source @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info =[ \"geometry\",\"capabilities\" ] , request = None , response = None ) : \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituita una struttura \" data \" di questo tipo: { \" features \": [ { \" type \": \" Feature \", \" properties \": { ... }, \" geometry \": <GeoJson Validable> }, ... ] } Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ) : if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ) : if info == \"\" : info = None else : info = [ info ] info . append ( \"capabilities\" ) if 'map' in info : info . append ( 'subitemsfrommap' ) try : # out . data = { \"features\" :[]} out . data = { \"features\" :{}} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ) : extract =[ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v['uid' ] ] subitems = { \"features\" :{}} for i in info : if i == 'parameters' : f [ i ]= [] try : for p , s in infos [ i ] . items () : if s is not None : try : cmap = db [ \"series\" ][ s ][ 'operands' ][ 'cmap' ][ 'f_cmap' ] cmap =[ [round(a[0 ] , 3 ), a [ 1 ] , a [ 2 ] ] for a in cmap ] except Exception as e : cmap = None f [ i ] . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] , \"cmap\" : cmap } ) except AttributeError as e : pass elif i in [ 'subitems','subitemsfrommap' ] : try : if infos [ 'subitems' ] is not None : subitems = features_info ( infos [ 'subitems' ] ). data except Exception as e : subitems = { \"features\" :{}} elif i == 'map' : try : f [ i ]= infos [ i ] except Exception as e : f [ i ] = None if f [ i ] is None : try : if 'map' in infos [ 'capabilities' ] : f [ i ] = mkpmaponthefly ( infos [ 'geometry' ] ) except Exception as e : f [ i ] = None else : try : f [ i ]= infos [ i ] except Exception as e : f [ i ]= None try : f [ 'map' ] . update ( subitems ) except Exception as e : pass if 'subitems' in info : try : f [ 'subitems' ]= subitems except Exception as e : f [ 'subitems' ]= { \"features\" :{}} try : if f [ 'properties' ][ 'inmap' ] == 'Y' : f [ 'properties' ][ 'inmap' ]= infos [ 'map' ][ 'basemapurl' ] else : f [ 'properties' ][ 'inmap' ]= None except Exception as e : f [ 'properties' ][ 'inmap' ]= None out . data [ 'features' ][ v['uid' ] ] = f except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) try : response = out . format ( response = response , request = request ) except Exception as e : return out return mkpmaponthefly def mkpmaponthefly ( geometry ) View Source def mkpmaponthefly ( geometry ): try : lon = geometry [ 'coordinates' ][ 0 ] lat = geometry [ 'coordinates' ][ 1 ] span = 0 . 005 maptempl = { \"extent\" : { \"minlon\" : min ( lon - span , lon + span ), \"minlat\" : min ( lat - span , lat + span ), \"maxlon\" : max ( lon - span , lon + span ), \"maxlat\" : max ( lat - span , lat + span ) } , \"center\" : { \"lon\" : lon , \"lat\" : lat } , \"zoom\" : { \"default\" : 14 } , \"basemapurl\" : None , \"geographic\" : True , \"features\" : None } except Exception as e : raise e return None return maptempl update_feature def update_feature ( uid , properties : < hielen3 . utils . JsonValidable object at 0x7f951f5eae50 > = {}, geometry : < hielen3 . utils . JsonValidable object at 0x7f951f601310 > = {}, request = None , response = None ) Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. View Source @hug . put ( \"/{uid}\" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = {} , request = None , response = None , ) : \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return Classes FeaturePropertiesSchema class FeaturePropertiesSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Base schema class with which to define custom schemas. Example usage: .. code-block:: python import datetime as dt from dataclasses import dataclass from marshmallow import Schema , fields @dataclass class Album : title : str release_date : dt . date class AlbumSchema ( Schema ): title = fields . Str () release_date = fields . Date () album = Album ( \"Beggars Banquet\" , dt . date ( 1968 , 12 , 6 )) schema = AlbumSchema () data = schema . dump ( album ) data # {'release_date': '1968-12-06', 'title': 'Beggars Banquet'} :param only: Whitelist of the declared fields to select when instantiating the Schema. If None, all fields are used. Nested fields can be represented with dot delimiters. :param exclude: Blacklist of the declared fields to exclude when instantiating the Schema. If a field appears in both only and exclude , it is not used. Nested fields can be represented with dot delimiters. :param many: Should be set to True if obj is a collection so that the object will be serialized to a list. :param context: Optional context passed to :class: fields.Method and :class: fields.Function fields. :param load_only: Fields to skip during serialization (write-only fields) :param dump_only: Fields to skip during deserialization (read-only fields) :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . .. versionchanged:: 3.0.0 prefix parameter removed. .. versionchanged:: 2.0.0 __validators__ , __preprocessors__ , and __data_handlers__ are removed in favor of marshmallow.decorators.validates_schema , marshmallow.decorators.pre_load and marshmallow.decorators.post_dump . __accessor__ and __error_handler__ are deprecated. Implement the handle_error and get_attribute methods instead. View Source class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING context description error_messages label location opts status style timestamp Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"Features"},{"location":"reference/hielen3/api/features/#module-hielen3apifeatures","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db from hielen3.utils import JsonValidable , hasher , ResponseFormatter , uuid import hielen3.source as sourceman from marshmallow import Schema , fields from marshmallow_geojson import GeoJSONSchema import traceback class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) def mkpmaponthefly ( geometry ): try : lon = geometry [ 'coordinates' ][ 0 ] lat = geometry [ 'coordinates' ][ 1 ] span = 0.005 maptempl = { \"extent\" : { \"minlon\" : min ( lon - span , lon + span ), \"minlat\" : min ( lat - span , lat + span ), \"maxlon\" : max ( lon - span , lon + span ), \"maxlat\" : max ( lat - span , lat + span ) }, \"center\" : { \"lon\" : lon , \"lat\" : lat }, \"zoom\" : { \"default\" : 14 }, \"basemapurl\" : None , \"geographic\" : True , \"features\" : None } except Exception as e : raise e return None return maptempl @hug . post ( \"/\" ) def create_feature ( prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0 , 0 ]}, request = None , response = None , ): \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo il suo prototipo `prototype` ed in fase di creazione viene \\ creato il campo `uid`. Questi due campi sono immutabli (vedi PUT `/feature/{uid}`). \\ Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" uid = uuid () out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ] = feature_info . pop ( \"classification\" ) try : feature [ \"inmap\" ] = feature_info . pop ( \"inmap\" ) except Exception as e : feature [ \"inmap\" ] = None db [ \"features\" ][ uid ] = feature feature_info [ \"geometry\" ] = geometry feature_info . update ({ \"data\" : None , \"map\" : None , \"cloud\" : None }) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ) . items (): try : struct [ 'operands' ][ k ] = eval ( w . replace ( '{{new}}' , 'feature' )) except AttributeError as e : struct [ 'operands' ][ k ] = None db [ 'series' ][ suid ] = struct params [ param ] = suid feature_info [ \"parameters\" ] = params db [ \"features_info\" ][ uid ] = feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . message = f \"prototype ' { prototype } ' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : out . message = str ( e ) out . status = falcon . HTTP_CONFLICT try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info = [ \"geometry\" , \"capabilities\" ], request = None , response = None ): \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ): if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ): if info == \"\" : info = None else : info = [ info ] info . append ( \"capabilities\" ) if 'map' in info : info . append ( 'subitemsfrommap' ) try : # out.data = {\"features\":[]} out . data = { \"features\" :{}} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ): extract = [ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v [ 'uid' ]] subitems = { \"features\" :{}} for i in info : if i == 'parameters' : f [ i ] = [] try : for p , s in infos [ i ] . items (): if s is not None : try : cmap = db [ \"series\" ][ s ][ 'operands' ][ 'cmap' ][ 'f_cmap' ] cmap = [ [ round ( a [ 0 ], 3 ), a [ 1 ], a [ 2 ]] for a in cmap ] except Exception as e : cmap = None f [ i ] . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ], \"cmap\" : cmap }) except AttributeError as e : pass elif i in [ 'subitems' , 'subitemsfrommap' ]: try : if infos [ 'subitems' ] is not None : subitems = features_info ( infos [ 'subitems' ]) . data except Exception as e : subitems = { \"features\" :{}} elif i == 'map' : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None if f [ i ] is None : try : if 'map' in infos [ 'capabilities' ]: f [ i ] = mkpmaponthefly ( infos [ 'geometry' ]) except Exception as e : f [ i ] = None else : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None try : f [ 'map' ] . update ( subitems ) except Exception as e : pass if 'subitems' in info : try : f [ 'subitems' ] = subitems except Exception as e : f [ 'subitems' ] = { \"features\" :{}} try : if f [ 'properties' ][ 'inmap' ] == 'Y' : f [ 'properties' ][ 'inmap' ] = infos [ 'map' ][ 'basemapurl' ] else : f [ 'properties' ][ 'inmap' ] = None except Exception as e : f [ 'properties' ][ 'inmap' ] = None out . data [ 'features' ][ v [ 'uid' ]] = f except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . get ( \"/ {uid} \" ) def feature_info ( uid , cntxt = None , info = [ \"geometry\" , \"capabilities\" ], request = None , response = None ): \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) @hug . put ( \"/ {uid} \" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = {}, request = None , response = None , ): \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return @hug . delete ( \"/ {uid} \" ) def del_feature ( uid , request = None , response = None ): \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] subits = info [ 'subitems' ] if subits is not None : for v in info [ 'subitems' ]: try : del_feature ( v ) except Exception as e : pass for v in info [ 'parameters' ] . values (): if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ) . deleteActionValues () except Exception as e : #traceback.print_exc() pass try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : #traceback.print_exc() out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return","title":"Module hielen3.api.features"},{"location":"reference/hielen3/api/features/#variables","text":"db","title":"Variables"},{"location":"reference/hielen3/api/features/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/features/#create_feature","text":"def create_feature ( prototype , properties : < hielen3 . utils . JsonValidable object at 0x7f951f5eac10 > = {}, geometry : < hielen3 . utils . JsonValidable object at 0x7f951f5eafd0 > = { 'type' : 'Point' , 'coordinates' : [ 0 , 0 ]}, request = None , response = None ) Creazione delle Features. Ogni feature deve avere il suo il suo prototipo prototype ed in fase di creazione viene creato il campo uid . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. View Source @hug . post ( \"/\" ) def create_feature ( prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0, 0 ] } , request = None , response = None , ) : \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo il suo prototipo `prototype` ed in fase di creazione viene \\ creato il campo `uid`. Questi due campi sono immutabli (vedi PUT `/feature/{uid}`). \\ Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" uid = uuid () out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ]= feature_info . pop ( \"classification\" ) try : feature [ \"inmap\" ]= feature_info . pop ( \"inmap\" ) except Exception as e : feature [ \"inmap\" ]= None db [ \"features\" ][ uid ]= feature feature_info [ \"geometry\" ] = geometry feature_info . update ( { \"data\" : None , \"map\" : None , \"cloud\" : None } ) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ). items () : try : struct [ 'operands' ][ k ]= eval ( w . replace ( '{{new}}' , 'feature' )) except AttributeError as e : struct [ 'operands' ][ k ] = None db [ 'series' ][ suid ]= struct params [ param ]= suid feature_info [ \"parameters\" ]= params db [ \"features_info\" ][ uid ]= feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . message = f \"prototype '{prototype}' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : out . message = str ( e ) out . status = falcon . HTTP_CONFLICT try : response = out . format ( response = response , request = request ) except Exception as e : return out return","title":"create_feature"},{"location":"reference/hielen3/api/features/#del_feature","text":"def del_feature ( uid , request = None , response = None ) Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente. View Source @hug . delete ( \"/{uid}\" ) def del_feature ( uid , request = None , response = None ) : \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] subits = info [ 'subitems' ] if subits is not None : for v in info [ 'subitems' ] : try : del_feature ( v ) except Exception as e : pass for v in info [ 'parameters' ] . values () : if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ). deleteActionValues () except Exception as e : #traceback . print_exc () pass try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : #traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return","title":"del_feature"},{"location":"reference/hielen3/api/features/#feature_info","text":"def feature_info ( uid , cntxt = None , info = [ 'geometry' , 'capabilities' ], request = None , response = None ) Alias di recupero informazioni della specifica feature View Source @hug . get ( \"/{uid}\" ) def feature_info ( uid , cntxt = None , info =[ \"geometry\",\"capabilities\" ] , request = None , response = None ) : \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response )","title":"feature_info"},{"location":"reference/hielen3/api/features/#features_info","text":"def features_info ( uids = None , cntxt = None , info = [ 'geometry' , 'capabilities' ], request = None , response = None ) Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituita una struttura \"data\" di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri View Source @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info =[ \"geometry\",\"capabilities\" ] , request = None , response = None ) : \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituita una struttura \" data \" di questo tipo: { \" features \": [ { \" type \": \" Feature \", \" properties \": { ... }, \" geometry \": <GeoJson Validable> }, ... ] } Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ) : if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ) : if info == \"\" : info = None else : info = [ info ] info . append ( \"capabilities\" ) if 'map' in info : info . append ( 'subitemsfrommap' ) try : # out . data = { \"features\" :[]} out . data = { \"features\" :{}} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ) : extract =[ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v['uid' ] ] subitems = { \"features\" :{}} for i in info : if i == 'parameters' : f [ i ]= [] try : for p , s in infos [ i ] . items () : if s is not None : try : cmap = db [ \"series\" ][ s ][ 'operands' ][ 'cmap' ][ 'f_cmap' ] cmap =[ [round(a[0 ] , 3 ), a [ 1 ] , a [ 2 ] ] for a in cmap ] except Exception as e : cmap = None f [ i ] . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] , \"cmap\" : cmap } ) except AttributeError as e : pass elif i in [ 'subitems','subitemsfrommap' ] : try : if infos [ 'subitems' ] is not None : subitems = features_info ( infos [ 'subitems' ] ). data except Exception as e : subitems = { \"features\" :{}} elif i == 'map' : try : f [ i ]= infos [ i ] except Exception as e : f [ i ] = None if f [ i ] is None : try : if 'map' in infos [ 'capabilities' ] : f [ i ] = mkpmaponthefly ( infos [ 'geometry' ] ) except Exception as e : f [ i ] = None else : try : f [ i ]= infos [ i ] except Exception as e : f [ i ]= None try : f [ 'map' ] . update ( subitems ) except Exception as e : pass if 'subitems' in info : try : f [ 'subitems' ]= subitems except Exception as e : f [ 'subitems' ]= { \"features\" :{}} try : if f [ 'properties' ][ 'inmap' ] == 'Y' : f [ 'properties' ][ 'inmap' ]= infos [ 'map' ][ 'basemapurl' ] else : f [ 'properties' ][ 'inmap' ]= None except Exception as e : f [ 'properties' ][ 'inmap' ]= None out . data [ 'features' ][ v['uid' ] ] = f except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) try : response = out . format ( response = response , request = request ) except Exception as e : return out return","title":"features_info"},{"location":"reference/hielen3/api/features/#mkpmaponthefly","text":"def mkpmaponthefly ( geometry ) View Source def mkpmaponthefly ( geometry ): try : lon = geometry [ 'coordinates' ][ 0 ] lat = geometry [ 'coordinates' ][ 1 ] span = 0 . 005 maptempl = { \"extent\" : { \"minlon\" : min ( lon - span , lon + span ), \"minlat\" : min ( lat - span , lat + span ), \"maxlon\" : max ( lon - span , lon + span ), \"maxlat\" : max ( lat - span , lat + span ) } , \"center\" : { \"lon\" : lon , \"lat\" : lat } , \"zoom\" : { \"default\" : 14 } , \"basemapurl\" : None , \"geographic\" : True , \"features\" : None } except Exception as e : raise e return None return maptempl","title":"mkpmaponthefly"},{"location":"reference/hielen3/api/features/#update_feature","text":"def update_feature ( uid , properties : < hielen3 . utils . JsonValidable object at 0x7f951f5eae50 > = {}, geometry : < hielen3 . utils . JsonValidable object at 0x7f951f601310 > = {}, request = None , response = None ) Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. View Source @hug . put ( \"/{uid}\" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = {} , request = None , response = None , ) : \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" try : response = out . format ( response = response , request = request ) except Exception as e : return out return","title":"update_feature"},{"location":"reference/hielen3/api/features/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/api/features/#featurepropertiesschema","text":"class FeaturePropertiesSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Base schema class with which to define custom schemas. Example usage: .. code-block:: python import datetime as dt from dataclasses import dataclass from marshmallow import Schema , fields @dataclass class Album : title : str release_date : dt . date class AlbumSchema ( Schema ): title = fields . Str () release_date = fields . Date () album = Album ( \"Beggars Banquet\" , dt . date ( 1968 , 12 , 6 )) schema = AlbumSchema () data = schema . dump ( album ) data # {'release_date': '1968-12-06', 'title': 'Beggars Banquet'} :param only: Whitelist of the declared fields to select when instantiating the Schema. If None, all fields are used. Nested fields can be represented with dot delimiters. :param exclude: Blacklist of the declared fields to exclude when instantiating the Schema. If a field appears in both only and exclude , it is not used. Nested fields can be represented with dot delimiters. :param many: Should be set to True if obj is a collection so that the object will be serialized to a list. :param context: Optional context passed to :class: fields.Method and :class: fields.Function fields. :param load_only: Fields to skip during serialization (write-only fields) :param dump_only: Fields to skip during deserialization (read-only fields) :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . .. versionchanged:: 3.0.0 prefix parameter removed. .. versionchanged:: 2.0.0 __validators__ , __preprocessors__ , and __data_handlers__ are removed in favor of marshmallow.decorators.validates_schema , marshmallow.decorators.pre_load and marshmallow.decorators.post_dump . __accessor__ and __error_handler__ are deprecated. Implement the handle_error and get_attribute methods instead. View Source class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None )","title":"FeaturePropertiesSchema"},{"location":"reference/hielen3/api/features/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/api/features/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING context description error_messages label location opts status style timestamp","title":"Class variables"},{"location":"reference/hielen3/api/features/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/api/features/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/api/features/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen3/api/features/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/api/features/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/api/features/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/api/features/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/api/features/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/api/features/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/api/features/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/api/features/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/api/features/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/api/glob/","text":"Module hielen3.api.glob View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python # coding=utf-8 import hug from . import prototypes , query , features , actions , actionschemata import falcon \"\"\" @hug.not_found() def not_found(): return {'error': { 'status': falcon.status.HTTP_NOT_FOUND, 'description': 'URL is invalid.', }} api = hug.get(on_invalid=hug.redirect.not_found) \"\"\" @hug . extend_api ( \"/prototypes\" ) def protoman (): \"\"\" Prototypes manager \"\"\" return [ prototypes ] @hug . extend_api ( \"/features\" ) def featman (): \"\"\" Features manager \"\"\" return [ features ] @hug . extend_api ( \"/actions\" ) def actiman (): \"\"\" Action manager \"\"\" return [ actions ] @hug . extend_api ( \"/actionschemata\" ) def scheman (): \"\"\" Schemata manager \"\"\" return [ actionschemata ] @hug . extend_api ( \"/query\" ) def dataman (): \"\"\" Data manager \"\"\" return [ query ] Functions actiman def actiman ( ) Action manager View Source @hug . extend_api ( \"/actions\" ) def actiman () : \"\"\" Action manager \"\"\" return [ actions ] dataman def dataman ( ) Data manager View Source @hug . extend_api ( \"/query\" ) def dataman () : \"\"\" Data manager \"\"\" return [ query ] featman def featman ( ) Features manager View Source @hug . extend_api ( \"/features\" ) def featman () : \"\"\" Features manager \"\"\" return [ features ] protoman def protoman ( ) Prototypes manager View Source @hug . extend_api ( \"/prototypes\" ) def protoman () : \"\"\" Prototypes manager \"\"\" return [ prototypes ] scheman def scheman ( ) Schemata manager View Source @hug . extend_api ( \"/actionschemata\" ) def scheman () : \"\"\" Schemata manager \"\"\" return [ actionschemata ]","title":"Glob"},{"location":"reference/hielen3/api/glob/#module-hielen3apiglob","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #!/usr/bin/env python # coding=utf-8 import hug from . import prototypes , query , features , actions , actionschemata import falcon \"\"\" @hug.not_found() def not_found(): return {'error': { 'status': falcon.status.HTTP_NOT_FOUND, 'description': 'URL is invalid.', }} api = hug.get(on_invalid=hug.redirect.not_found) \"\"\" @hug . extend_api ( \"/prototypes\" ) def protoman (): \"\"\" Prototypes manager \"\"\" return [ prototypes ] @hug . extend_api ( \"/features\" ) def featman (): \"\"\" Features manager \"\"\" return [ features ] @hug . extend_api ( \"/actions\" ) def actiman (): \"\"\" Action manager \"\"\" return [ actions ] @hug . extend_api ( \"/actionschemata\" ) def scheman (): \"\"\" Schemata manager \"\"\" return [ actionschemata ] @hug . extend_api ( \"/query\" ) def dataman (): \"\"\" Data manager \"\"\" return [ query ]","title":"Module hielen3.api.glob"},{"location":"reference/hielen3/api/glob/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/glob/#actiman","text":"def actiman ( ) Action manager View Source @hug . extend_api ( \"/actions\" ) def actiman () : \"\"\" Action manager \"\"\" return [ actions ]","title":"actiman"},{"location":"reference/hielen3/api/glob/#dataman","text":"def dataman ( ) Data manager View Source @hug . extend_api ( \"/query\" ) def dataman () : \"\"\" Data manager \"\"\" return [ query ]","title":"dataman"},{"location":"reference/hielen3/api/glob/#featman","text":"def featman ( ) Features manager View Source @hug . extend_api ( \"/features\" ) def featman () : \"\"\" Features manager \"\"\" return [ features ]","title":"featman"},{"location":"reference/hielen3/api/glob/#protoman","text":"def protoman ( ) Prototypes manager View Source @hug . extend_api ( \"/prototypes\" ) def protoman () : \"\"\" Prototypes manager \"\"\" return [ prototypes ]","title":"protoman"},{"location":"reference/hielen3/api/glob/#scheman","text":"def scheman ( ) Schemata manager View Source @hug . extend_api ( \"/actionschemata\" ) def scheman () : \"\"\" Schemata manager \"\"\" return [ actionschemata ]","title":"scheman"},{"location":"reference/hielen3/api/prototypes/","text":"Module hielen3.api.prototypes View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db from hielen3.utils import ResponseFormatter @hug . get ( \"/\" ) def prototypes ( request = None , response = None ): \"\"\" **Ritorna l'elenco dei prototipi disponibili come array json** \"\"\" out = ResponseFormatter () try : out . data = list ( db [ 'features_proto' ] . db . index ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def prototype_struct ( prototype , request = None , response = None ): \"\"\" **Ritorna informazioni dettagliate sullo specifico prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) Variables db Functions prototype_struct def prototype_struct ( prototype , request = None , response = None ) Ritorna informazioni dettagliate sullo specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def prototype_struct ( prototype , request = None , response = None ) : \"\"\" **Ritorna informazioni dettagliate sullo specifico prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) prototypes def prototypes ( request = None , response = None ) Ritorna l'elenco dei prototipi disponibili come array json View Source @hug . get ( \"/\" ) def prototypes ( request = None , response = None ) : \"\"\" **Ritorna l'elenco dei prototipi disponibili come array json** \"\"\" out = ResponseFormatter () try : out . data = list ( db [ 'features_proto' ] . db . index ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"Prototypes"},{"location":"reference/hielen3/api/prototypes/#module-hielen3apiprototypes","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen3 import db from hielen3.utils import ResponseFormatter @hug . get ( \"/\" ) def prototypes ( request = None , response = None ): \"\"\" **Ritorna l'elenco dei prototipi disponibili come array json** \"\"\" out = ResponseFormatter () try : out . data = list ( db [ 'features_proto' ] . db . index ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def prototype_struct ( prototype , request = None , response = None ): \"\"\" **Ritorna informazioni dettagliate sullo specifico prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"Module hielen3.api.prototypes"},{"location":"reference/hielen3/api/prototypes/#variables","text":"db","title":"Variables"},{"location":"reference/hielen3/api/prototypes/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/prototypes/#prototype_struct","text":"def prototype_struct ( prototype , request = None , response = None ) Ritorna informazioni dettagliate sullo specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def prototype_struct ( prototype , request = None , response = None ) : \"\"\" **Ritorna informazioni dettagliate sullo specifico prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"prototype_struct"},{"location":"reference/hielen3/api/prototypes/#prototypes","text":"def prototypes ( request = None , response = None ) Ritorna l'elenco dei prototipi disponibili come array json View Source @hug . get ( \"/\" ) def prototypes ( request = None , response = None ) : \"\"\" **Ritorna l'elenco dei prototipi disponibili come array json** \"\"\" out = ResponseFormatter () try : out . data = list ( db [ 'features_proto' ] . db . index ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"prototypes"},{"location":"reference/hielen3/api/query/","text":"Module hielen3.api.query View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 #!/usr/bin/env python # coding=utf-8 import hug import falcon import json from marshmallow import Schema , fields from numpy import nan , unique from pandas import DataFrame , to_datetime from hielen3 import db from hielen3.query import HSeries from hielen3.utils import hug_output_format_conten_type , JsonValidable , Selection , ResponseFormatter import asyncio from marshmallow_geojson import GeoJSONSchema data_out_handler = hug_output_format_conten_type ( [ hug . output_format . json , hug . output_format . text ] ) CSV = \"text/plain; charset=utf-8\" JSON = \"application/json; charset=utf-8\" class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , required = False , allow_none = True ) series = fields . List ( fields . Str , default = []) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . List ( fields . Nested ( GeoJSONSchema , required = False , allow_none = True ), default = []) ####### API DATATABLE ####### @hug . get ( \"/ {capability} \" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ): series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys (): series [ p ] = [] try : series [ p ] . append ( HSeries ( p , orient = capability ) . thdata ( ** query , ** kwargs )) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items (): ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ) . sort_index () idx = unique ( ser . index . values , return_index = True )[ 1 ] ser = ser . iloc [ idx ] try : ser . columns = [ \"_\" . join ([ param , a ]) for a in ser . columns ] except Exception as e : ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ) . content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' , date_format = \"%Y-%m- %d %H:%M:%S\" )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) @hug . get ( \"/ {capability} / {feature} /\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ): if isinstance ( geometry , list ): geometry = \",\" . join ( geometry ) if geometry is None : geometry = \"[]\" #TODO VErificare unificazione con HielenSource.retriveSeries() try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ par ]] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , geometry = \"#PLACEHOLDER#\" , refresh = refresh ) datamap = json . dumps ( datamap ) . replace ( '\"#PLACEHOLDER#\"' , geometry ) datamap = DataMapSchema () . loads ( datamap ) return tabular_data ( capability = capability , datamap = [ datamap ], content_type = content_type , request = request , response = response , ** kwargs ) @hug . get ( \"/ {capability} / {feature} / {par} \" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ): return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , geometry = geometry , content_type = content_type , request = request , response = response , ** kwargs ) Variables CSV JSON db nan Functions data_out_handler def data_out_handler ( data , request , response ) Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text View Source def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) tabular_data def tabular_data ( capability , datamap : < hielen3 . utils . JsonValidable object at 0x7f951f52e8e0 > , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}\" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ) : series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys () : series [ p ] = [] try : series [ p ] . append ( HSeries ( p , orient = capability ). thdata ( ** query , ** kwargs )) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items () : ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ). sort_index () idx = unique ( ser . index . values , return_index = True ) [ 1 ] ser = ser . iloc [ idx ] try : ser . columns = [ \"_\".join([param,a ] ) for a in ser . columns ] except Exception as e : ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ). content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' , date_format = \"%Y-%m-%d %H:%M:%S\" )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) tabular_data_el def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) : if isinstance ( geometry , list ) : geometry = \",\" . join ( geometry ) if geometry is None : geometry = \"[]\" #TODO VErificare unificazione con HielenSource . retriveSeries () try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ par ] ] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , geometry = \"#PLACEHOLDER#\" , refresh = refresh ) datamap = json . dumps ( datamap ). replace ( '\"#PLACEHOLDER#\"' , geometry ) datamap = DataMapSchema (). loads ( datamap ) return tabular_data ( capability = capability , datamap =[ datamap ] , content_type = content_type , request = request , response = response , ** kwargs ) tabular_data_par def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/{par}\" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) : return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , geometry = geometry , content_type = content_type , request = request , response = response , ** kwargs ) Classes DataMapSchema class DataMapSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) View Source class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , required = False , allow_none = True ) series = fields . List ( fields . Str , default =[]) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . List ( fields . Nested ( GeoJSONSchema , required = False , allow_none = True ), default =[]) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages geometry opts refresh series timeref times Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"Query"},{"location":"reference/hielen3/api/query/#module-hielen3apiquery","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 #!/usr/bin/env python # coding=utf-8 import hug import falcon import json from marshmallow import Schema , fields from numpy import nan , unique from pandas import DataFrame , to_datetime from hielen3 import db from hielen3.query import HSeries from hielen3.utils import hug_output_format_conten_type , JsonValidable , Selection , ResponseFormatter import asyncio from marshmallow_geojson import GeoJSONSchema data_out_handler = hug_output_format_conten_type ( [ hug . output_format . json , hug . output_format . text ] ) CSV = \"text/plain; charset=utf-8\" JSON = \"application/json; charset=utf-8\" class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , required = False , allow_none = True ) series = fields . List ( fields . Str , default = []) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . List ( fields . Nested ( GeoJSONSchema , required = False , allow_none = True ), default = []) ####### API DATATABLE ####### @hug . get ( \"/ {capability} \" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ): series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys (): series [ p ] = [] try : series [ p ] . append ( HSeries ( p , orient = capability ) . thdata ( ** query , ** kwargs )) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items (): ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ) . sort_index () idx = unique ( ser . index . values , return_index = True )[ 1 ] ser = ser . iloc [ idx ] try : ser . columns = [ \"_\" . join ([ param , a ]) for a in ser . columns ] except Exception as e : ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ) . content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' , date_format = \"%Y-%m- %d %H:%M:%S\" )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) @hug . get ( \"/ {capability} / {feature} /\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ): if isinstance ( geometry , list ): geometry = \",\" . join ( geometry ) if geometry is None : geometry = \"[]\" #TODO VErificare unificazione con HielenSource.retriveSeries() try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ par ]] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , geometry = \"#PLACEHOLDER#\" , refresh = refresh ) datamap = json . dumps ( datamap ) . replace ( '\"#PLACEHOLDER#\"' , geometry ) datamap = DataMapSchema () . loads ( datamap ) return tabular_data ( capability = capability , datamap = [ datamap ], content_type = content_type , request = request , response = response , ** kwargs ) @hug . get ( \"/ {capability} / {feature} / {par} \" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ): return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , geometry = geometry , content_type = content_type , request = request , response = response , ** kwargs )","title":"Module hielen3.api.query"},{"location":"reference/hielen3/api/query/#variables","text":"CSV JSON db nan","title":"Variables"},{"location":"reference/hielen3/api/query/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/api/query/#data_out_handler","text":"def data_out_handler ( data , request , response ) Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text View Source def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response )","title":"data_out_handler"},{"location":"reference/hielen3/api/query/#tabular_data","text":"def tabular_data ( capability , datamap : < hielen3 . utils . JsonValidable object at 0x7f951f52e8e0 > , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}\" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ) : series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys () : series [ p ] = [] try : series [ p ] . append ( HSeries ( p , orient = capability ). thdata ( ** query , ** kwargs )) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items () : ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ). sort_index () idx = unique ( ser . index . values , return_index = True ) [ 1 ] ser = ser . iloc [ idx ] try : ser . columns = [ \"_\".join([param,a ] ) for a in ser . columns ] except Exception as e : ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ). content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' , date_format = \"%Y-%m-%d %H:%M:%S\" )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" ))","title":"tabular_data"},{"location":"reference/hielen3/api/query/#tabular_data_el","text":"def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) : if isinstance ( geometry , list ) : geometry = \",\" . join ( geometry ) if geometry is None : geometry = \"[]\" #TODO VErificare unificazione con HielenSource . retriveSeries () try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ par ] ] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , geometry = \"#PLACEHOLDER#\" , refresh = refresh ) datamap = json . dumps ( datamap ). replace ( '\"#PLACEHOLDER#\"' , geometry ) datamap = DataMapSchema (). loads ( datamap ) return tabular_data ( capability = capability , datamap =[ datamap ] , content_type = content_type , request = request , response = response , ** kwargs )","title":"tabular_data_el"},{"location":"reference/hielen3/api/query/#tabular_data_par","text":"def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/{par}\" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , geometry = None , content_type = None , request = None , response = None , ** kwargs ) : return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , geometry = geometry , content_type = content_type , request = request , response = response , ** kwargs )","title":"tabular_data_par"},{"location":"reference/hielen3/api/query/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/api/query/#datamapschema","text":"class DataMapSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) View Source class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , required = False , allow_none = True ) series = fields . List ( fields . Str , default =[]) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . List ( fields . Nested ( GeoJSONSchema , required = False , allow_none = True ), default =[])","title":"DataMapSchema"},{"location":"reference/hielen3/api/query/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/api/query/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages geometry opts refresh series timeref times","title":"Class variables"},{"location":"reference/hielen3/api/query/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/api/query/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/api/query/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen3/api/query/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/api/query/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/api/query/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/api/query/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/api/query/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/api/query/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/api/query/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/api/query/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/api/query/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/","text":"Module hielen3.ext Sub-modules hielen3.ext.davedere_hotspot_multiseries hielen3.ext.source_csv hielen3.ext.source_logger hielen3.ext.source_photomonitoring hielen3.ext.source_rawsource hielen3.ext.source_smori hielen3.ext.source_tinsar hielen3.ext.source_winecap","title":"Index"},{"location":"reference/hielen3/ext/#module-hielen3ext","text":"","title":"Module hielen3.ext"},{"location":"reference/hielen3/ext/#sub-modules","text":"hielen3.ext.davedere_hotspot_multiseries hielen3.ext.source_csv hielen3.ext.source_logger hielen3.ext.source_photomonitoring hielen3.ext.source_rawsource hielen3.ext.source_smori hielen3.ext.source_tinsar hielen3.ext.source_winecap","title":"Sub-modules"},{"location":"reference/hielen3/ext/source_csv/","text":"Module hielen3.ext.source_csv View Source # coding: utf-8 from pandas import to_datetime , read_csv def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ) . getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ): self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ): out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col = [ 0 ], )[ column ] # out.index=to_datetime(out.index) out = out . loc [ timefrom : timeto ] return out Functions get_ch def get_ch ( path = './incomes' , restype = None , resource = None , filename = 'last_load.csv' , column = None , timefrom = None , timeto = None ) View Source def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ). getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) Classes GWO class GWO ( path = './incomes' , restype = None , filename = 'last_load.csv' ) View Source class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ) : self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out Methods getDataSeries def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) View Source def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"Source Csv"},{"location":"reference/hielen3/ext/source_csv/#module-hielen3extsource_csv","text":"View Source # coding: utf-8 from pandas import to_datetime , read_csv def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ) . getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ): self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ): out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col = [ 0 ], )[ column ] # out.index=to_datetime(out.index) out = out . loc [ timefrom : timeto ] return out","title":"Module hielen3.ext.source_csv"},{"location":"reference/hielen3/ext/source_csv/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_csv/#get_ch","text":"def get_ch ( path = './incomes' , restype = None , resource = None , filename = 'last_load.csv' , column = None , timefrom = None , timeto = None ) View Source def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ). getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto )","title":"get_ch"},{"location":"reference/hielen3/ext/source_csv/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_csv/#gwo","text":"class GWO ( path = './incomes' , restype = None , filename = 'last_load.csv' ) View Source class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ) : self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"GWO"},{"location":"reference/hielen3/ext/source_csv/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_csv/#getdataseries","text":"def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) View Source def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"getDataSeries"},{"location":"reference/hielen3/ext/source_smori/","text":"Module hielen3.ext.source_smori View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime import json import requests def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO () . getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) class GWO : def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out Functions get_ch def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO (). getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) Classes GWO class GWO ( uri = 'https://www.smori.it/tisma/api/v1/sensor_data.php' ) View Source class GWO: def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None: params [ \"aggr\" ] = aggr if timefrom is not None: params [ \"dal\" ] = timefrom if timefrom is not None: params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty: return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out Methods getDataSeries def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print ( r . url ) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"Source Smori"},{"location":"reference/hielen3/ext/source_smori/#module-hielen3extsource_smori","text":"View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime import json import requests def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO () . getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) class GWO : def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"Module hielen3.ext.source_smori"},{"location":"reference/hielen3/ext/source_smori/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_smori/#get_ch","text":"def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO (). getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , )","title":"get_ch"},{"location":"reference/hielen3/ext/source_smori/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_smori/#gwo","text":"class GWO ( uri = 'https://www.smori.it/tisma/api/v1/sensor_data.php' ) View Source class GWO: def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None: params [ \"aggr\" ] = aggr if timefrom is not None: params [ \"dal\" ] = timefrom if timefrom is not None: params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty: return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"GWO"},{"location":"reference/hielen3/ext/source_smori/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_smori/#getdataseries","text":"def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print ( r . url ) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"getDataSeries"},{"location":"reference/hielen3/ext/source_winecap/","text":"Module hielen3.ext.source_winecap View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime from zeep import Client from zeep.helpers import serialize_object from concurrent.futures import ThreadPoolExecutor from functools import wraps from time import time from hielen.utils import isot2ut \"\"\" sudo apt-get install libxml2-dev libxslt1-dev pip install lxml==4.2.5 zeep \"\"\" # key='80d373db820fea6f8c5f57d125eb509d' key = \"04a71268d386d61801824863ad7e2a5d\" GWOmac = \"00009DEA\" def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ) . getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) def threadpool ( f , executor = None ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ): self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ): return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ] Variables GWOmac key Functions get_ch def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ) View Source def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ). getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) threadpool def threadpool ( f , executor = None ) View Source def threadpool ( f , executor = None ) : @wraps ( f ) def wrap ( * args , ** kwargs ) : return ThreadPoolExecutor (). submit ( f , * args , ** kwargs ) return wrap Classes GWO class GWO ( key = '04a71268d386d61801824863ad7e2a5d' , mac = '00009DEA' , wsdl = 'http://www.winecap.it/winecapws.wsdl' ) View Source class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ) : self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ) : return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) : if not isinstance ( timefrom , int ) : timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ) : timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ( [ \"timeStamp\" ] ) [ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [] , timefrom = None , timeto = None ) : thds = [ self.getThreadedSeries(*x, timefrom, timeto) for x in reqser ] return [ x.result() for x in thds ] def getDataFrameSE ( self , reqser = [] , timefrom = None , timeto = None ) : return [ self.getDataSeries(*x, timefrom, timeto) for x in reqser ] Methods getDataFrame def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] getDataFrameSE def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ] getDataSeries def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) View Source def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out getSensorsList def getSensorsList ( self ) View Source def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) getThreadedSeries def getThreadedSeries ( self , * args , ** kwargs ) View Source @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs )","title":"Source Winecap"},{"location":"reference/hielen3/ext/source_winecap/#module-hielen3extsource_winecap","text":"View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime from zeep import Client from zeep.helpers import serialize_object from concurrent.futures import ThreadPoolExecutor from functools import wraps from time import time from hielen.utils import isot2ut \"\"\" sudo apt-get install libxml2-dev libxslt1-dev pip install lxml==4.2.5 zeep \"\"\" # key='80d373db820fea6f8c5f57d125eb509d' key = \"04a71268d386d61801824863ad7e2a5d\" GWOmac = \"00009DEA\" def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ) . getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) def threadpool ( f , executor = None ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ): self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ): return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ]","title":"Module hielen3.ext.source_winecap"},{"location":"reference/hielen3/ext/source_winecap/#variables","text":"GWOmac key","title":"Variables"},{"location":"reference/hielen3/ext/source_winecap/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_winecap/#get_ch","text":"def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ) View Source def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ). getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto )","title":"get_ch"},{"location":"reference/hielen3/ext/source_winecap/#threadpool","text":"def threadpool ( f , executor = None ) View Source def threadpool ( f , executor = None ) : @wraps ( f ) def wrap ( * args , ** kwargs ) : return ThreadPoolExecutor (). submit ( f , * args , ** kwargs ) return wrap","title":"threadpool"},{"location":"reference/hielen3/ext/source_winecap/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_winecap/#gwo","text":"class GWO ( key = '04a71268d386d61801824863ad7e2a5d' , mac = '00009DEA' , wsdl = 'http://www.winecap.it/winecapws.wsdl' ) View Source class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ) : self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ) : return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) : if not isinstance ( timefrom , int ) : timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ) : timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ( [ \"timeStamp\" ] ) [ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [] , timefrom = None , timeto = None ) : thds = [ self.getThreadedSeries(*x, timefrom, timeto) for x in reqser ] return [ x.result() for x in thds ] def getDataFrameSE ( self , reqser = [] , timefrom = None , timeto = None ) : return [ self.getDataSeries(*x, timefrom, timeto) for x in reqser ]","title":"GWO"},{"location":"reference/hielen3/ext/source_winecap/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_winecap/#getdataframe","text":"def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ]","title":"getDataFrame"},{"location":"reference/hielen3/ext/source_winecap/#getdataframese","text":"def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ]","title":"getDataFrameSE"},{"location":"reference/hielen3/ext/source_winecap/#getdataseries","text":"def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) View Source def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out","title":"getDataSeries"},{"location":"reference/hielen3/ext/source_winecap/#getsensorslist","text":"def getSensorsList ( self ) View Source def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac )))","title":"getSensorsList"},{"location":"reference/hielen3/ext/source_winecap/#getthreadedseries","text":"def getThreadedSeries ( self , * args , ** kwargs ) View Source @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs )","title":"getThreadedSeries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/","text":"Module hielen3.ext.davedere_hotspot_multiseries View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .hotspot import Source , ConfigSchema __all__ = [ \"Source\" , \"ConfigSchema\" ] Sub-modules hielen3.ext.davedere_hotspot_multiseries.hotspot Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Index"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#module-hielen3extdavedere_hotspot_multiseries","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .hotspot import Source , ConfigSchema __all__ = [ \"Source\" , \"ConfigSchema\" ]","title":"Module hielen3.ext.davedere_hotspot_multiseries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#sub-modules","text":"hielen3.ext.davedere_hotspot_multiseries.hotspot","title":"Sub-modules"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts","title":"Class variables"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#ancestors-in-mro_1","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#data","text":"def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/","text":"Module hielen3.ext.davedere_hotspot_multiseries.hotspot View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LoggerHeader from pandas import read_csv , DatetimeIndex , Series from marshmallow import fields from pathlib import Path import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ], \"column\" : chinfo [ 1 ], \"rawunit\" : chinfo [ 2 ], \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ], list ): for p in range ( chinfo [ 5 ] . __len__ ()): operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 3 ], \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ): if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col = [ 0 ], parse_dates = True ) out = out [ out . columns [ column ]] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" )[ 0 ] if scalar in [ 'rot' ]: out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out[columns] # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ] Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Hotspot"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#module-hielen3extdavedere_hotspot_multiserieshotspot","text":"View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LoggerHeader from pandas import read_csv , DatetimeIndex , Series from marshmallow import fields from pathlib import Path import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ], \"column\" : chinfo [ 1 ], \"rawunit\" : chinfo [ 2 ], \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ], list ): for p in range ( chinfo [ 5 ] . __len__ ()): operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 3 ], \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ): if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col = [ 0 ], parse_dates = True ) out = out [ out . columns [ column ]] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" )[ 0 ] if scalar in [ 'rot' ]: out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out[columns] # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ]","title":"Module hielen3.ext.davedere_hotspot_multiseries.hotspot"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts","title":"Class variables"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#ancestors-in-mro_1","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#data","text":"def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , filename = \"last_load.csv\" , ** kwargs ) : if times is None : times = slice ( None , None , None ) if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/davedere_hotspot_multiseries/hotspot/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_logger/","text":"Module hielen3.ext.source_logger View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .logger import Source , ConfigSchema __all__ = [ \"Source\" , \"ConfigSchema\" ] Sub-modules hielen3.ext.source_logger.logger Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Index"},{"location":"reference/hielen3/ext/source_logger/#module-hielen3extsource_logger","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .logger import Source , ConfigSchema __all__ = [ \"Source\" , \"ConfigSchema\" ]","title":"Module hielen3.ext.source_logger"},{"location":"reference/hielen3/ext/source_logger/#sub-modules","text":"hielen3.ext.source_logger.logger","title":"Sub-modules"},{"location":"reference/hielen3/ext/source_logger/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_logger/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_logger/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_logger/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_logger/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_logger/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_logger/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_logger/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_logger/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_logger/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_logger/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_logger/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_logger/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_logger/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_logger/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_logger/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_logger/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/source_logger/#ancestors-in-mro_1","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_logger/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_logger/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_logger/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_logger/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_logger/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_logger/#data","text":"def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/source_logger/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_logger/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_logger/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_logger/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_logger/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_logger/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_logger/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_logger/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_logger/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_logger/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_logger/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_logger/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_logger/logger/","text":"Module hielen3.ext.source_logger.logger View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LoggerHeader from pandas import read_csv , DatetimeIndex , Series from marshmallow import fields from pathlib import Path import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ], \"column\" : chinfo [ 1 ], \"rawunit\" : chinfo [ 2 ], \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ], list ): for p in range ( chinfo [ 5 ] . __len__ ()): operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 3 ], \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ): if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col = [ 0 ], parse_dates = True ) out = out [ out . columns [ column ]] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" )[ 0 ] if scalar in [ 'rot' ]: out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out[columns] # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ] Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Logger"},{"location":"reference/hielen3/ext/source_logger/logger/#module-hielen3extsource_loggerlogger","text":"View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LoggerHeader from pandas import read_csv , DatetimeIndex , Series from marshmallow import fields from pathlib import Path import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ], \"column\" : chinfo [ 1 ], \"rawunit\" : chinfo [ 2 ], \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ], list ): for p in range ( chinfo [ 5 ] . __len__ ()): operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 3 ], \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ): if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col = [ 0 ], parse_dates = True ) out = out [ out . columns [ column ]] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" )[ 0 ] if scalar in [ 'rot' ]: out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out[columns] # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ]","title":"Module hielen3.ext.source_logger.logger"},{"location":"reference/hielen3/ext/source_logger/logger/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_logger/logger/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Logger info\" : { 0 :[ \"logger_type\" , \"The logger type\" ], 1 :[ \"logger_serial\" , \"The logger serial\" ], 2 :[ \"logger_header\" , \"The logger header\" ] } } logger_type = fields . Str ( required = True , allow_none = False ) logger_serial = fields . Str ( reuired = True , allow_none = False ) logger_header = LoggerHeader ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_logger/logger/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_logger/logger/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages logger_header logger_serial logger_type opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_logger/logger/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_logger/logger/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_logger/logger/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_logger/logger/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_logger/logger/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_logger/logger/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_logger/logger/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_logger/logger/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_logger/logger/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_logger/logger/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_logger/logger/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_logger/logger/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_logger/logger/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/source_logger/logger/#ancestors-in-mro_1","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_logger/logger/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_logger/logger/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_logger/logger/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_logger/logger/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_logger/logger/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ) : chlist = kwargs [ 'logger_header' ] logger = kwargs [ 'logger_serial' ] logger_type = kwargs [ 'logger_type' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 raw_mu:2 ing_mu:3 signal_cond:4 poli_coeff:5 \"\"\" for chinfo in chlist : operands = { \"param\" : chinfo [ 0 ] , \"column\" : chinfo [ 1 ] , \"rawunit\" : chinfo [ 2 ] , \"logger\" : logger , \"logger_type\" : logger_type } if isinstance ( chinfo [ 5 ] , list ) : for p in range ( chinfo [ 5 ] . __len__ ()) : operands . update ( { f \"E{p}\" : chinfo [ 5 ][ p ] } ) chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 3 ] , \"operands\" : operands , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_logger/logger/#data","text":"def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = 'last_load.csv' , ** kwargs ) View Source def data ( self , logger_type = None , logger = None , param = None , column = None , rawunit = None , times = None , first = None , filename = \"last_load.csv\" , ** kwargs ) : if column is None : column = 0 incomes = Path ( self . incomepath , logger_type , logger , filename ) try : out = read_csv ( str ( incomes ), header = None , index_col =[ 0 ] , parse_dates = True ) out = out [ out.columns[column ] ] . squeeze () out = calc . poly_trans ( out , ** kwargs ) scalar = param . split ( \"_\" ) [ 0 ] if scalar in [ 'rot' ] : out = calc . slope ( out , rawunit , 1000 ) except Exception as e : traceback . print_exc () return Series () #out = out [ columns ] # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/source_logger/logger/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_logger/logger/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_logger/logger/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_logger/logger/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_logger/logger/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_logger/logger/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_logger/logger/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_logger/logger/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_logger/logger/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_logger/logger/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_logger/logger/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_logger/logger/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_photomonitoring/","text":"Module hielen3.ext.source_photomonitoring View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .phm import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ] Sub-modules hielen3.ext.source_photomonitoring.phm hielen3.ext.source_photomonitoring.struct hielen3.ext.source_photomonitoring.struct_boh hielen3.ext.source_photomonitoring.struct_good Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING cc_cmap ch_cmap displ_cmap error_messages ew_cmap ns_cmap opts param_file Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables CHANGE CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ) : return self . filecache / f \"{self.hasher(timestamp)}.nc\" def config ( self , ** kwargs ) : out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ] ) except Exception as e : #traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ]= step_size out [ 'window_size' ]= x_offset out [ 'ccthreshold' ]= nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ]- y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ]- x_offset , step_size ) #deg2met = 4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ]+ meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ]+ meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print ( json . dumps ( out , indent = 4 )) return kwargs def updateConfig ( self , ** kwargs ) : ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ) : timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ) : try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ] ) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ] ) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ] ) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ] ) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ) : reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ) : #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ) : timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' ) [ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser Ancestors (in MRO) hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : # traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) # deg2met = 4 . 4915764206 e - 06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) # print ( json . dumps ( out , indent = 4 )) return kwargs data def data ( self , times = None , timeref = None , geometry = None , output = 'D' , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): # 1 Selezionare i file per estrarre i dati in base ai tempi # 2 Selezionare il delta di riferimento # ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] # COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 . 99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( self , times = None , timeref = None , geometry = None , output = 'D' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser ncfile def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\" retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) updateConfig def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs updateFeed def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"Index"},{"location":"reference/hielen3/ext/source_photomonitoring/#module-hielen3extsource_photomonitoring","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .phm import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ]","title":"Module hielen3.ext.source_photomonitoring"},{"location":"reference/hielen3/ext/source_photomonitoring/#sub-modules","text":"hielen3.ext.source_photomonitoring.phm hielen3.ext.source_photomonitoring.struct hielen3.ext.source_photomonitoring.struct_boh hielen3.ext.source_photomonitoring.struct_good","title":"Sub-modules"},{"location":"reference/hielen3/ext/source_photomonitoring/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_photomonitoring/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/#ancestors-in-mro","text":"hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING cc_cmap ch_cmap displ_cmap error_messages ew_cmap ns_cmap opts param_file","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_photomonitoring/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_photomonitoring/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_photomonitoring/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_photomonitoring/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_photomonitoring/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_photomonitoring/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_photomonitoring/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_photomonitoring/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_photomonitoring/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_photomonitoring/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_photomonitoring/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/#class-variables_1","text":"CHANGE CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_photomonitoring/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_photomonitoring/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_photomonitoring/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_photomonitoring/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_photomonitoring/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_photomonitoring/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_photomonitoring/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_photomonitoring/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_photomonitoring/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_photomonitoring/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_photomonitoring/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ) : return self . filecache / f \"{self.hasher(timestamp)}.nc\" def config ( self , ** kwargs ) : out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ] ) except Exception as e : #traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ]= step_size out [ 'window_size' ]= x_offset out [ 'ccthreshold' ]= nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ]- y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ]- x_offset , step_size ) #deg2met = 4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ]+ meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ]+ meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print ( json . dumps ( out , indent = 4 )) return kwargs def updateConfig ( self , ** kwargs ) : ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ) : timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ) : try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ] ) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ] ) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ] ) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ] ) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ) : reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ) : #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ) : timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' ) [ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"Source"},{"location":"reference/hielen3/ext/source_photomonitoring/#ancestors-in-mro_2","text":"hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/#class-variables_2","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_photomonitoring/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache ()","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_photomonitoring/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_photomonitoring/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp )","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_photomonitoring/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : # traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) # deg2met = 4 . 4915764206 e - 06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) # print ( json . dumps ( out , indent = 4 )) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_photomonitoring/#data","text":"def data ( self , times = None , timeref = None , geometry = None , output = 'D' , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): # 1 Selezionare i file per estrarre i dati in base ai tempi # 2 Selezionare il delta di riferimento # ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] # COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data","title":"data"},{"location":"reference/hielen3/ext/source_photomonitoring/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_photomonitoring/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_photomonitoring/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 . 99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_photomonitoring/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_photomonitoring/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_photomonitoring/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_photomonitoring/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_photomonitoring/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'D' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"map"},{"location":"reference/hielen3/ext/source_photomonitoring/#ncfile","text":"def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"ncfile"},{"location":"reference/hielen3/ext/source_photomonitoring/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_photomonitoring/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_photomonitoring/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_photomonitoring/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_photomonitoring/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_photomonitoring/#updateconfig","text":"def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs","title":"updateConfig"},{"location":"reference/hielen3/ext/source_photomonitoring/#updatefeed","text":"def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"updateFeed"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/","text":"Module hielen3.ext.source_photomonitoring.phm View Source # coding=utf-8 from hielen3.source import MapSource , ActionSchema , GeoInfoSchema from hielen3.utils import LocalFile , ColorMap , loadjsonfile , FTPPath from hielen3.mapmanager import Multiraster import rasterio import json from rasterio.warp import transform_bounds , transform_geom import magic import os import re from pathlib import Path from .struct import config_NC , feed_NC , clean_feed_NC , generate_map , extract_data from marshmallow import fields from numpy import arange , full , zeros , log from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None ) class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True ) class Source ( MapSource ): ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ): return self . filecache / f \" { self . hasher ( timestamp ) } .nc\" def config ( self , ** kwargs ): out = super () . config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : #traceback.print_exc() pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) #deg2met=4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ) . close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print(json.dumps(out,indent=4)) return kwargs def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ) . mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ) . close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE!!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE!! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ]) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf=conf['value'] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ]) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ], threshold = conf [ 'ccthreshold' ], ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \" { reffieldinfile } _ { self . hasher ( timestamp )[: 14 ] } _ { output } .tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = count = 4 conf [ 'meta' ][ 'compress' ] = 'LZW' conf [ 'meta' ][ 'driver' ] = 'GTiff' conf [ 'meta' ][ 'dtype' ] = 'uint8' imgout = zeros ([ h , w , count ], dtype = conf [ 'meta' ][ 'dtype' ]) hd = min ( imgout . shape [ 0 ] - wsc , imgarray . shape [ 0 ]) wd = min ( imgout . shape [ 1 ] - wsc , imgarray . shape [ 1 ]) imgout [ wsc : hd , wsc : wd ,: count ] = imgarray [: hd - wsc ,: wd - wsc ,: count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ]) as dst : for i in range ( 0 , count ): dst . write ( imgout [:,:, i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser Variables log Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING cc_cmap ch_cmap displ_cmap error_messages ew_cmap ns_cmap opts param_file Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables CHANGE CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ) : return self . filecache / f \"{self.hasher(timestamp)}.nc\" def config ( self , ** kwargs ) : out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ] ) except Exception as e : #traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ]= step_size out [ 'window_size' ]= x_offset out [ 'ccthreshold' ]= nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ]- y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ]- x_offset , step_size ) #deg2met = 4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ]+ meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ]+ meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print ( json . dumps ( out , indent = 4 )) return kwargs def updateConfig ( self , ** kwargs ) : ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ) : timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ) : try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ] ) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ] ) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ] ) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ] ) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ) : reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ) : #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ) : timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' ) [ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser Ancestors (in MRO) hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : # traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) # deg2met = 4 . 4915764206 e - 06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) # print ( json . dumps ( out , indent = 4 )) return kwargs data def data ( self , times = None , timeref = None , geometry = None , output = 'D' , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): # 1 Selezionare i file per estrarre i dati in base ai tempi # 2 Selezionare il delta di riferimento # ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] # COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 . 99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( self , times = None , timeref = None , geometry = None , output = 'D' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser ncfile def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\" retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) updateConfig def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs updateFeed def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"Phm"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#module-hielen3extsource_photomonitoringphm","text":"View Source # coding=utf-8 from hielen3.source import MapSource , ActionSchema , GeoInfoSchema from hielen3.utils import LocalFile , ColorMap , loadjsonfile , FTPPath from hielen3.mapmanager import Multiraster import rasterio import json from rasterio.warp import transform_bounds , transform_geom import magic import os import re from pathlib import Path from .struct import config_NC , feed_NC , clean_feed_NC , generate_map , extract_data from marshmallow import fields from numpy import arange , full , zeros , log from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None ) class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True ) class Source ( MapSource ): ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ): return self . filecache / f \" { self . hasher ( timestamp ) } .nc\" def config ( self , ** kwargs ): out = super () . config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : #traceback.print_exc() pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) #deg2met=4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ) . close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print(json.dumps(out,indent=4)) return kwargs def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ) . mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ) . close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE!!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE!! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ]) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf=conf['value'] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ]) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ], threshold = conf [ 'ccthreshold' ], ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \" { reffieldinfile } _ { self . hasher ( timestamp )[: 14 ] } _ { output } .tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = count = 4 conf [ 'meta' ][ 'compress' ] = 'LZW' conf [ 'meta' ][ 'driver' ] = 'GTiff' conf [ 'meta' ][ 'dtype' ] = 'uint8' imgout = zeros ([ h , w , count ], dtype = conf [ 'meta' ][ 'dtype' ]) hd = min ( imgout . shape [ 0 ] - wsc , imgarray . shape [ 0 ]) wd = min ( imgout . shape [ 1 ] - wsc , imgarray . shape [ 1 ]) imgout [ wsc : hd , wsc : wd ,: count ] = imgarray [: hd - wsc ,: wd - wsc ,: count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ]) as dst : for i in range ( 0 , count ): dst . write ( imgout [:,:, i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser","title":"Module hielen3.ext.source_photomonitoring.phm"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#variables","text":"log","title":"Variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): _self_hints = { \"PhotoMonitoring Base\" : { 0 : [ \"param_file\" , \"The parameters.json file used for retrive 'step_size', 'window_size', 'cc_thresh'\" , True ], }, \"PhotoMonitoring Color Maps\" : { 0 : [ \"ns_cmap\" , \"East-Weast colormap range\" , True ], 1 : [ \"ew_cmap\" , \"Nord-South colormap range\" , True ], 2 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 3 : [ \"cc_cmap\" , \"Correlation Coefficient mask color map\" , True ], 4 : [ \"ch_cmap\" , \"Change Detection mask color map\" , True ] } } param_file = FTPPath ( required = False , allow_none = True ) ew_cmap = ColorMap ( required = False , allow_none = True , default = None ) ns_cmap = ColorMap ( required = False , allow_none = True , default = None ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) cc_cmap = ColorMap ( required = False , allow_none = True , default = None ) ch_cmap = ColorMap ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#ancestors-in-mro","text":"hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING cc_cmap ch_cmap displ_cmap error_messages ew_cmap ns_cmap opts param_file","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"PhotoMonitoring Feed\" : { 0 : [ \"NS_displacement\" , \"textfile containing the grid of the North-South displacement.\" , True ], 1 : [ \"EW_displacement\" , \"textfile containing the grid of the East-Weast displacement.\" , True ], 2 : [ \"CORR\" , \"textfile containing the grid of the correlation coefficents.\" , True ], 3 : [ \"CHANGE\" , \"textfile containing the grid of the change detection.\" , True ] } } NS_displacement = FTPPath ( required = False , allow_none = True ) EW_displacement = FTPPath ( required = False , allow_none = True ) CORR = FTPPath ( required = False , allow_none = True ) CHANGE = FTPPath ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#class-variables_1","text":"CHANGE CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def ncfile ( self , timestamp ) : return self . filecache / f \"{self.hasher(timestamp)}.nc\" def config ( self , ** kwargs ) : out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ] ) except Exception as e : #traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ]= step_size out [ 'window_size' ]= x_offset out [ 'ccthreshold' ]= nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ]- y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ]- x_offset , step_size ) #deg2met = 4.4915764206e-06 x_values = x_values * meta [ 'transform' ][ 0 ]+ meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ]+ meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) #print ( json . dumps ( out , indent = 4 )) return kwargs def updateConfig ( self , ** kwargs ) : ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ( [ [0,\"#00FF00\" ] , [ 1,\"#FF0000\" ] ] ) mu = self . getFeatureInfo ( 'map' ) [ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs def cleanConfig ( self , timestamp ) : timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache () def feed ( self , ** kwargs ) : try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ] ) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ] ) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ] ) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ] ) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0.99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ] . shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ) : reftime = self . lastActionBefore ( 'config' , timestamp ) [ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp ) def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ) : #1 Selezionare i file per estrarre i dati in base ai tempi #2 Selezionare il delta di riferimento #ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ) : timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] #COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' ) [ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"Source"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#ancestors-in-mro_2","text":"hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#class-variables_2","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () self . cleanFeatureCache ()","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] clean_feed_NC ( self . ncfile ( reftime ), timestamp ) self . cleanFeatureCache () self . _timeline_remove ( timestamp )","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): out = super (). config ( ** kwargs ) try : pars = loadjsonfile ( kwargs [ \"param_file\" ]) except Exception as e : # traceback . print_exc () pass try : x_offset = y_offset = pars [ 'window_size' ] except Exception : x_offset = y_offset = kwargs [ 'window_size' ] or 1 x_offset = int ( x_offset / 2 ) try : step_size = pars [ 'step_size' ] except Exception : step_size = kwargs [ 'step_size' ] or 1 try : nthr = pars [ 'CCthreshold' ] or 0 except Exception : nthr = kwargs [ 'ccthreshold' ] or 0 nthr = max ( nthr , 0 ) out [ 'step_size' ] = step_size out [ 'window_size' ] = x_offset out [ 'ccthreshold' ] = nthr meta = out [ 'meta' ] timestamp = out [ 'timestamp' ] x_values = arange ( step_size , step_size + meta [ 'width' ] - y_offset , step_size ) y_values = arange ( step_size , step_size + meta [ 'height' ] - x_offset , step_size ) # deg2met = 4 . 4915764206 e - 06 x_values = x_values * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = y_values * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] \"\"\" if self.getFeatureInfo('map')['geographic']: x_values=x_values*meta['transform'][0]+meta['transform'][2] y_values=y_values*meta['transform'][4]+meta['transform'][5] else: x_values=x_values*deg2met y_values=y_values*deg2met \"\"\" self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) kwargs . update ( out ) # print ( json . dumps ( out , indent = 4 )) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#data","text":"def data ( self , times = None , timeref = None , geometry = None , output = 'D' , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"D\" , ** kwargs ): # 1 Selezionare i file per estrarre i dati in base ai tempi # 2 Selezionare il delta di riferimento # ATTENZIONE ATTENZIONE !!! FUNZIONA CON UN SOLO FILE DI CONFIGURAZIONE !! if times is not None : if isinstance ( times , slice ): timefrom = times . start timeto = times . stop else : timefrom = times timeto = times else : timefrom = None timeto = None conf = self . lastActionBefore ( 'config' , timefrom ) reftime = conf [ 'timestamp' ] try : threshold = conf [ 'ccthreshold' ] except Exception as e : threshold = 0 dest_epsg = conf [ 'meta' ][ 'crs' ] # COMPORTAMENTO NORMALE geometry = transform_geom ( 'EPSG:4326' , dest_epsg , geometry ) geographic = self . getFeatureInfo ( 'map' )[ 'geographic' ] targetfile = self . ncfile ( reftime ) data = extract_data ( targetfile , geometry = geometry , times = times , output = output , timeref = timeref , geographic = geographic ) return data","title":"data"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): try : fileCHANGE = Path ( kwargs [ \"CHANGE\" ]) except Exception as e : fileCHANGE = None try : fileNS = Path ( kwargs [ \"NS_displacement\" ]) except Exception as e : fileNS = None try : fileEW = Path ( kwargs [ \"EW_displacement\" ]) except Exception as e : fileEW = None try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . lastActionBefore ( 'config' , timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None , \"ch\" : None } if fileCHANGE is None : frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) try : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) except FileNotFoundError as e : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 . 99 )) frames [ \"ch\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), fill_value = 0 )) else : frames [ \"ch\" ] = read_csv ( fileCHANGE , header = None ) frames [ \"ns\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"ew\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ch\" ]. shape ), fill_value = 0 )) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'D' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"D\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) if timeref is None : reffieldinfile = mapname else : reffieldinfile = self . hasher ( timeref ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile #conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size' ] ) timestamp , imgarray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] , threshold = conf [ 'ccthreshold' ] , ** ColorMap . parse_colormap ( cmap ), alphacolor = ( 0 , 0 , 0 ) ) imgname = f \"{reffieldinfile}_{self.hasher(timestamp)[:14]}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= count = 4 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imgout = zeros ( [ h,w,count ] , dtype = conf [ 'meta' ][ 'dtype' ] ) hd = min ( imgout . shape [ 0 ]- wsc , imgarray . shape [ 0 ] ) wd = min ( imgout . shape [ 1 ]- wsc , imgarray . shape [ 1 ] ) imgout [ wsc:hd,wsc:wd,:count ]= imgarray [ :hd-wsc,:wd-wsc,:count ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , count ) : dst . write ( imgout [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"map"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#ncfile","text":"def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"ncfile"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#updateconfig","text":"def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): ew_cmap = kwargs [ 'ew_cmap' ] or ColorMap . make_colormap () ns_cmap = kwargs [ 'ns_cmap' ] or ColorMap . make_colormap () displ_cmap = kwargs [ 'displ_cmap' ] or ColorMap . make_colormap () cc_cmap = kwargs [ 'cc_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) ch_cmap = kwargs [ 'ch_cmap' ] or ColorMap . make_colormap ([[ 0 , \"#00FF00\" ],[ 1 , \"#FF0000\" ]]) mu = self . getFeatureInfo ( 'map' )[ 'geographic' ] and \"m\" or \"mm\" self . setParamOperands ( 'East-West_Displacement' , cmap = ew_cmap , mu = mu ) self . setParamOperands ( 'North-South_Displacement' , cmap = ns_cmap , mu = mu ) self . setParamOperands ( 'Displacement' , cmap = displ_cmap , mu = mu ) self . setParamOperands ( 'Correlation_Coefficient' , cmap = cc_cmap , mu = mu ) self . setParamOperands ( 'Change_Detection' , cmap = ch_cmap , mu = '' ) self . cleanFeatureCache () return kwargs","title":"updateConfig"},{"location":"reference/hielen3/ext/source_photomonitoring/phm/#updatefeed","text":"def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"updateFeed"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/","text":"Module hielen3.ext.source_photomonitoring.struct View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError from numpy import datetime64 from pathlib import Path def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" # ch (change detection) informations dataset . createVariable ( \"ch\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ch\" ] . units = \"1\" dataset . variables [ \"ch\" ] . long_name = \"change_detection\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def clean_feed_NC ( target , time , ** kwargs ): origd = Dataset ( target ) newtarget = f \" { origd . filepath () } .tmp\" dataset = config_NC ( newtarget , origd . timestamp , origd . variables [ 'x' ][:], origd . variables [ 'y' ][:]) timevar = origd . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [:] == time ) try : position = int ( position [ 0 ]) except TypeError as e : raise e dataset . variables [ 'time' ][:] = timevar [: position ] . data for k in [ 'corr' , 'ns' , 'ew' , 'ch' ]: try : dataset . variables [ k ][: position ,:,:] = origd . variables [ k ][: position ,:,:] . data except KeyError as e : pass try : dataset . variables [ 'time' ][ position :] = timevar [ position + 1 :] . data for k in [ 'corr' , 'ns' , 'ew' , 'ch' ]: try : dataset . variables [ k ][ position :,:,:] = origd . variables [ k ][ position + 1 :,:,:] . data except KeyError as e : pass except Exception as e : print ( \"Ultimo\" ) origd . close () dataset . close () Path ( newtarget ) . replace ( target ) def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [:] == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West \"CC\" Correlation Coefficient \"CH\" Change Detection ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr ch = dataset . ch if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CC\" ): h = corr if param in ( \"CH\" ): h = ch # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CC\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.65 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor plt . close () return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = dataset . time [ - 1 ] . values else : timestamp = datetime64 ( agoodtime ( timestamp )) ds1 = dataset . sel ( time = timestamp ) . squeeze () m = ds1 . corr . mean () if m is not np . nan and m : ds1 = ds1 . where ( ds1 . corr > threshold ) try : timeref = datetime64 ( agoodtime ( timeref )) except Exception as e : timeref = None try : if np . isnat ( timeref ): timeref = None except Exception as e : timeref = None try : if np . isnat ( timestamp ): timestamp = None except Exception as e : timeref = None if timeref is not None : try : ds2 = dataset . sel ( time = timeref , method = 'nearest' ) . squeeze () ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except Exception as e : pass try : ds1 = ds1 . sel ( time = timestamp , method = 'nearest' ) . squeeze () except Exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , geographic = False , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : #TODO ricorda dataframe.rio.clip(geometries) #print (geometry) coords = list ( geojson . utils . coords ( geometry [ 0 ])) if not geographic : coords = list ( map ( lambda l : [ l [ 0 ], dataset . y [ - 1 ] - l [ 1 ]], coords ) ) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ - 1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ - 1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : return None #print (query) \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ) . sel ( time = times ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : try : ref = dataset . sel ( time = timeref , ** query ) . squeeze () dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew dst = dst . sel ( time = slice ( timeref , None , None )) except Exception as e : pass if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CC\" ): out = dst . corr if output in ( \"CH\" ): out = dst . ch if name == 'mean' : try : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) except Exception as e : pass out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) out = out [ out . columns [ 0 ]] #.map('{:,.4f}'.format) dataset . close () return out Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t clean_feed_NC def clean_feed_NC ( target , time , ** kwargs ) View Source def clean_feed_NC ( target , time , ** kwargs ) : origd = Dataset ( target ) newtarget = f \"{origd.filepath()}.tmp\" dataset = config_NC ( newtarget , origd . timestamp , origd . variables [ 'x' ][ : ] , origd . variables [ 'y' ][ : ] ) timevar = origd . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [ : ] == time ) try : position = int ( position [ 0 ] ) except TypeError as e : raise e dataset . variables [ 'time' ][ : ]= timevar [ :position ] . data for k in [ 'corr', 'ns', 'ew', 'ch' ] : try : dataset . variables [ k ][ :position,:,: ]= origd . variables [ k ][ :position,:,: ] . data except KeyError as e : pass try : dataset . variables [ 'time' ][ position: ]= timevar [ position+1: ] . data for k in [ 'corr', 'ns', 'ew', 'ch' ] : try : dataset . variables [ k ][ position:,:,: ]= origd . variables [ k ][ position+1:,:,: ] . data except KeyError as e : pass except Exception as e : print ( \"Ultimo\" ) origd . close () dataset . close () Path ( newtarget ). replace ( target ) config_NC def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # ch ( change detection ) informations dataset . createVariable ( \"ch\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ch\" ]. units = \"1\" dataset . variables [ \"ch\" ]. long_name = \"change_detection\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset extract_data def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , geographic = False , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , geographic = False , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) if not geographic : coords = list ( map ( lambda l : [ l[0 ] , dataset . y [ -1 ]- l [ 1 ] ] , coords ) ) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : return None #print ( query ) \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ). sel ( time = times ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : try : ref = dataset . sel ( time = timeref , ** query ). squeeze () dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew dst = dst . sel ( time = slice ( timeref , None , None )) except Exception as e : pass if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CC\" ) : out = dst . corr if output in ( \"CH\" ) : out = dst . ch if name == 'mean' : try : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) except Exception as e : pass out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) out = out [ out.columns[0 ] ]# . map ( '{:,.4f}' . format ) dataset . close () return out feed_NC def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [ : ] == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset generate_map def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = dataset . time [ - 1 ]. values else : timestamp = datetime64 ( agoodtime ( timestamp )) ds1 = dataset . sel ( time = timestamp ). squeeze () m = ds1 . corr . mean () if m is not np . nan and m : ds1 = ds1 . where ( ds1 . corr > threshold ) try : timeref = datetime64 ( agoodtime ( timeref )) except Exception as e : timeref = None try : if np . isnat ( timeref ): timeref = None except Exception as e : timeref = None try : if np . isnat ( timestamp ): timestamp = None except Exception as e : timeref = None if timeref is not None : try : ds2 = dataset . sel ( time = timeref , method = 'nearest' ). squeeze () ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except Exception as e : pass try : ds1 = ds1 . sel ( time = timestamp , method = 'nearest' ). squeeze () except Exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"Struct"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#module-hielen3extsource_photomonitoringstruct","text":"View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError from numpy import datetime64 from pathlib import Path def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" # ch (change detection) informations dataset . createVariable ( \"ch\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ch\" ] . units = \"1\" dataset . variables [ \"ch\" ] . long_name = \"change_detection\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def clean_feed_NC ( target , time , ** kwargs ): origd = Dataset ( target ) newtarget = f \" { origd . filepath () } .tmp\" dataset = config_NC ( newtarget , origd . timestamp , origd . variables [ 'x' ][:], origd . variables [ 'y' ][:]) timevar = origd . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [:] == time ) try : position = int ( position [ 0 ]) except TypeError as e : raise e dataset . variables [ 'time' ][:] = timevar [: position ] . data for k in [ 'corr' , 'ns' , 'ew' , 'ch' ]: try : dataset . variables [ k ][: position ,:,:] = origd . variables [ k ][: position ,:,:] . data except KeyError as e : pass try : dataset . variables [ 'time' ][ position :] = timevar [ position + 1 :] . data for k in [ 'corr' , 'ns' , 'ew' , 'ch' ]: try : dataset . variables [ k ][ position :,:,:] = origd . variables [ k ][ position + 1 :,:,:] . data except KeyError as e : pass except Exception as e : print ( \"Ultimo\" ) origd . close () dataset . close () Path ( newtarget ) . replace ( target ) def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [:] == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West \"CC\" Correlation Coefficient \"CH\" Change Detection ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr ch = dataset . ch if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CC\" ): h = corr if param in ( \"CH\" ): h = ch # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CC\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.65 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor plt . close () return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = dataset . time [ - 1 ] . values else : timestamp = datetime64 ( agoodtime ( timestamp )) ds1 = dataset . sel ( time = timestamp ) . squeeze () m = ds1 . corr . mean () if m is not np . nan and m : ds1 = ds1 . where ( ds1 . corr > threshold ) try : timeref = datetime64 ( agoodtime ( timeref )) except Exception as e : timeref = None try : if np . isnat ( timeref ): timeref = None except Exception as e : timeref = None try : if np . isnat ( timestamp ): timestamp = None except Exception as e : timeref = None if timeref is not None : try : ds2 = dataset . sel ( time = timeref , method = 'nearest' ) . squeeze () ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except Exception as e : pass try : ds1 = ds1 . sel ( time = timestamp , method = 'nearest' ) . squeeze () except Exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , geographic = False , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : #TODO ricorda dataframe.rio.clip(geometries) #print (geometry) coords = list ( geojson . utils . coords ( geometry [ 0 ])) if not geographic : coords = list ( map ( lambda l : [ l [ 0 ], dataset . y [ - 1 ] - l [ 1 ]], coords ) ) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ - 1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ - 1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : return None #print (query) \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ) . sel ( time = times ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : try : ref = dataset . sel ( time = timeref , ** query ) . squeeze () dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew dst = dst . sel ( time = slice ( timeref , None , None )) except Exception as e : pass if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CC\" ): out = dst . corr if output in ( \"CH\" ): out = dst . ch if name == 'mean' : try : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) except Exception as e : pass out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) out = out [ out . columns [ 0 ]] #.map('{:,.4f}'.format) dataset . close () return out","title":"Module hielen3.ext.source_photomonitoring.struct"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#clean_feed_nc","text":"def clean_feed_NC ( target , time , ** kwargs ) View Source def clean_feed_NC ( target , time , ** kwargs ) : origd = Dataset ( target ) newtarget = f \"{origd.filepath()}.tmp\" dataset = config_NC ( newtarget , origd . timestamp , origd . variables [ 'x' ][ : ] , origd . variables [ 'y' ][ : ] ) timevar = origd . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [ : ] == time ) try : position = int ( position [ 0 ] ) except TypeError as e : raise e dataset . variables [ 'time' ][ : ]= timevar [ :position ] . data for k in [ 'corr', 'ns', 'ew', 'ch' ] : try : dataset . variables [ k ][ :position,:,: ]= origd . variables [ k ][ :position,:,: ] . data except KeyError as e : pass try : dataset . variables [ 'time' ][ position: ]= timevar [ position+1: ] . data for k in [ 'corr', 'ns', 'ew', 'ch' ] : try : dataset . variables [ k ][ position:,:,: ]= origd . variables [ k ][ position+1:,:,: ] . data except KeyError as e : pass except Exception as e : print ( \"Ultimo\" ) origd . close () dataset . close () Path ( newtarget ). replace ( target )","title":"clean_feed_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#config_nc","text":"def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # ch ( change detection ) informations dataset . createVariable ( \"ch\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ch\" ]. units = \"1\" dataset . variables [ \"ch\" ]. long_name = \"change_detection\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset","title":"config_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#extract_data","text":"def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , geographic = False , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , geographic = False , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"NS\" North-South component \"EW\" Eeast-West component \"CC\" Correlation Coefficient \"CH\" Change Detection ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) if not geographic : coords = list ( map ( lambda l : [ l[0 ] , dataset . y [ -1 ]- l [ 1 ] ] , coords ) ) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : return None #print ( query ) \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ). sel ( time = times ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : try : ref = dataset . sel ( time = timeref , ** query ). squeeze () dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew dst = dst . sel ( time = slice ( timeref , None , None )) except Exception as e : pass if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CC\" ) : out = dst . corr if output in ( \"CH\" ) : out = dst . ch if name == 'mean' : try : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) except Exception as e : pass out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) out = out [ out.columns[0 ] ]# . map ( '{:,.4f}' . format ) dataset . close () return out","title":"extract_data"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#feed_nc","text":"def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar [ : ] == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset","title":"feed_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct/#generate_map","text":"def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = dataset . time [ - 1 ]. values else : timestamp = datetime64 ( agoodtime ( timestamp )) ds1 = dataset . sel ( time = timestamp ). squeeze () m = ds1 . corr . mean () if m is not np . nan and m : ds1 = ds1 . where ( ds1 . corr > threshold ) try : timeref = datetime64 ( agoodtime ( timeref )) except Exception as e : timeref = None try : if np . isnat ( timeref ): timeref = None except Exception as e : timeref = None try : if np . isnat ( timestamp ): timestamp = None except Exception as e : timeref = None if timeref is not None : try : ds2 = dataset . sel ( time = timeref , method = 'nearest' ). squeeze () ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except Exception as e : pass try : ds1 = ds1 . sel ( time = timestamp , method = 'nearest' ). squeeze () except Exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"generate_map"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/","text":"Module hielen3.ext.source_photomonitoring.struct_boh View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CH\" ): h = corr # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 1 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) . squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dst = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ])) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { #'method':'nearest', 'method' : 'pad' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : try : dst [ 'ns' ] = dst . ns - dst . ns . sel ( time = timeref ) dst [ 'ew' ] = dst . ew - dst . ns . sel ( time = timeref ) except Exception as e : print ( \"WARNING: \" , e ) if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CH\" ): out = dst . corr #out = out.where(dst.corr > threshold) out = out . sel ( ** query ) . sel ( time = times ) if name == 'mean' : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) dst . close () return out \"\"\" class Render(): @property def timeline(self): times = self.dataset.time.values return list(map(lambda x:str(x).replace('.000000000',''),(times))) @property def reftime(self): return self.dataset.timestamp def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False def extract_data(self,geom=(0,0),timefrom=None,timeto=None,param=\"D\",timeref=None): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom=agoodtime(timefrom) timeto=agoodtime(timeto) timeref=agoodtime(timeref) dst=self.dataset.sel(x=geom[0],y=geom[1],method='nearest').sel(time=slice(timefrom,timeto)) if timeref is not None and not self.isbasetime(timeref): ref=self.dataset.sel(x=geom[0],y=geom[1],time=timeref,method='nearest') dst['ns']=dst.ns-ref.ns dst['ew']=dst.ew-ref.ew if param in (\"D\"): out=np.sqrt(dst.ns**2+dst.ew**2) if param in (\"V\"): out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if param in (\"NS\"): out=dst.ns if param in (\"EW\"): out=dst.ew out = pd.DataFrame(out,index=out.time.values,columns=['xxx']).dropna() return out \"\"\" Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t config_NC def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset extract_data def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , threshold = 0 , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dst = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ] )) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { # 'method' : 'nearest' , 'method' : 'pad' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : try : dst [ 'ns' ]= dst . ns - dst . ns . sel ( time = timeref ) dst [ 'ew' ]= dst . ew - dst . ns . sel ( time = timeref ) except Exception as e : print ( \"WARNING: \" , e ) if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CH\" ) : out = dst . corr #out = out . where ( dst . corr > threshold ) out = out . sel ( ** query ). sel ( time = times ) if name == 'mean' : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) dst . close () return out feed_NC def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset generate_map def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ). squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"Struct Boh"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#module-hielen3extsource_photomonitoringstruct_boh","text":"View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CH\" ): h = corr # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 1 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) . squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dst = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ])) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { #'method':'nearest', 'method' : 'pad' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : try : dst [ 'ns' ] = dst . ns - dst . ns . sel ( time = timeref ) dst [ 'ew' ] = dst . ew - dst . ns . sel ( time = timeref ) except Exception as e : print ( \"WARNING: \" , e ) if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CH\" ): out = dst . corr #out = out.where(dst.corr > threshold) out = out . sel ( ** query ) . sel ( time = times ) if name == 'mean' : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) dst . close () return out \"\"\" class Render(): @property def timeline(self): times = self.dataset.time.values return list(map(lambda x:str(x).replace('.000000000',''),(times))) @property def reftime(self): return self.dataset.timestamp def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False def extract_data(self,geom=(0,0),timefrom=None,timeto=None,param=\"D\",timeref=None): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom=agoodtime(timefrom) timeto=agoodtime(timeto) timeref=agoodtime(timeref) dst=self.dataset.sel(x=geom[0],y=geom[1],method='nearest').sel(time=slice(timefrom,timeto)) if timeref is not None and not self.isbasetime(timeref): ref=self.dataset.sel(x=geom[0],y=geom[1],time=timeref,method='nearest') dst['ns']=dst.ns-ref.ns dst['ew']=dst.ew-ref.ew if param in (\"D\"): out=np.sqrt(dst.ns**2+dst.ew**2) if param in (\"V\"): out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if param in (\"NS\"): out=dst.ns if param in (\"EW\"): out=dst.ew out = pd.DataFrame(out,index=out.time.values,columns=['xxx']).dropna() return out \"\"\"","title":"Module hielen3.ext.source_photomonitoring.struct_boh"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#config_nc","text":"def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset","title":"config_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#extract_data","text":"def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , threshold = 0 , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dst = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ] )) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { # 'method' : 'nearest' , 'method' : 'pad' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : try : dst [ 'ns' ]= dst . ns - dst . ns . sel ( time = timeref ) dst [ 'ew' ]= dst . ew - dst . ns . sel ( time = timeref ) except Exception as e : print ( \"WARNING: \" , e ) if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CH\" ) : out = dst . corr #out = out . where ( dst . corr > threshold ) out = out . sel ( ** query ). sel ( time = times ) if name == 'mean' : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) dst . close () return out","title":"extract_data"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#feed_nc","text":"def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset","title":"feed_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_boh/#generate_map","text":"def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ). squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"generate_map"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/","text":"Module hielen3.ext.source_photomonitoring.struct_good View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CH\" ): h = corr # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 1 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) . squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ])) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ) . sel ( time = times ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : ref = dataset . sel ( time = timeref , ** query ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CH\" ): out = dst . corr #out = out.where(dst.corr > threshold) try : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) except : pass out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) dataset . close () return out \"\"\" class Render(): @property def timeline(self): times = self.dataset.time.values return list(map(lambda x:str(x).replace('.000000000',''),(times))) @property def reftime(self): return self.dataset.timestamp def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False def extract_data(self,geom=(0,0),timefrom=None,timeto=None,param=\"D\",timeref=None): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom=agoodtime(timefrom) timeto=agoodtime(timeto) timeref=agoodtime(timeref) dst=self.dataset.sel(x=geom[0],y=geom[1],method='nearest').sel(time=slice(timefrom,timeto)) if timeref is not None and not self.isbasetime(timeref): ref=self.dataset.sel(x=geom[0],y=geom[1],time=timeref,method='nearest') dst['ns']=dst.ns-ref.ns dst['ew']=dst.ew-ref.ew if param in (\"D\"): out=np.sqrt(dst.ns**2+dst.ew**2) if param in (\"V\"): out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if param in (\"NS\"): out=dst.ns if param in (\"EW\"): out=dst.ew out = pd.DataFrame(out,index=out.time.values,columns=['xxx']).dropna() return out \"\"\" Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t config_NC def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset extract_data def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , threshold = 0 , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ] )) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ). sel ( time = times ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : ref = dataset . sel ( time = timeref , ** query ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CH\" ) : out = dst . corr #out = out . where ( dst . corr > threshold ) try : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) except : pass out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) dataset . close () return out feed_NC def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset generate_map def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ). squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"Struct Good"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#module-hielen3extsource_photomonitoringstruct_good","text":"View Source # coding: utf-8 import numpy as np import pandas as pd import re import os import PIL import xarray as xr import datetime import scipy.ndimage as snd import matplotlib import geojson matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap , Normalize from netCDF4 import Dataset , date2num from json import JSONDecodeError def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = None , param = None , cmap = None , norm = None ): ''' params dataset: dataset at fixed time param: \"D\" displacment \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa try : span = norm . vmax - norm . vmin except Exception : span = 1 if step_size is None : step_size = 1 if param is None : param = \"D\" ns = dataset . ns ew = dataset . ew corr = dataset . corr if param in ( \"D\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns if param in ( \"CH\" ): h = corr # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) coords = [( \"y\" , Y ), ( \"x\" , X )] heatmap = xr . DataArray ( h , coords = coords ) if param in ( \"NS\" , \"EW\" , \"CH\" ): return dict ( heatmap = heatmap , vectors = None ) # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 5 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to # coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) # coeff=heatmap.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" coeff=heatmap.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) coeff=coeff.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(x=rollingside).construct('tmp').isel(x=slice(1, None, rollingside)).mean('tmp',skipna=False) angle=angle.rolling(y=rollingside).construct('tmp').isel(y=slice(1, None, rollingside)).mean('tmp',skipna=False) \"\"\" #SENZA MEDIA coeff = heatmap [:: rollingside ,:: rollingside ] angle = angle [:: rollingside ,:: rollingside ] # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma #coeff=coeff.where(coeff<coeff.mean()+coeff.std()*10) coeff = ( coeff / span ) #coeff=coeff.where(coeff>0) #coeff=coeff.where(coeff<50) # normalizzo su un valore adeguato # coeff=coeff/(coeff.mean()) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente #angle=angle.where(np.abs(coeff) > np.abs(coeff.mean())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff #if param in (\"V\"): # heatmap=heatmap.where(heatmap is np.nan) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , cmap = None , norm = None , alphacolor = ( 0 , 0 , 0 )): if cmap is None : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , [ \"red\" , \"green\" , \"blue\" ]) if norm is None : norm = Normalize ( vmin =- 2.5 , vmax = 2.5 ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 1 , origin = 'upper' , cmap = cmap , norm = norm ) # ax.imshow(heatmap,origin='upper',cmap=cmap,norm=norm) if vectors is not None : #ax.quiver(*vectors,width=0.0020,color='white',scale=100) ax . quiver ( * vectors , color = 'white' , units = 'dots' , scale_units = 'xy' , angles = 'uv' , scale = 0.01 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 1 , 2 , 3 , 0 ]] red , green , blue , alpha = data . T # Temporarily unpack the bands for readability sel = ( alpha == 0 ) data [ ... , : - 1 ][ sel . T ] = alphacolor return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) . squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )] def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ])) geotype = str ( geometry [ 0 ][ 'type' ]) name = \"\" #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ) . sel ( time = times ) # if timeref is not None and not targetfile.isbasetime(timeref): if timeref is not None : ref = dataset . sel ( time = timeref , ** query ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"D\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in (\"V\"): # out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew if output in ( \"CH\" ): out = dst . corr #out = out.where(dst.corr > threshold) try : out = out . mean ( dim = 'x' , skipna = True ) . mean ( dim = 'y' , skipna = True ) except : pass out . name = name out = out . to_dataframe () . reset_index () . set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] }, axis = 1 , result_type = 'expand' ) out = out . reset_index () . set_index ([ 'time' , 'name' ]) . unstack () . droplevel ( 0 , axis = 1 ) dataset . close () return out \"\"\" class Render(): @property def timeline(self): times = self.dataset.time.values return list(map(lambda x:str(x).replace('.000000000',''),(times))) @property def reftime(self): return self.dataset.timestamp def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False def extract_data(self,geom=(0,0),timefrom=None,timeto=None,param=\"D\",timeref=None): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom=agoodtime(timefrom) timeto=agoodtime(timeto) timeref=agoodtime(timeref) dst=self.dataset.sel(x=geom[0],y=geom[1],method='nearest').sel(time=slice(timefrom,timeto)) if timeref is not None and not self.isbasetime(timeref): ref=self.dataset.sel(x=geom[0],y=geom[1],time=timeref,method='nearest') dst['ns']=dst.ns-ref.ns dst['ew']=dst.ew-ref.ew if param in (\"D\"): out=np.sqrt(dst.ns**2+dst.ew**2) if param in (\"V\"): out=np.rad2deg(np.arctan2(dst.ns,dst.ew)) if param in (\"NS\"): out=dst.ns if param in (\"EW\"): out=dst.ew out = pd.DataFrame(out,index=out.time.values,columns=['xxx']).dropna() return out \"\"\"","title":"Module hielen3.ext.source_photomonitoring.struct_good"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#config_nc","text":"def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset","title":"config_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#extract_data","text":"def extract_data ( targetfile , geometry = None , times = None , output = 'D' , timeref = None , threshold = 0 , ** kwargs ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( targetfile , geometry = None , times = None , output = \"D\" , timeref = None , threshold = 0 , ** kwargs ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"D\" Displacement \"V\" Direction \"NS\" North-South component \"EW\" Eeast-West component ''' dataset = xr . open_dataset ( targetfile ) #1 manipola json #2 se json \u00e8 un punto extrac \"nearest\" #3 altrimenti boundigbox e slices if times is None : times = slice ( None , None , None ) if geometry is None : return None \"\"\" geometry = geojson.Point([800,800]) else: geometry = geojson.loads(geojson.dumps(geometry)) coords=list(geojson.utils.coords(geometry[0])) \"\"\" try : coords = list ( geojson . utils . coords ( geometry [ 0 ] )) geotype = str ( geometry [ 0 ][ 'type' ] ) name = \"\" #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = pd . DataFrame ( coords ) query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max ()), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max ()) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) except Exception as e : print ( e ) return None \"\"\" def isbasetime(self,time): try: return np.datetime64(time) == np.datetime64(self.reftime) except Exception: return False \"\"\" timeref = agoodtime ( timeref ) dst = dataset . sel ( ** query ). sel ( time = times ) # if timeref is not None and not targetfile . isbasetime ( timeref ) : if timeref is not None : ref = dataset . sel ( time = timeref , ** query ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if output in ( \"D\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) #if output in ( \"V\" ) : # out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew if output in ( \"CH\" ) : out = dst . corr #out = out . where ( dst . corr > threshold ) try : out = out . mean ( dim = 'x' , skipna = True ). mean ( dim = 'y' , skipna = True ) except : pass out . name = name out = out . to_dataframe (). reset_index (). set_index ( 'time' ) out = out . apply ( lambda a : { \"name\" : name , \"value\" : a [ name ] } , axis = 1 , result_type = 'expand' ) out = out . reset_index (). set_index ( [ 'time','name' ] ). unstack (). droplevel ( 0 , axis = 1 ) dataset . close () return out","title":"extract_data"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#feed_nc","text":"def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset","title":"feed_NC"},{"location":"reference/hielen3/ext/source_photomonitoring/struct_good/#generate_map","text":"def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , cmap = None , norm = None , threshold = 0 , ** kwargs ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ). squeeze () if ds1 . corr . min is not np . nan and ds1 . corr . max is not np . nan and threshold > 0 : ds1 = ds1 . where ( ds1 . corr > threshold ) if timeref is not None : try : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs except exception as e : pass managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size , cmap = cmap , norm = norm ) dataset . close () return [ timestamp , _render ( ** managed , cmap = cmap , norm = norm )]","title":"generate_map"},{"location":"reference/hielen3/ext/source_rawsource/","text":"Module hielen3.ext.source_rawsource View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .rawsource import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ] Sub-modules hielen3.ext.source_rawsource.rawsource hielen3.ext.source_rawsource.rawsource_ Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts param_list Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages input_file opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' @property def incomesfile ( self ) : return self . filecache / 'last_load.csv' def config ( self , ** kwargs ) : self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ] , \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Instance variables incomesfile Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , times = None , column = None , ** kwargs ) View Source def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Index"},{"location":"reference/hielen3/ext/source_rawsource/#module-hielen3extsource_rawsource","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .rawsource import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ]","title":"Module hielen3.ext.source_rawsource"},{"location":"reference/hielen3/ext/source_rawsource/#sub-modules","text":"hielen3.ext.source_rawsource.rawsource hielen3.ext.source_rawsource.rawsource_","title":"Sub-modules"},{"location":"reference/hielen3/ext/source_rawsource/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_rawsource/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_rawsource/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts param_list","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_rawsource/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/#class-variables_1","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages input_file opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' @property def incomesfile ( self ) : return self . filecache / 'last_load.csv' def config ( self , ** kwargs ) : self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ] , \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/source_rawsource/#ancestors-in-mro_2","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/#instance-variables_2","text":"incomesfile","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_rawsource/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_rawsource/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_rawsource/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_rawsource/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_rawsource/#data","text":"def data ( self , times = None , column = None , ** kwargs ) View Source def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/source_rawsource/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_rawsource/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_rawsource/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_rawsource/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_rawsource/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_rawsource/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_rawsource/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_rawsource/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_rawsource/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_rawsource/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_rawsource/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/","text":"Module hielen3.ext.source_rawsource.rawsource View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import ParamsDefinition , LocalFile from pandas import read_csv , DatetimeIndex , Series , DataFrame from marshmallow import fields from pathlib import Path from numpy import unique import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None ) class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True ) class Source ( DataSource ): ''' RawSourceData manager ''' @property def incomesfile ( self ): return self . filecache / 'last_load.csv' def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def feed ( self , ** kwargs ): _input_ = kwargs [ 'input_file' ] incomes = DataFrame ([]) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ): try : incomes = read_csv ( str ( _input_ ), header = None , index_col = [ 0 ], parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )): incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ) . sort_index () idx = unique ( loaded . index . values , return_index = True )[ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , column = None , ** kwargs ): if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col = [ 0 ], parse_dates = True , sep = \";\" ) if column is not None : out = out [ out . columns [ column ]] out = out . squeeze () except Exception as e : #traceback.print_exc() return Series () # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ] Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts param_list Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages input_file opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' @property def incomesfile ( self ) : return self . filecache / 'last_load.csv' def config ( self , ** kwargs ) : self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ] , \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Instance variables incomesfile Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs data def data ( self , times = None , column = None , ** kwargs ) View Source def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Rawsource"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#module-hielen3extsource_rawsourcerawsource","text":"View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import ParamsDefinition , LocalFile from pandas import read_csv , DatetimeIndex , Series , DataFrame from marshmallow import fields from pathlib import Path from numpy import unique import hielen3.tools.calc as calc import traceback class ConfigSchema ( ActionSchema ): _self_hints = { \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None ) class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True ) class Source ( DataSource ): ''' RawSourceData manager ''' @property def incomesfile ( self ): return self . filecache / 'last_load.csv' def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {}, \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ): pass def feed ( self , ** kwargs ): _input_ = kwargs [ 'input_file' ] incomes = DataFrame ([]) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ): try : incomes = read_csv ( str ( _input_ ), header = None , index_col = [ 0 ], parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )): incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ) . sort_index () idx = unique ( loaded . index . values , return_index = True )[ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , column = None , ** kwargs ): if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col = [ 0 ], parse_dates = True , sep = \";\" ) if column is not None : out = out [ out . columns [ column ]] out = out . squeeze () except Exception as e : #traceback.print_exc() return Series () # out.columns=[self.uid] # out.index=to_datetime(out.index) return out . loc [ times ]","title":"Module hielen3.ext.source_rawsource.rawsource"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): _self_hints ={ \"Raw Source info\" : { 0 :[ \"param_list\" , \"list of parameters\" ] } } param_list = ParamsDefinition ( required = False , allow_none = True , default = None )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts param_list","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Feed\" : { 0 :[ \"input_file\" , \"input file to load\" ], }, } input_file = LocalFile ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#class-variables_1","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages input_file opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' @property def incomesfile ( self ) : return self . filecache / 'last_load.csv' def config ( self , ** kwargs ) : self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ] , \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ] , \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#ancestors-in-mro_2","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#instance-variables_2","text":"incomesfile","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): self . filecache . mkdir () chlist = kwargs [ 'param_list' ] if chlist is None : chlist = [] \"\"\" param:0 column:1 ing_mu:2 \"\"\" for chinfo in chlist : chstruct = { \"param\" : chinfo [ 0 ], \"struct\" : { \"cache\" : \"active\" , \"modules\" : {} , \"mu\" : chinfo [ 2 ], \"operands\" : { \"column\" : chinfo [ 1 ] } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#data","text":"def data ( self , times = None , column = None , ** kwargs ) View Source def data ( self , times = None , column = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) loaded = self . incomesfile try : out = read_csv ( str ( loaded ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) if column is not None : out = out [ out.columns[column ] ] out = out . squeeze () except Exception as e : #traceback . print_exc () return Series () # out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ) : _input_ = kwargs [ 'input_file' ] incomes = DataFrame ( [] ) if _input_ is not None : #try if is a file if isinstance ( _input_ , str ) : try : incomes = read_csv ( str ( _input_ ), header = None , index_col =[ 0 ] , parse_dates = True , sep = \";\" ) except Exception as e : pass if isinstance ( _input_ , ( DataFrame , Series )) : incomes = _input_ if not incomes . empty : loaded = self . data () try : loaded = loaded . to_frame () except Exception as e : pass try : incomes = incomes . to_frame () except Exception as e : pass #IT COULD RAISE AN EXCEPTION IF COLUMNS NUMBERS DO NOT MATCH if loaded . empty : loaded = incomes else : incomes . columns = loaded . columns loaded = loaded . append ( incomes ). sort_index () idx = unique ( loaded . index . values , return_index = True ) [ 1 ] loaded = loaded . iloc [ idx ] if not loaded . empty : loaded . to_csv ( self . incomesfile , header = None , sep = \";\" ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_rawsource/rawsource/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/","text":"Module hielen3.ext.source_rawsource.rawsource_ View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LocalFile import shutil from pathlib import Path from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback class ConfigSchema ( ActionSchema ): pass class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Configuration\" : { 0 :[ \"Input\" , ], }, \"TinSAR Color Maps and Style\" : { 0 : [ \"displ_cmap\" , \"displacement colormap range\" ], } } DATAFILE = LocalFile ( required = False , allow_none = True ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): return kwargs def cleanConfig ( self , timestamp ): pass def feed ( self , ** kwargs ): self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ], str ( destfile )) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , ** kwargs ): if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col = [ 0 ], parse_dates = True ) out . columns = [ self . uid ] # out.index=to_datetime(out.index) return out . loc [ times ] Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): pass Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Configuration\" : { 0 :[ \"Input\" , ], }, \"TinSAR Color Maps and Style\" : { 0 : [ \"displ_cmap\" , \"displacement colormap range\" ], } } DATAFILE = LocalFile ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables DATAFILE Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ] , str ( destfile )) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col =[ 0 ] , parse_dates = True ) out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] Ancestors (in MRO) hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return kwargs data def data ( self , times = None , ** kwargs ) View Source def data ( self , times = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col =[ 0 ] , parse_dates = True ) out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ] deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ], str ( destfile )) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"Rawsource "},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#module-hielen3extsource_rawsourcerawsource_","text":"View Source # coding=utf-8 from hielen3.source import ActionSchema , DataSource from hielen3.utils import LocalFile import shutil from pathlib import Path from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback class ConfigSchema ( ActionSchema ): pass class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Configuration\" : { 0 :[ \"Input\" , ], }, \"TinSAR Color Maps and Style\" : { 0 : [ \"displ_cmap\" , \"displacement colormap range\" ], } } DATAFILE = LocalFile ( required = False , allow_none = True ) class Source ( DataSource ): ''' RawSourceData manager ''' def config ( self , ** kwargs ): return kwargs def cleanConfig ( self , timestamp ): pass def feed ( self , ** kwargs ): self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ], str ( destfile )) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , ** kwargs ): if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col = [ 0 ], parse_dates = True ) out . columns = [ self . uid ] # out.index=to_datetime(out.index) return out . loc [ times ]","title":"Module hielen3.ext.source_rawsource.rawsource_"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): pass","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#ancestors-in-mro","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"Raw Source Configuration\" : { 0 :[ \"Input\" , ], }, \"TinSAR Color Maps and Style\" : { 0 : [ \"displ_cmap\" , \"displacement colormap range\" ], } } DATAFILE = LocalFile ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#class-variables_1","text":"DATAFILE Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#source","text":"class Source ( feature ) RawSourceData manager View Source class Source ( DataSource ) : ''' RawSourceData manager ''' def config ( self , ** kwargs ) : return kwargs def cleanConfig ( self , timestamp ) : pass def feed ( self , ** kwargs ) : self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ] , str ( destfile )) return kwargs def cleanFeed ( self , timestamp ) : pass def data ( self , times = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col =[ 0 ] , parse_dates = True ) out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"Source"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#ancestors-in-mro_2","text":"hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): pass","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return kwargs","title":"config"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#data","text":"def data ( self , times = None , ** kwargs ) View Source def data ( self , times = None , ** kwargs ) : if times is None : times = slice ( None , None , None ) out = read_csv ( str ( self . filecache / \"incoming.csv\" ), header = None , index_col =[ 0 ] , parse_dates = True ) out . columns =[ self.uid ] # out . index = to_datetime ( out . index ) return out . loc [ times ]","title":"data"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): self . filecache . mkdir () destfile = self . filecache / \"incoming.csv\" input = kwargs [ \"DATAFILE\" ] shutil . copy ( kwargs [ \"DATAFILE\" ], str ( destfile )) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_rawsource/rawsource_/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_tinsar/","text":"Module hielen3.ext.source_tinsar View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .tin import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ] Sub-modules hielen3.ext.source_tinsar.cloudpainter hielen3.ext.source_tinsar.struct hielen3.ext.source_tinsar.tin Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING ampli_cmap displ_cmap error_messages master_cloud opts point_style series_file Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING amplitude_cloud amplitude_geotiff displacement_cloud displacement_geotiff error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( CloudSource ) : ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ) : if brandnewconf : kwargs [ 'opacity' ]= 50 out = super (). config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ]= kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI : displ_cmap , ampli_cmap def_cmap =[ [ a/100, rgb2hex(jet (a/100)[0:3 ] ) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ]= kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ]= kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ] ) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ] ) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ] , str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items () : cloudman . makePotree ( w , k ) #print ( json . dumps ( out , indent = 4 )) out [ 'point_style' ]= kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ] ) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ] ) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None )) [ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ) : return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ) : return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ) : \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ) : try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ( [] ) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates =[ 0 ] , date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ). head ( 4 ). T points . columns = list ( map ( str . lower , points . columns )) labels = points [ [ x for x in points.columns if x not in ['x','y','z' ] ]] points = points [ ['x','y','z' ] ] points [ 'label' ]= labels points . columns =[ 'x','y','z','label' ] points [ 'puid' ]= points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples () : prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" : [ x,y,z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list =[ [\"Displacement\",0,\"mm\" ] ] ) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) subitems . add ( subuid ) if resp not in ( 200 , 201 ) : print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing {label}, '{resp}' occurs\" ) rs . feed ( input_file = series [ label ] ) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ] ) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ] ) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ] ) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ] ) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ] ) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ] ) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ] ) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser Ancestors (in MRO) hielen3.source.CloudSource hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) da analizzare View Source def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) cloud def cloud ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs ) data def data ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) updateConfig def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs ) updateFeed def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"Index"},{"location":"reference/hielen3/ext/source_tinsar/#module-hielen3extsource_tinsar","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .tin import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ]","title":"Module hielen3.ext.source_tinsar"},{"location":"reference/hielen3/ext/source_tinsar/#sub-modules","text":"hielen3.ext.source_tinsar.cloudpainter hielen3.ext.source_tinsar.struct hielen3.ext.source_tinsar.tin","title":"Sub-modules"},{"location":"reference/hielen3/ext/source_tinsar/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_tinsar/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_tinsar/#ancestors-in-mro","text":"hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING ampli_cmap displ_cmap error_messages master_cloud opts point_style series_file","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_tinsar/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_tinsar/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_tinsar/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_tinsar/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_tinsar/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_tinsar/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_tinsar/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_tinsar/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_tinsar/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_tinsar/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_tinsar/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_tinsar/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/#class-variables_1","text":"Meta OPTIONS_CLASS TYPE_MAPPING amplitude_cloud amplitude_geotiff displacement_cloud displacement_geotiff error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_tinsar/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_tinsar/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_tinsar/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_tinsar/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_tinsar/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_tinsar/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_tinsar/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_tinsar/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_tinsar/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_tinsar/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_tinsar/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( CloudSource ) : ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ) : if brandnewconf : kwargs [ 'opacity' ]= 50 out = super (). config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ]= kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI : displ_cmap , ampli_cmap def_cmap =[ [ a/100, rgb2hex(jet (a/100)[0:3 ] ) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ]= kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ]= kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ] ) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ] ) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ] , str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items () : cloudman . makePotree ( w , k ) #print ( json . dumps ( out , indent = 4 )) out [ 'point_style' ]= kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ] ) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ] ) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None )) [ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ) : return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ) : return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ) : \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ) : try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ( [] ) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates =[ 0 ] , date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ). head ( 4 ). T points . columns = list ( map ( str . lower , points . columns )) labels = points [ [ x for x in points.columns if x not in ['x','y','z' ] ]] points = points [ ['x','y','z' ] ] points [ 'label' ]= labels points . columns =[ 'x','y','z','label' ] points [ 'puid' ]= points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples () : prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" : [ x,y,z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list =[ [\"Displacement\",0,\"mm\" ] ] ) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) subitems . add ( subuid ) if resp not in ( 200 , 201 ) : print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing {label}, '{resp}' occurs\" ) rs . feed ( input_file = series [ label ] ) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ] ) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ] ) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ] ) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ] ) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ] ) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ] ) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ] ) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"Source"},{"location":"reference/hielen3/ext/source_tinsar/#ancestors-in-mro_2","text":"hielen3.source.CloudSource hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/#class-variables_2","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_tinsar/#cleanconfig","text":"def cleanConfig ( self , timestamp ) da analizzare View Source def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir ()","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_tinsar/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_tinsar/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp )","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_tinsar/#cloud","text":"def cloud ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"cloud"},{"location":"reference/hielen3/ext/source_tinsar/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs )","title":"config"},{"location":"reference/hielen3/ext/source_tinsar/#data","text":"def data ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser","title":"data"},{"location":"reference/hielen3/ext/source_tinsar/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_tinsar/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_tinsar/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_tinsar/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_tinsar/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_tinsar/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_tinsar/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_tinsar/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_tinsar/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"map"},{"location":"reference/hielen3/ext/source_tinsar/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_tinsar/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_tinsar/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_tinsar/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_tinsar/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_tinsar/#updateconfig","text":"def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs )","title":"updateConfig"},{"location":"reference/hielen3/ext/source_tinsar/#updatefeed","text":"def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"updateFeed"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/","text":"Module hielen3.ext.source_tinsar.cloudpainter View Source # coding: utf-8 import pandas as pd import numpy as np import laspy from pathlib import Path from scipy.spatial import KDTree from matplotlib.colors import Normalize , Colormap , LinearSegmentedColormap from matplotlib.cm import ScalarMappable import getopt import sys def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance (dist) and value clouds relative ## ids (idsv). the position of each cell in the arrays reflects the cells ## in the base cloud. k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]] . values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ) . stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ) . stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud (base cloud index) and his neighbous (value cloud ids, ## distance and neighbour group progressive). Then we clean the infinite ## distances (points with no neighbours) values = dist . to_frame () . join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv', allows to join with the value cloud and add the 'v' # info values = values . reset_index () . set_index ( \"idsv\" ) . sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance', allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]) . sort_index () ## Here we calculte the [distance based, weighted] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ) . apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) if norm is None : norm = Normalize ( vmin = vals . min (), vmax = vals . max (), clip = True ) if not isinstance ( cmap , ( Colormap , str )): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) # mapper = ScalarMappable(cmap=cmap) cols = mapper . to_rgba ( vals ) return cols def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , norm = norm ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ 'r' , 'g' , 'b' ]] * 255 #65536 if basecld is not None : result = basecld . join ( colors , how = \"left\" ) . replace ( np . nan , 0.9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) \"\"\" result[\"r\"]=result[\"r\"]*65536 result[\"g\"]=result[\"g\"]*65536 result[\"b\"]=result[\"b\"]*65536 \"\"\" return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] #65536 def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0.01 , 0.01 , 0.01 ]): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] y = frame [ 'y' ] z = frame [ 'z' ] r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () def makemultilaz ( csvfile , targetpath = None , sep = \" \" , basemanage = 'i' , scale = [ 0.000001 , 0.000001 , 0.000001 ], columns = None , cmap = 'jet' , norm = None ): \"\"\" o : only i : ignore a : also \"\"\" try : targetpath = Path ( targetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower , cloud . columns )) fields = [ c for c in cloud . columns if c not in [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] ] if basemanage == 'o' and 'r' in cloud . columns : fields = [ 'base' ] if basemanage == 'a' : fields . append ( 'base' ) lazdone = {} for c in fields : if c == 'base' : theframe = cloud [[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] else : theframe = paint ( cloud [[ 'x' , 'y' , 'z' , c ]], cmap = cmap , norm = norm )[[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] #colors='jet' lazpath = str ( targetpath / f ' { c } .laz' ) makelaz ( theframe , lazpath , scale = scale ) lazdone [ c ] = lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \"#ee55ee\"], [ -66.6 ,\"#0000ff\"] , [-33.3, \"#00ffff\" ],[0,\"#00FF00\"] ,[ 33.3, \"#ffff00\"], [ 66.6,\"#ffa500\" ], [ 100, \"#FF0000\" ]])) r={ 'cmap':ListedColormap([\"#ee55ee\", \"#0000ff\",\"#00ffff\",\"#00FF00\",\"#ffff00\",\"#ffa500\",\"#FF0000\"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\" \"\"\" import open3d as o3d def openpcl(res): #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d.geometry.PointCloud() pcl.points = o3d.utility.Vector3dVector(res[[\"x\", \"y\", \"z\"]].values) pcl.colors = o3d.utility.Vector3dVector(res[[\"r\", \"g\", \"b\"]].values) o3d.visualization.draw_geometries([pcl]) \"\"\" def usage (): helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) if __name__ == \"__main__\" : #DEFAULTS datacloud = None basecloud = None group = 1 distance = 5 degree = 0 colors = [ 'violet' , 'blue' , 'cyan' , 'green' , 'yellow' , 'orange' , 'red' ] outfile = None output = 'las' vmin =- 500 vmax = 500 try : opts , args = getopt . getopt ( sys . argv [ 1 :], \"b:g:d:D:c:o:O:v:V:\" , [ \"basecloud=\" , \"group=\" , \"distance=\" , \"degree=\" , \"colors=\" , \"outfile=\" , \"output=\" , \"vmin=\" , \"vmax=\" ]) for o , a in opts : if o in ( \"-b\" , \"--basecloud\" ): basecloud = a elif o in ( \"-g\" , \"--group\" ): group = a elif o in ( \"-d\" , \"--distance\" ): distance = a elif o in ( \"-D\" , \"--degree\" ): degree = a elif o in ( \"-c\" , \"--colors\" ): colors = a . split ( \",\" ) elif o in ( \"-o\" , \"--outfile\" ): outfile = a elif o in ( \"-O\" , \"--output\" ): output = a elif o in ( \"-v\" , \"--vmin\" ): vmin = a elif o in ( \"-V\" , \"--vmax\" ): vmax = a else : assert False , \"unhandled option\" try : infile = args [ 0 ] except Exception : raise Exception ( f \"No file\" ) try : norm = norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) except Exception as e : norm = None datacloud = pd . read_csv ( infile ) datacloud = datacloud [ datacloud . columns [ 0 : 4 ]] datacloud . columns = [ \"X\" , \"Y\" , \"Z\" , \"V\" ] if basecloud is not None : basecloud = pd . read_csv ( basecloud ) basecloud = basecloud [ basecloud . columns [ 0 : 3 ]] basecloud . columns = [ \"X\" , \"Y\" , \"Z\" ] result = paint ( valcld = datacloud , basecld = basecloud , distance = distance , degree = degree , group = group , cmap = colors , norm = norm ) if outfile is None : outfile = '.' . join ([ infile , output ]) if output == 'las' : makelaz ( result [[ \"x\" , \"y\" , \"z\" , \"r\" , \"g\" , \"b\" ]], outfile ) elif output == 'csv' : result . to_csv ( outfile , index = False ) # elif output == 'view': # openpcl(result) else : raise Exception ( f 'unkwnown output type: { output } ' ) except Exception as err : # print help information and exit: print ( err ) usage () sys . exit ( 2 ) Functions colorize def colorize ( vals , cmap = [ 'red' , 'green' , 'blue' ], norm = None ) Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) if norm is None : norm = Normalize ( vmin = vals . min (), vmax = vals . max (), clip = True ) if not isinstance ( cmap , ( Colormap , str )): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) # mapper = ScalarMappable ( cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols makelaz def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0.01 , 0.01 , 0.01 ] ) View Source def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0 . 01 , 0 . 01 , 0 . 01 ]): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] y = frame [ 'y' ] z = frame [ 'z' ] r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () makemultilaz def makemultilaz ( csvfile , targetpath = None , sep = ' ' , basemanage = 'i' , scale = [ 1e-06 , 1e-06 , 1e-06 ], columns = None , cmap = 'jet' , norm = None ) o : only i : ignore a : also View Source def makemultilaz ( csvfile , targetpath = None , sep = \" \" , basemanage = 'i' , scale =[ 0.000001,0.000001,0.000001 ] , columns = None , cmap = 'jet' , norm = None ) : \"\"\" o : only i : ignore a : also \"\"\" try : targetpath = Path ( targetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower , cloud . columns )) fields =[ c for c in cloud.columns if c not in ['x','y','z','r','g','b' ] ] if basemanage == 'o' and 'r' in cloud . columns : fields =[ 'base' ] if basemanage == 'a' : fields . append ( 'base' ) lazdone = {} for c in fields : if c == 'base' : theframe = cloud [ ['x','y','z','r','g','b' ] ] else : theframe = paint ( cloud [ ['x','y','z',c ] ] , cmap = cmap , norm = norm ) [ ['x','y','z','r','g','b' ] ] #colors = 'jet' lazpath = str ( targetpath / f '{c}.laz' ) makelaz ( theframe , lazpath , scale = scale ) lazdone [ c ]= lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \" #ee55ee \"], [ -66.6 ,\" #0000ff \"] , [-33.3, \" #00ffff \" ],[0,\" #00FF00 \"] ,[ 33.3, \" #ffff00 \"], [ 66.6,\" #ffa500 \" ], [ 100, \" #FF0000 \" ]])) r={ 'cmap':ListedColormap([\" #ee55ee \", \" #0000ff \",\" #00ffff \",\" #00FF00 \",\" #ffff00 \",\" #ffa500 \",\" #FF0000 \"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\" paint def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ 'red' , 'green' , 'blue' ], norm = None ) Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , norm = norm ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ 'r' , 'g' , 'b' ]] * 255 # 65536 if basecld is not None : result = basecld . join ( colors , how = \"left\" ). replace ( np . nan , 0 . 9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) \"\"\" result[\" r \"]=result[\" r \"]*65536 result[\" g \"]=result[\" g \"]*65536 result[\" b \"]=result[\" b \"]*65536 \"\"\" return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] usage def usage ( ) View Source def usage () : helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) valorize def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ) Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . i . e : N1 ----------P----N2 Given two neighbours , N1 and N2 , for a fixed point P where : d ( N1 ) = 10 ; v ( N1 ) =- 15 d ( N2 ) = 4 ; v ( N2 ) = 3 v ( P ) = ( - 15 / 10 ** d + 3 / 4 ** d ) / ( 1 / 10 ** d + 1 / 4 ** d ) being d the degree , we have : d = 0 : v ( P ) = - 6 < -- arimetic mean d = 1 : v ( P ) = - 2 . 14 d = 2 : v ( P ) = 0 . 51 d = 3 : v ( P ) = 1 . 91 d = 4 : v ( P ) = 2 . 55 d = 5 : v ( P ) = 2 . 81 .. d = 9 : v ( P ) = 2 . 99 .. d ( x ): v ( P ) = 3 < -- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. View Source def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance ( dist ) and value clouds relative ## ids ( idsv ). the position of each cell in the arrays reflects the cells ## in the base cloud . k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]]. values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ). stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ). stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud ( base cloud index ) and his neighbous ( value cloud ids , ## distance and neighbour group progressive ). Then we clean the infinite ## distances ( points with no neighbours ) values = dist . to_frame (). join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv' , allows to join with the value cloud and add the 'v' # info values = values . reset_index (). set_index ( \"idsv\" ). sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance' , allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]). sort_index () ## Here we calculte the [ distance based , weighted ] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ). apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values","title":"Cloudpainter"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#module-hielen3extsource_tinsarcloudpainter","text":"View Source # coding: utf-8 import pandas as pd import numpy as np import laspy from pathlib import Path from scipy.spatial import KDTree from matplotlib.colors import Normalize , Colormap , LinearSegmentedColormap from matplotlib.cm import ScalarMappable import getopt import sys def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance (dist) and value clouds relative ## ids (idsv). the position of each cell in the arrays reflects the cells ## in the base cloud. k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]] . values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ) . stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ) . stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud (base cloud index) and his neighbous (value cloud ids, ## distance and neighbour group progressive). Then we clean the infinite ## distances (points with no neighbours) values = dist . to_frame () . join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv', allows to join with the value cloud and add the 'v' # info values = values . reset_index () . set_index ( \"idsv\" ) . sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance', allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]) . sort_index () ## Here we calculte the [distance based, weighted] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ) . apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) if norm is None : norm = Normalize ( vmin = vals . min (), vmax = vals . max (), clip = True ) if not isinstance ( cmap , ( Colormap , str )): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) # mapper = ScalarMappable(cmap=cmap) cols = mapper . to_rgba ( vals ) return cols def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , norm = norm ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ 'r' , 'g' , 'b' ]] * 255 #65536 if basecld is not None : result = basecld . join ( colors , how = \"left\" ) . replace ( np . nan , 0.9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) \"\"\" result[\"r\"]=result[\"r\"]*65536 result[\"g\"]=result[\"g\"]*65536 result[\"b\"]=result[\"b\"]*65536 \"\"\" return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] #65536 def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0.01 , 0.01 , 0.01 ]): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] y = frame [ 'y' ] z = frame [ 'z' ] r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () def makemultilaz ( csvfile , targetpath = None , sep = \" \" , basemanage = 'i' , scale = [ 0.000001 , 0.000001 , 0.000001 ], columns = None , cmap = 'jet' , norm = None ): \"\"\" o : only i : ignore a : also \"\"\" try : targetpath = Path ( targetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower , cloud . columns )) fields = [ c for c in cloud . columns if c not in [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] ] if basemanage == 'o' and 'r' in cloud . columns : fields = [ 'base' ] if basemanage == 'a' : fields . append ( 'base' ) lazdone = {} for c in fields : if c == 'base' : theframe = cloud [[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] else : theframe = paint ( cloud [[ 'x' , 'y' , 'z' , c ]], cmap = cmap , norm = norm )[[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] #colors='jet' lazpath = str ( targetpath / f ' { c } .laz' ) makelaz ( theframe , lazpath , scale = scale ) lazdone [ c ] = lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \"#ee55ee\"], [ -66.6 ,\"#0000ff\"] , [-33.3, \"#00ffff\" ],[0,\"#00FF00\"] ,[ 33.3, \"#ffff00\"], [ 66.6,\"#ffa500\" ], [ 100, \"#FF0000\" ]])) r={ 'cmap':ListedColormap([\"#ee55ee\", \"#0000ff\",\"#00ffff\",\"#00FF00\",\"#ffff00\",\"#ffa500\",\"#FF0000\"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\" \"\"\" import open3d as o3d def openpcl(res): #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d.geometry.PointCloud() pcl.points = o3d.utility.Vector3dVector(res[[\"x\", \"y\", \"z\"]].values) pcl.colors = o3d.utility.Vector3dVector(res[[\"r\", \"g\", \"b\"]].values) o3d.visualization.draw_geometries([pcl]) \"\"\" def usage (): helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) if __name__ == \"__main__\" : #DEFAULTS datacloud = None basecloud = None group = 1 distance = 5 degree = 0 colors = [ 'violet' , 'blue' , 'cyan' , 'green' , 'yellow' , 'orange' , 'red' ] outfile = None output = 'las' vmin =- 500 vmax = 500 try : opts , args = getopt . getopt ( sys . argv [ 1 :], \"b:g:d:D:c:o:O:v:V:\" , [ \"basecloud=\" , \"group=\" , \"distance=\" , \"degree=\" , \"colors=\" , \"outfile=\" , \"output=\" , \"vmin=\" , \"vmax=\" ]) for o , a in opts : if o in ( \"-b\" , \"--basecloud\" ): basecloud = a elif o in ( \"-g\" , \"--group\" ): group = a elif o in ( \"-d\" , \"--distance\" ): distance = a elif o in ( \"-D\" , \"--degree\" ): degree = a elif o in ( \"-c\" , \"--colors\" ): colors = a . split ( \",\" ) elif o in ( \"-o\" , \"--outfile\" ): outfile = a elif o in ( \"-O\" , \"--output\" ): output = a elif o in ( \"-v\" , \"--vmin\" ): vmin = a elif o in ( \"-V\" , \"--vmax\" ): vmax = a else : assert False , \"unhandled option\" try : infile = args [ 0 ] except Exception : raise Exception ( f \"No file\" ) try : norm = norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) except Exception as e : norm = None datacloud = pd . read_csv ( infile ) datacloud = datacloud [ datacloud . columns [ 0 : 4 ]] datacloud . columns = [ \"X\" , \"Y\" , \"Z\" , \"V\" ] if basecloud is not None : basecloud = pd . read_csv ( basecloud ) basecloud = basecloud [ basecloud . columns [ 0 : 3 ]] basecloud . columns = [ \"X\" , \"Y\" , \"Z\" ] result = paint ( valcld = datacloud , basecld = basecloud , distance = distance , degree = degree , group = group , cmap = colors , norm = norm ) if outfile is None : outfile = '.' . join ([ infile , output ]) if output == 'las' : makelaz ( result [[ \"x\" , \"y\" , \"z\" , \"r\" , \"g\" , \"b\" ]], outfile ) elif output == 'csv' : result . to_csv ( outfile , index = False ) # elif output == 'view': # openpcl(result) else : raise Exception ( f 'unkwnown output type: { output } ' ) except Exception as err : # print help information and exit: print ( err ) usage () sys . exit ( 2 )","title":"Module hielen3.ext.source_tinsar.cloudpainter"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#colorize","text":"def colorize ( vals , cmap = [ 'red' , 'green' , 'blue' ], norm = None ) Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) if norm is None : norm = Normalize ( vmin = vals . min (), vmax = vals . max (), clip = True ) if not isinstance ( cmap , ( Colormap , str )): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) # mapper = ScalarMappable ( cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols","title":"colorize"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#makelaz","text":"def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0.01 , 0.01 , 0.01 ] ) View Source def makelaz ( frame , filetowrite , colormult = 1 , scale = [ 0 . 01 , 0 . 01 , 0 . 01 ]): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] y = frame [ 'y' ] z = frame [ 'z' ] r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close ()","title":"makelaz"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#makemultilaz","text":"def makemultilaz ( csvfile , targetpath = None , sep = ' ' , basemanage = 'i' , scale = [ 1e-06 , 1e-06 , 1e-06 ], columns = None , cmap = 'jet' , norm = None ) o : only i : ignore a : also View Source def makemultilaz ( csvfile , targetpath = None , sep = \" \" , basemanage = 'i' , scale =[ 0.000001,0.000001,0.000001 ] , columns = None , cmap = 'jet' , norm = None ) : \"\"\" o : only i : ignore a : also \"\"\" try : targetpath = Path ( targetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower , cloud . columns )) fields =[ c for c in cloud.columns if c not in ['x','y','z','r','g','b' ] ] if basemanage == 'o' and 'r' in cloud . columns : fields =[ 'base' ] if basemanage == 'a' : fields . append ( 'base' ) lazdone = {} for c in fields : if c == 'base' : theframe = cloud [ ['x','y','z','r','g','b' ] ] else : theframe = paint ( cloud [ ['x','y','z',c ] ] , cmap = cmap , norm = norm ) [ ['x','y','z','r','g','b' ] ] #colors = 'jet' lazpath = str ( targetpath / f '{c}.laz' ) makelaz ( theframe , lazpath , scale = scale ) lazdone [ c ]= lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \" #ee55ee \"], [ -66.6 ,\" #0000ff \"] , [-33.3, \" #00ffff \" ],[0,\" #00FF00 \"] ,[ 33.3, \" #ffff00 \"], [ 66.6,\" #ffa500 \" ], [ 100, \" #FF0000 \" ]])) r={ 'cmap':ListedColormap([\" #ee55ee \", \" #0000ff \",\" #00ffff \",\" #00FF00 \",\" #ffff00 \",\" #ffa500 \",\" #FF0000 \"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\"","title":"makemultilaz"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#paint","text":"def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ 'red' , 'green' , 'blue' ], norm = None ) Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], norm = None ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , norm = norm ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ 'r' , 'g' , 'b' ]] * 255 # 65536 if basecld is not None : result = basecld . join ( colors , how = \"left\" ). replace ( np . nan , 0 . 9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) \"\"\" result[\" r \"]=result[\" r \"]*65536 result[\" g \"]=result[\" g \"]*65536 result[\" b \"]=result[\" b \"]*65536 \"\"\" return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]]","title":"paint"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#usage","text":"def usage ( ) View Source def usage () : helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext )","title":"usage"},{"location":"reference/hielen3/ext/source_tinsar/cloudpainter/#valorize","text":"def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ) Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . i . e : N1 ----------P----N2 Given two neighbours , N1 and N2 , for a fixed point P where : d ( N1 ) = 10 ; v ( N1 ) =- 15 d ( N2 ) = 4 ; v ( N2 ) = 3 v ( P ) = ( - 15 / 10 ** d + 3 / 4 ** d ) / ( 1 / 10 ** d + 1 / 4 ** d ) being d the degree , we have : d = 0 : v ( P ) = - 6 < -- arimetic mean d = 1 : v ( P ) = - 2 . 14 d = 2 : v ( P ) = 0 . 51 d = 3 : v ( P ) = 1 . 91 d = 4 : v ( P ) = 2 . 55 d = 5 : v ( P ) = 2 . 81 .. d = 9 : v ( P ) = 2 . 99 .. d ( x ): v ( P ) = 3 < -- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. View Source def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance ( dist ) and value clouds relative ## ids ( idsv ). the position of each cell in the arrays reflects the cells ## in the base cloud . k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]]. values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ). stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ). stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud ( base cloud index ) and his neighbous ( value cloud ids , ## distance and neighbour group progressive ). Then we clean the infinite ## distances ( points with no neighbours ) values = dist . to_frame (). join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv' , allows to join with the value cloud and add the 'v' # info values = values . reset_index (). set_index ( \"idsv\" ). sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance' , allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]). sort_index () ## Here we calculte the [ distance based , weighted ] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ). apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values","title":"valorize"},{"location":"reference/hielen3/ext/source_tinsar/struct/","text":"Module hielen3.ext.source_tinsar.struct View Source # coding: utf-8 import pandas as pd import hielen3.ext.source_tinsar.cloudpainter as cloudpainter from pathlib import Path def make_laz_clouds ( csvfile , targetpath = None , sep = \" \" , fields = None , scale = [ 0.000001 , 0.000001 , 0.000001 ], field_cmaps = None ): if fileds is None : fields = [ 'base' ] if not isinstance ( fields , str ): fields = [ fields ] fields = list ( map ( str . lower ), fields ) try : targetpath = Path ( tergetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower ), cloud . columns ) lazdone = {} for c in fields : try : cmap = field_cmaps [ c ] except KeyError as e : cmap = {} if c == 'base' : theframe = cloud [[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] else : theframe = cloudpainter . paint ( cloud [[ 'x' , 'y' , 'z' , c ]], ** cmap )[[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] colormult = 65536 colormult = 255 colormult = 1 #colors='jet' lazpath = str ( targetpath / f '{c}.laz' ) cloudpainter . makelaz ( theframe , lazpath , scale = scale , colormult = 1 ) lazdone [ c ] = lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \"#ee55ee\"], [ -66.6 ,\"#0000ff\"] , [-33.3, \"#00ffff\" ],[0,\"#00FF00\"] ,[ 33.3, \"#ffff00\"], [ 66.6,\"#ffa500\" ], [ 100, \"#FF0000\" ]])) r={ 'cmap':ListedColormap([\"#ee55ee\", \"#0000ff\",\"#00ffff\",\"#00FF00\",\"#ffff00\",\"#ffa500\",\"#FF0000\"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\" Functions make_laz_clouds def make_laz_clouds ( csvfile , targetpath = None , sep = ' ' , fields = None , scale = [ 1e-06 , 1e-06 , 1e-06 ], field_cmaps = None ) View Source def make_laz_clouds ( csvfile , targetpath = None , sep = \" \" , fields = None , scale =[ 0.000001,0.000001,0.000001 ] , field_cmaps = None ) : if fileds is None : fields = [ 'base' ] if not isinstance ( fields , str ) : fields = [ fields ] fields = list ( map ( str . lower ), fields ) try : targetpath = Path ( tergetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower ), cloud . columns ) lazdone = {} for c in fields : try : cmap = field_cmaps [ c ] except KeyError as e : cmap = {} if c == 'base' : theframe = cloud [ ['x','y','z','r','g','b' ] ] else : theframe = cloudpainter . paint ( cloud [ ['x','y','z',c ] ] , ** cmap ) [ ['x','y','z','r','g','b' ] ] colormult = 65536 colormult = 255 colormult = 1 #colors = 'jet' lazpath = str ( targetpath / f '{c}.laz' ) cloudpainter . makelaz ( theframe , lazpath , scale = scale , colormult = 1 ) lazdone [ c ]= lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \" #ee55ee \"], [ -66.6 ,\" #0000ff \"] , [-33.3, \" #00ffff \" ],[0,\" #00FF00 \"] ,[ 33.3, \" #ffff00 \"], [ 66.6,\" #ffa500 \" ], [ 100, \" #FF0000 \" ]])) r={ 'cmap':ListedColormap([\" #ee55ee \", \" #0000ff \",\" #00ffff \",\" #00FF00 \",\" #ffff00 \",\" #ffa500 \",\" #FF0000 \"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\"","title":"Struct"},{"location":"reference/hielen3/ext/source_tinsar/struct/#module-hielen3extsource_tinsarstruct","text":"View Source # coding: utf-8 import pandas as pd import hielen3.ext.source_tinsar.cloudpainter as cloudpainter from pathlib import Path def make_laz_clouds ( csvfile , targetpath = None , sep = \" \" , fields = None , scale = [ 0.000001 , 0.000001 , 0.000001 ], field_cmaps = None ): if fileds is None : fields = [ 'base' ] if not isinstance ( fields , str ): fields = [ fields ] fields = list ( map ( str . lower ), fields ) try : targetpath = Path ( tergetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower ), cloud . columns ) lazdone = {} for c in fields : try : cmap = field_cmaps [ c ] except KeyError as e : cmap = {} if c == 'base' : theframe = cloud [[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] else : theframe = cloudpainter . paint ( cloud [[ 'x' , 'y' , 'z' , c ]], ** cmap )[[ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ]] colormult = 65536 colormult = 255 colormult = 1 #colors='jet' lazpath = str ( targetpath / f '{c}.laz' ) cloudpainter . makelaz ( theframe , lazpath , scale = scale , colormult = 1 ) lazdone [ c ] = lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \"#ee55ee\"], [ -66.6 ,\"#0000ff\"] , [-33.3, \"#00ffff\" ],[0,\"#00FF00\"] ,[ 33.3, \"#ffff00\"], [ 66.6,\"#ffa500\" ], [ 100, \"#FF0000\" ]])) r={ 'cmap':ListedColormap([\"#ee55ee\", \"#0000ff\",\"#00ffff\",\"#00FF00\",\"#ffff00\",\"#ffa500\",\"#FF0000\"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\"","title":"Module hielen3.ext.source_tinsar.struct"},{"location":"reference/hielen3/ext/source_tinsar/struct/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_tinsar/struct/#make_laz_clouds","text":"def make_laz_clouds ( csvfile , targetpath = None , sep = ' ' , fields = None , scale = [ 1e-06 , 1e-06 , 1e-06 ], field_cmaps = None ) View Source def make_laz_clouds ( csvfile , targetpath = None , sep = \" \" , fields = None , scale =[ 0.000001,0.000001,0.000001 ] , field_cmaps = None ) : if fileds is None : fields = [ 'base' ] if not isinstance ( fields , str ) : fields = [ fields ] fields = list ( map ( str . lower ), fields ) try : targetpath = Path ( tergetpath ) except Exception as e : targetpath = Path ( \".\" ) #We expect header cloud = pd . read_csv ( csvfile , sep = sep ) cloud . columns = list ( map ( str . lower ), cloud . columns ) lazdone = {} for c in fields : try : cmap = field_cmaps [ c ] except KeyError as e : cmap = {} if c == 'base' : theframe = cloud [ ['x','y','z','r','g','b' ] ] else : theframe = cloudpainter . paint ( cloud [ ['x','y','z',c ] ] , ** cmap ) [ ['x','y','z','r','g','b' ] ] colormult = 65536 colormult = 255 colormult = 1 #colors = 'jet' lazpath = str ( targetpath / f '{c}.laz' ) cloudpainter . makelaz ( theframe , lazpath , scale = scale , colormult = 1 ) lazdone [ c ]= lazpath return lazdone \"\"\" r=parse_colormap(make_colormap([[-100, \" #ee55ee \"], [ -66.6 ,\" #0000ff \"] , [-33.3, \" #00ffff \" ],[0,\" #00FF00 \"] ,[ 33.3, \" #ffff00 \"], [ 66.6,\" #ffa500 \" ], [ 100, \" #FF0000 \" ]])) r={ 'cmap':ListedColormap([\" #ee55ee \", \" #0000ff \",\" #00ffff \",\" #00FF00 \",\" #ffff00 \",\" #ffa500 \",\" #FF0000 \"],'Custom_map'), 'norm':Normalize(vmin=-50,vmax=50) } result=cloudpainter_new.paint(spostamento,**r) cloudpainter_new.makelaz(result[['x','y','z','r','g','b']],'spostamento.laz',colormult=255, scale=[0.000001,0.000001,0.000001]) \"\"\"","title":"make_laz_clouds"},{"location":"reference/hielen3/ext/source_tinsar/tin/","text":"Module hielen3.ext.source_tinsar.tin View Source # coding=utf-8 from hielen3.source import CloudSource , ActionSchema , GeoInfoSchema from hielen3.utils import LocalFile , ColorMap , Style , FTPPath from hielen3.ext.source_rawsource import Source as RawSource import hielen3.api.features as featman from hielen3.mapmanager import Multiraster from hielen3.cloudmanager import PotreeCM from .cloudpainter import makemultilaz import json from pathlib import Path from marshmallow import fields from numpy import full from pandas import read_csv , DataFrame , Series , DatetimeIndex from matplotlib.cm import jet from matplotlib.colors import rgb2hex from xarray import open_rasterio from shutil import copy import geojson from datetime import datetime import traceback series_file_date_parser = lambda x : datetime . strptime ( x , \" %d /%m/%Y %H.%M\" ) #mapbasename=\"basemap.tif\" class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True ) class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True ) def get_imgname ( mapname , timestamp , param ): return f \" { mapname } _ { timestamp [: 14 ] } _ { param } .tif\" class Source ( CloudSource ): ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ): if brandnewconf : kwargs [ 'opacity' ] = 50 out = super () . config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {}, \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {}, \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ] = kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI: displ_cmap, ampli_cmap def_cmap = [ [ a / 100 , rgb2hex ( jet ( a / 100 )[ 0 : 3 ]) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ] = kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ] = kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ]) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ]) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ], str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items (): cloudman . makePotree ( w , k ) #print(json.dumps(out,indent=4)) out [ 'point_style' ] = kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ]) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ]) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None ))[ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ) . cloudcache . rmdir () Multiraster ( self . uid , timestamp ) . mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ): try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ([]) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates = [ 0 ], date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ) . head ( 4 ) . T points . columns = list ( map ( str . lower , points . columns )) labels = points [[ x for x in points . columns if x not in [ 'x' , 'y' , 'z' ]]] points = points [[ 'x' , 'y' , 'z' ]] points [ 'label' ] = labels points . columns = [ 'x' , 'y' , 'z' , 'label' ] points [ 'puid' ] = points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples (): prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" :[ x , y , z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ) . status resp = int ( resp . split ( \" \" )[ 0 ]) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list = [[ \"Displacement\" , 0 , \"mm\" ]]) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ) . status resp = int ( resp . split ( \" \" )[ 0 ]) subitems . add ( subuid ) if resp not in ( 200 , 201 ): print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing { label } , ' { resp } ' occurs\" ) rs . feed ( input_file = series [ label ]) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ) . cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' )[ - 1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ]) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe.rio.clip(geometries) #print (geometry) coords = list ( geojson . utils . coords ( geometry [ 0 ])) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ]) #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ - 1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ - 1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int ( selection . sel ( band = 1 ) . mean () . round ( 0 )), int ( selection . sel ( band = 2 ) . mean () . round ( 0 )), int ( selection . sel ( band = 3 ) . mean () . round ( 0 )) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ([ result ], index = DatetimeIndex ([ timestamp ])) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ]) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' )[ - 1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ) . geturl ( results , output ) + f \"&feature= { self . uid } \" ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) except Exception as e : return None return ser Functions get_imgname def get_imgname ( mapname , timestamp , param ) View Source def get_imgname ( mapname , timestamp , param ): return f \"{mapname}_{timestamp[:14]}_{param}.tif\" series_file_date_parser def series_file_date_parser ( x ) View Source series_file_date_parser = lambda x: datetime.strptime(x, \"%d/%m/%Y %H.%M\") Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING ampli_cmap displ_cmap error_messages master_cloud opts point_style series_file Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True ) Ancestors (in MRO) hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING amplitude_cloud amplitude_geotiff displacement_cloud displacement_geotiff error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class hints set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( CloudSource ) : ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ) : if brandnewconf : kwargs [ 'opacity' ]= 50 out = super (). config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ]= kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI : displ_cmap , ampli_cmap def_cmap =[ [ a/100, rgb2hex(jet (a/100)[0:3 ] ) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ]= kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ]= kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ] ) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ] ) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ] , str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items () : cloudman . makePotree ( w , k ) #print ( json . dumps ( out , indent = 4 )) out [ 'point_style' ]= kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ] ) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ] ) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None )) [ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ) : return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ) : return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ) : \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ) : try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ( [] ) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates =[ 0 ] , date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ). head ( 4 ). T points . columns = list ( map ( str . lower , points . columns )) labels = points [ [ x for x in points.columns if x not in ['x','y','z' ] ]] points = points [ ['x','y','z' ] ] points [ 'label' ]= labels points . columns =[ 'x','y','z','label' ] points [ 'puid' ]= points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples () : prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" : [ x,y,z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list =[ [\"Displacement\",0,\"mm\" ] ] ) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) subitems . add ( subuid ) if resp not in ( 200 , 201 ) : print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing {label}, '{resp}' occurs\" ) rs . feed ( input_file = series [ label ] ) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ] ) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ] ) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ] ) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ] ) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ] ) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ] ) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ] ) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser Ancestors (in MRO) hielen3.source.CloudSource hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC Class variables mapbasename Methods addParamSeries def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params ) cleanConfig def cleanConfig ( self , timestamp ) da analizzare View Source def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () cleanFeatureCache def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) cloud def cloud ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs ) data def data ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out getFeatureInfo def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ] hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) lastActionBefore def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None map def map ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser retriveSeries def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series setFeatureInfo def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info setParamOperand def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () setParamOperands def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save () updateAction def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e ) updateConfig def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs ) updateFeed def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"Tin"},{"location":"reference/hielen3/ext/source_tinsar/tin/#module-hielen3extsource_tinsartin","text":"View Source # coding=utf-8 from hielen3.source import CloudSource , ActionSchema , GeoInfoSchema from hielen3.utils import LocalFile , ColorMap , Style , FTPPath from hielen3.ext.source_rawsource import Source as RawSource import hielen3.api.features as featman from hielen3.mapmanager import Multiraster from hielen3.cloudmanager import PotreeCM from .cloudpainter import makemultilaz import json from pathlib import Path from marshmallow import fields from numpy import full from pandas import read_csv , DataFrame , Series , DatetimeIndex from matplotlib.cm import jet from matplotlib.colors import rgb2hex from xarray import open_rasterio from shutil import copy import geojson from datetime import datetime import traceback series_file_date_parser = lambda x : datetime . strptime ( x , \" %d /%m/%Y %H.%M\" ) #mapbasename=\"basemap.tif\" class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True ) class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True ) def get_imgname ( mapname , timestamp , param ): return f \" { mapname } _ { timestamp [: 14 ] } _ { param } .tif\" class Source ( CloudSource ): ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ): if brandnewconf : kwargs [ 'opacity' ] = 50 out = super () . config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {}, \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {}, \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" }, \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ] = kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI: displ_cmap, ampli_cmap def_cmap = [ [ a / 100 , rgb2hex ( jet ( a / 100 )[ 0 : 3 ]) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ] = kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ] = kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ]) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ]) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ], str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items (): cloudman . makePotree ( w , k ) #print(json.dumps(out,indent=4)) out [ 'point_style' ] = kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ]) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ]) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None ))[ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ) . cloudcache . rmdir () Multiraster ( self . uid , timestamp ) . mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ): try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ([]) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates = [ 0 ], date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ) . head ( 4 ) . T points . columns = list ( map ( str . lower , points . columns )) labels = points [[ x for x in points . columns if x not in [ 'x' , 'y' , 'z' ]]] points = points [[ 'x' , 'y' , 'z' ]] points [ 'label' ] = labels points . columns = [ 'x' , 'y' , 'z' , 'label' ] points [ 'puid' ] = points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples (): prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" :[ x , y , z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ) . status resp = int ( resp . split ( \" \" )[ 0 ]) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list = [[ \"Displacement\" , 0 , \"mm\" ]]) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ) . status resp = int ( resp . split ( \" \" )[ 0 ]) subitems . add ( subuid ) if resp not in ( 200 , 201 ): print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing { label } , ' { resp } ' occurs\" ) rs . feed ( input_file = series [ label ]) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ) . cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' )[ - 1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ]) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe.rio.clip(geometries) #print (geometry) coords = list ( geojson . utils . coords ( geometry [ 0 ])) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ]) #if isinstance(geometry[0],geojson.Point) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ([ 'x' , 'y' ], coords [ 0 ])) } #name=\"_\".join(map(str,coords[0])) name = 'nearest' #elif isinstance(geometry[0],geojson.Polygon): elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ - 1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ - 1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int ( selection . sel ( band = 1 ) . mean () . round ( 0 )), int ( selection . sel ( band = 2 ) . mean () . round ( 0 )), int ( selection . sel ( band = 3 ) . mean () . round ( 0 )) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ([ result ], index = DatetimeIndex ([ timestamp ])) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ]) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' )[ - 1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ) . geturl ( results , output ) + f \"&feature= { self . uid } \" ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) except Exception as e : return None return ser","title":"Module hielen3.ext.source_tinsar.tin"},{"location":"reference/hielen3/ext/source_tinsar/tin/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/ext/source_tinsar/tin/#get_imgname","text":"def get_imgname ( mapname , timestamp , param ) View Source def get_imgname ( mapname , timestamp , param ): return f \"{mapname}_{timestamp[:14]}_{param}.tif\"","title":"get_imgname"},{"location":"reference/hielen3/ext/source_tinsar/tin/#series_file_date_parser","text":"def series_file_date_parser ( x ) View Source series_file_date_parser = lambda x: datetime.strptime(x, \"%d/%m/%Y %H.%M\")","title":"series_file_date_parser"},{"location":"reference/hielen3/ext/source_tinsar/tin/#classes","text":"","title":"Classes"},{"location":"reference/hielen3/ext/source_tinsar/tin/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal map based ActionSchema object. Used to define geo-info View Source class ConfigSchema ( GeoInfoSchema ): #class ConfigSchema(ActionSchema): _self_hints = { \"TinSAR Base\" : { 0 : [ \"master_cloud\" , \"references to master cloud csv in FTP\" , True ], }, \"TinSAR Color Maps\" : { 0 : [ \"displ_cmap\" , \"Displacement colormap range\" , True ], 1 : [ \"ampli_cmap\" , \"Amplitude colormap range\" , True ], }, \"TinSAR Selected Points\" :{ 0 : [ \"point_style\" , \"style code for the selected points\" , True ], 1 : [ \"series_file\" , \"textfile containing selected points and dataseries of theirs\" , True ] } } master_cloud = FTPPath ( required = True , allow_none = False ) displ_cmap = ColorMap ( required = False , allow_none = True , default = None ) ampli_cmap = ColorMap ( required = False , allow_none = True , default = None ) point_style = Style ( required = False , allow_none = True , default = None ) series_file = FTPPath ( required = False , allow_none = True )","title":"ConfigSchema"},{"location":"reference/hielen3/ext/source_tinsar/tin/#ancestors-in-mro","text":"hielen3.source.GeoInfoSchema hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/tin/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING ampli_cmap displ_cmap error_messages master_cloud opts point_style series_file","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/tin/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_tinsar/tin/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_tinsar/tin/#instance-variables","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_tinsar/tin/#methods","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/tin/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_tinsar/tin/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_tinsar/tin/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_tinsar/tin/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_tinsar/tin/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_tinsar/tin/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_tinsar/tin/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_tinsar/tin/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_tinsar/tin/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): _self_hints = { \"TinSAR Feed\" : { 0 : [ \"displacement_cloud\" , \"reference to result cloud in FTP\" , True ], 1 : [ \"amplitude_cloud\" , \"refernce to radar amplitutde cloud in FTP\" , True ], 2 : [ \"displacement_geotiff\" , \"reference to result geotiff in FTP\" , True ], 3 : [ \"amplitude_geotiff\" , \"refernce to radar amplitude geotiff in FTP\" , True ] } } displacement_cloud = FTPPath ( required = False , allow_none = True ) amplitude_cloud = FTPPath ( required = False , allow_none = True ) displacement_geotiff = FTPPath ( required = False , allow_none = True ) amplitude_geotiff = FTPPath ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen3/ext/source_tinsar/tin/#ancestors-in-mro_1","text":"hielen3.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/tin/#class-variables_1","text":"Meta OPTIONS_CLASS TYPE_MAPPING amplitude_cloud amplitude_geotiff displacement_cloud displacement_geotiff error_messages opts","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/tin/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen3/ext/source_tinsar/tin/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen3/ext/source_tinsar/tin/#instance-variables_1","text":"dict_class hints set_class","title":"Instance variables"},{"location":"reference/hielen3/ext/source_tinsar/tin/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/tin/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen3/ext/source_tinsar/tin/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen3/ext/source_tinsar/tin/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen3/ext/source_tinsar/tin/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen3/ext/source_tinsar/tin/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen3/ext/source_tinsar/tin/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen3/ext/source_tinsar/tin/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen3/ext/source_tinsar/tin/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen3/ext/source_tinsar/tin/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( CloudSource ) : ''' PhotoMonitoring source manager ''' def _config ( self , brandnewconf = True , ** kwargs ) : if brandnewconf : kwargs [ 'opacity' ]= 50 out = super (). config ( ** kwargs ) chstruct = { \"param\" : 'Displacement' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"displacement\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) chstruct = { \"param\" : 'Radar_Amplitude' , \"struct\" : { \"cache\" : None , \"modules\" : {} , \"mu\" : \"mm\" , \"operands\" : { \"output\" : \"amplitude\" } , \"operator\" : None } } self . addParamSeries ( ** chstruct ) else : out = kwargs timestamp = out [ 'timestamp' ] out [ 'master_cloud' ]= kwargs [ 'master_cloud' ] confpath = self . hasher ( timestamp ) mapmanager = Multiraster ( self . uid , confpath ) mapmanager . mapcache . mkdir () mapmanager . setMFparams ( bands = 3 , crs = 'EPSG:4326' ) self . filecache . mkdir ( confpath ) #CONFIGURABILI : displ_cmap , ampli_cmap def_cmap =[ [ a/100, rgb2hex(jet (a/100)[0:3 ] ) ] for a in range ( 0 , 101 , 10 ) ] if kwargs [ 'displ_cmap' ] is None : kwargs [ 'displ_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'displ_cmap' ][ \"norm\" ] = None out [ 'displ_cmap' ]= kwargs [ 'displ_cmap' ] if kwargs [ 'ampli_cmap' ] is None : kwargs [ 'ampli_cmap' ] = ColorMap . make_colormap ( def_cmap ) kwargs [ 'ampli_cmap' ][ \"norm\" ] = None out [ 'ampli_cmap' ]= kwargs [ 'ampli_cmap' ] self . setParamOperands ( 'Displacement' , cmap = out [ \"displ_cmap\" ] ) self . setParamOperands ( 'Radar_Amplitude' , cmap = out [ \"ampli_cmap\" ] ) cloudman = PotreeCM ( self . uid , confpath ) cloudman . cloudcache . mkdir () clds = makemultilaz ( out [ 'master_cloud' ] , str ( self . filecache / confpath ), basemanage = 'a' ) for k , w in clds . items () : cloudman . makePotree ( w , k ) #print ( json . dumps ( out , indent = 4 )) out [ 'point_style' ]= kwargs [ 'point_style' ] try : points_file = Path ( kwargs [ \"series_file\" ] ) except Exception as e : points_file = None self . _feed_subitems ( points_file , out [ 'point_style' ] ) if not brandnewconf : ##Ricreare le cloud associate alla config try : nextconf = self . getActionValues ( 'config' , slice ( timestamp , None )) [ 1 ][ 'timestamp' ] except Exception as e : nextconf = None feeds = self . getActionValues ( 'feed' , slice ( timestamp , nextconf )) for f in feeds : feedkwargs = f [ 'value' ] self . feed ( ** feedkwargs ) return out def config ( self , ** kwargs ) : return self . _config ( brandnewconf = True , ** kwargs ) def updateConfig ( self , ** kwargs ) : return self . _config ( brandnewconf = False , ** kwargs ) def cleanConfig ( self , timestamp ) : \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir () def _feed_subitems ( self , points_file = None , point_style = None ) : try : subitems = set ( self . getFeatureInfo ( 'subitems' )) except Exception as e : subitems = set ( [] ) \"\"\" associa punti a feature principale e crea serie dati \"\"\" if points_file is not None : series = read_csv ( points_file , sep = \";\" , index_col = 0 , skiprows = 3 , parse_dates =[ 0 ] , date_parser = series_file_date_parser ) points = read_csv ( points_file , sep = \";\" , index_col = 0 , header = None ). head ( 4 ). T points . columns = list ( map ( str . lower , points . columns )) labels = points [ [ x for x in points.columns if x not in ['x','y','z' ] ]] points = points [ ['x','y','z' ] ] points [ 'label' ]= labels points . columns =[ 'x','y','z','label' ] points [ 'puid' ]= points [ 'label' ] . apply ( lambda x : self . uid + x ) points = points . set_index ( \"puid\" ) for subuid , x , y , z , label in points . itertuples () : prototype = \"RawSource\" properties = { \"label\" : self . label + \"_\" + label , \"context\" : self . context , \"style\" : point_style } geometry = { \"type\" : \"Point\" , \"coordinates\" : [ x,y,z ] } resp = featman . create_feature ( uid = subuid , prototype = prototype , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) if resp == 201 : rs = RawSource ( subuid ) rs . config ( param_list =[ [\"Displacement\",0,\"mm\" ] ] ) subitems . add ( subuid ) elif resp == 409 : rs = RawSource ( subuid ) resp = featman . update_feature ( uid = subuid , properties = properties , geometry = geometry ). status resp = int ( resp . split ( \" \" ) [ 0 ] ) subitems . add ( subuid ) if resp not in ( 200 , 201 ) : print ( resp ) self . setFeatureInfo ( 'subitems' , list ( subitems )) raise ValueError ( f \"While manageing {label}, '{resp}' occurs\" ) rs . feed ( input_file = series [ label ] ) self . setFeatureInfo ( 'subitems' , list ( subitems )) return def feed ( self , ** kwargs ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ] ) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ] ) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ] ) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ] ) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items () : result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ] ) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ] ) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ] ) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs def updateFeed ( self , ** kwargs ) : self . cleanFeatureCache () return self . feed ( ** kwargs ) def cleanFeed ( self , timestamp ) : timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ] ) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp ) def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"Source"},{"location":"reference/hielen3/ext/source_tinsar/tin/#ancestors-in-mro_2","text":"hielen3.source.CloudSource hielen3.source.MapSource hielen3.source.DataSource hielen3.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen3/ext/source_tinsar/tin/#class-variables_2","text":"mapbasename","title":"Class variables"},{"location":"reference/hielen3/ext/source_tinsar/tin/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen3/ext/source_tinsar/tin/#addparamseries","text":"def addParamSeries ( self , param , struct ) View Source def addParamSeries ( self , param , struct ) : suid = hasher ( self . uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass struct [ 'operands' ][ 'source' ]= self . uid db [ 'series' ][ suid ]= struct try : params = self . getFeatureInfo ( 'parameters' ) except KeyError as e : params = {} params . update ( { param : suid } ) self . setFeatureInfo ( 'parameters' , params )","title":"addParamSeries"},{"location":"reference/hielen3/ext/source_tinsar/tin/#cleanconfig","text":"def cleanConfig ( self , timestamp ) da analizzare View Source def cleanConfig ( self , timestamp ): \"\"\" da analizzare \"\"\" timestamp = self . hasher ( timestamp ) self . filecache . rmdir ( timestamp ) PotreeCM ( self . uid , timestamp ). cloudcache . rmdir () Multiraster ( self . uid , timestamp ). mapcache . rmdir ()","title":"cleanConfig"},{"location":"reference/hielen3/ext/source_tinsar/tin/#cleanfeaturecache","text":"def cleanFeatureCache ( self , params = None ) View Source def cleanFeatureCache ( self , params = None ) : fpars = list ( db [ \"features_info\" ][ self.uid ][ 'parameters' ] . values ()) if params is None : params = fpars if not isinstance ( params , list ) : params = [ params ] params =[ a for a in fpars if a in params ] for p in params : try : db [ \"datacache\" ][ p ]= None except KeyError as e : pass","title":"cleanFeatureCache"},{"location":"reference/hielen3/ext/source_tinsar/tin/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) subpath = Path ( reftimehash , timestahash ) PotreeCM ( self . uid , subpath ). cloudcache . rmdir () self . _timeline_remove ( timestamp )","title":"cleanFeed"},{"location":"reference/hielen3/ext/source_tinsar/tin/#cloud","text":"def cloud ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def cloud ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] conf = self . lastActionBefore ( 'config' , timestamp ) try : reftimestamp = timeref or conf [ 'timestamp' ] cloudref = self . hasher ( reftimestamp ) results = self . hasher ( timestamp ) url = PotreeCM ( self . uid , cloudref ). geturl ( results , output ) + f \"&feature={self.uid}\" ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"cloud"},{"location":"reference/hielen3/ext/source_tinsar/tin/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return self . _config ( brandnewconf = True , ** kwargs )","title":"config"},{"location":"reference/hielen3/ext/source_tinsar/tin/#data","text":"def data ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : cmappo = cmap [ 'f_cmap' ] if geometry is None : return None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times if timestamp is None : try : timestamp = self . getFeatureInfo ( 'timeline' ) [ -1 ] except Exception as e : timestamp = None if timestamp is None : return None conf = self . lastActionBefore ( 'config' , timestamp ) mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname name = \"\" try : with open_rasterio ( path_image ) as dataset : #TODO ricorda dataframe . rio . clip ( geometries ) #print ( geometry ) coords = list ( geojson . utils . coords ( geometry [ 0 ] )) ''' if not geographic: coords = list( map( lambda l: [l[0], dataset.y[-1]-l[1]], coords ) ) ''' geotype = str ( geometry [ 0 ][ 'type' ] ) #if isinstance ( geometry [ 0 ] , geojson . Point ) : if geotype == 'Point' : query = { 'method' : 'nearest' , ** dict ( zip ( [ 'x','y' ] , coords [ 0 ] )) } #name = \"_\" . join ( map ( str , coords [ 0 ] )) name = 'nearest' #elif isinstance ( geometry [ 0 ] , geojson . Polygon ) : elif geotype == 'Polygon' : coords = DataFrame ( coords ) dirx = dataset . x [ 0 ] < dataset . x [ -1 ] and 1 or - 1 diry = dataset . y [ 0 ] < dataset . y [ -1 ] and 1 or - 1 query = { 'method' : None , \"x\" : slice ( coords [ 0 ] . min (), coords [ 0 ] . max (), dirx ), \"y\" : slice ( coords [ 1 ] . min (), coords [ 1 ] . max (), diry ) } name = 'mean' else : raise ValueError ( \"Unmanaged geometry Type\" ) selection = dataset . sel ( ** query ) color = [ int(selection.sel(band=1).mean().round(0)), int(selection.sel(band=2).mean().round(0)), int(selection.sel(band=3).mean().round(0)) ] result = ColorMap . valorizeColor ( cmappo , color ) except Exception as e : return None ser = Series ( [ result ] , index = DatetimeIndex ( [ timestamp ] )) ser . name = name return ser","title":"data"},{"location":"reference/hielen3/ext/source_tinsar/tin/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : #traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen3/ext/source_tinsar/tin/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise e # raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen3/ext/source_tinsar/tin/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): timestamp = kwargs [ \"timestamp\" ] conf = self . lastActionBefore ( 'config' , timestamp ) timestahash = self . hasher ( timestamp ) reftimehash = self . hasher ( conf [ \"timestamp\" ]) point_style = conf [ 'point_style' ] subpath = Path ( reftimehash , timestahash ) cloudman = PotreeCM ( self . uid , subpath ) mapmanager = Multiraster ( self . uid , reftimehash ) self . filecache . mkdir ( subpath ) try : result_cloud = Path ( kwargs [ \"displacement_cloud\" ]) except Exception as e : result_cloud = None if result_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'displ_cmap' ]) clds = makemultilaz ( result_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) try : info_cloud = Path ( kwargs [ \"amplitude_cloud\" ]) except Exception as e : info_cloud = None if info_cloud is not None : r = ColorMap . parse_colormap ( conf [ 'ampli_cmap' ]) clds = makemultilaz ( info_cloud , str ( self . filecache / subpath ), basemanage = 'i' , ** r ) for k , w in clds . items (): result = cloudman . makePotree ( w , k ) # MAPS # mapname = self . hasher ( conf [ 'timestamp' ]) try : result_tiff = Path ( kwargs [ \"displacement_geotiff\" ]) except Exception as e : result_tiff = None if result_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'displacement' ) path_image = mapmanager . mapcache / imgname copy ( result_tiff , path_image ) try : info_tiff = Path ( kwargs [ \"amplitude_geotiff\" ]) except Exception as e : info_tiff = None if info_tiff is not None : imgname = get_imgname ( mapname , self . hasher ( timestamp ), 'amplitude' ) path_image = mapmanager . mapcache / imgname copy ( info_tiff , path_image ) self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen3/ext/source_tinsar/tin/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen3/ext/source_tinsar/tin/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen3/ext/source_tinsar/tin/#getfeatureinfo","text":"def getFeatureInfo ( self , info ) View Source def getFeatureInfo ( self , info ) : return db [ \"features_info\" ][ self.uid ][ info ]","title":"getFeatureInfo"},{"location":"reference/hielen3/ext/source_tinsar/tin/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen3/ext/source_tinsar/tin/#lastactionbefore","text":"def lastActionBefore ( self , action , timestamp = None ) View Source def lastActionBefore ( self , action , timestamp = None ): c = self . getActionValues ( action , slice ( None , timestamp , None )) try : c = c [ - 1 ] try : return c [ 'value' ] except KeyError : return c except Exception as e : return None","title":"lastActionBefore"},{"location":"reference/hielen3/ext/source_tinsar/tin/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'displacement' , cmap = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"displacement\" , cmap = None , ** kwargs ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . lastActionBefore ( 'config' , timestamp ) try : mapname = self . hasher ( conf [ 'timestamp' ] ) mapmanager = Multiraster ( self . uid , mapname ) mapfile = mapmanager . mapfile imgname = get_imgname ( mapname , self . hasher ( timestamp ), output ) path_image = mapmanager . mapcache / imgname url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) except Exception as e : return None return ser","title":"map"},{"location":"reference/hielen3/ext/source_tinsar/tin/#retriveseries","text":"def retriveSeries ( self , parameters ) View Source def retriveSeries ( self , parameters ) : ft = db [ \"features_info\" ][ self.uid ] try : if parameters is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ parameters ] ] except KeyError as e : raise KeyError ( str ( e ) + \" not found\" ) return series","title":"retriveSeries"},{"location":"reference/hielen3/ext/source_tinsar/tin/#setfeatureinfo","text":"def setFeatureInfo ( self , info , value ) View Source def setFeatureInfo ( self , info , value ) : feat_info = db [ \"features_info\" ][ self.uid ] feat_info [ info ]= value db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info","title":"setFeatureInfo"},{"location":"reference/hielen3/ext/source_tinsar/tin/#setparamoperand","text":"def setParamOperand ( self , param , operand , value ) View Source def setParamOperand ( self , param , operand , value ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] ser [ 'operands' ][ operand ]= value db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperand"},{"location":"reference/hielen3/ext/source_tinsar/tin/#setparamoperands","text":"def setParamOperands ( self , param , ** kwargs ) View Source def setParamOperands ( self , param , ** kwargs ) : serid = self . retriveSeries ( param ) ser = db [ 'series' ][ serid ] for k , w in kwargs . items () : ser [ 'operands' ][ k ]= w db [ 'series' ][ serid ]= None db [ 'series' ][ serid ]= ser db [ 'series' ] . save ()","title":"setParamOperands"},{"location":"reference/hielen3/ext/source_tinsar/tin/#updateaction","text":"def updateAction ( self , action , ** kwargs ) View Source def updateAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : out = self . getActionValues ( action , kwargs [ 'timestamp' ] ) [ 0 ][ 'value' ] for k , w in kwargs . items () : if w is not None : out [ k ]= w kwargs = aclass (). load ( out ) return self . __getattribute__ ( f \"update{action.capitalize()}\" )( ** kwargs ) except Exception as e : raise e #raise ValueError ( e )","title":"updateAction"},{"location":"reference/hielen3/ext/source_tinsar/tin/#updateconfig","text":"def updateConfig ( self , ** kwargs ) View Source def updateConfig ( self , ** kwargs ): return self . _config ( brandnewconf = False , ** kwargs )","title":"updateConfig"},{"location":"reference/hielen3/ext/source_tinsar/tin/#updatefeed","text":"def updateFeed ( self , ** kwargs ) View Source def updateFeed ( self , ** kwargs ): self . cleanFeatureCache () return self . feed ( ** kwargs )","title":"updateFeed"},{"location":"reference/hielen3/tools/","text":"Module hielen3.tools Sub-modules hielen3.tools.calc","title":"Index"},{"location":"reference/hielen3/tools/#module-hielen3tools","text":"","title":"Module hielen3.tools"},{"location":"reference/hielen3/tools/#sub-modules","text":"hielen3.tools.calc","title":"Sub-modules"},{"location":"reference/hielen3/tools/calc/","text":"Module hielen3.tools.calc View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 #!/usr/bin/env python # coding=utf-8 __name__ = \"hielen3.series.calc\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"hub for hielen calculations\" __license__ = \"MIT\" __uri__ = \"\" from pandas import DataFrame , Series from numpy import sin , radians , mean , std #### CUSTOM LIBRARY #### def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) . replace ( \"e\" , \"\" ) return f \" { w } *S0** { k } \" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = radians ( S0 ) unit = \"rad\" if unit == \"rad\" : S0 = sin ( S0 ) return S0 * radius def aligned ( func ): def wrap_align ( left , right ): left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna ()[ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ], right [ mask ]) return wrap_align @aligned def add ( left , right ): right = right . fillna ( 0 ) return left + right @aligned def sub ( left , right ): right = right . fillna ( 0 ) return left - right @aligned def mult ( left , right ): right = right . fillna ( 0 ) return left * right def filter ( b , window = 50 , center = True , min_periods = 1 ): d = abs ( b - b . rolling ( window = window , center = center , min_periods = min_periods ) . apply ( mean )) stdv = abs ( b . rolling ( window = window , center = center , min_periods = min_periods ) . apply ( std )) return b [ d < 3 * stdv ] def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"poly_trans\" , \"add\" , \"sub\" , \"slope\" , \"filter\" ] Functions add def add ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] ) filter def filter ( b , window = 50 , center = True , min_periods = 1 ) View Source def filter ( b , window = 50 , center = True , min_periods = 1 ): d = abs ( b - b . rolling ( window = window , center = center , min_periods = min_periods ). apply ( mean )) stdv = abs ( b . rolling ( window = window , center = center , min_periods = min_periods ). apply ( std )) return b [ d < 3 * stdv ] poly_trans def poly_trans ( S0 , ** kwargs ) View Source def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ). replace ( \"e\" , \"\" ) return f \"{w}*S0**{k}\" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) slope def slope ( S0 , unit , radius ) View Source def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = radians ( S0 ) unit = \"rad\" if unit == \"rad\" : S0 = sin ( S0 ) return S0 * radius sub def sub ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"Calc"},{"location":"reference/hielen3/tools/calc/#module-hielen3toolscalc","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 #!/usr/bin/env python # coding=utf-8 __name__ = \"hielen3.series.calc\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"hub for hielen calculations\" __license__ = \"MIT\" __uri__ = \"\" from pandas import DataFrame , Series from numpy import sin , radians , mean , std #### CUSTOM LIBRARY #### def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) . replace ( \"e\" , \"\" ) return f \" { w } *S0** { k } \" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = radians ( S0 ) unit = \"rad\" if unit == \"rad\" : S0 = sin ( S0 ) return S0 * radius def aligned ( func ): def wrap_align ( left , right ): left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna ()[ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ], right [ mask ]) return wrap_align @aligned def add ( left , right ): right = right . fillna ( 0 ) return left + right @aligned def sub ( left , right ): right = right . fillna ( 0 ) return left - right @aligned def mult ( left , right ): right = right . fillna ( 0 ) return left * right def filter ( b , window = 50 , center = True , min_periods = 1 ): d = abs ( b - b . rolling ( window = window , center = center , min_periods = min_periods ) . apply ( mean )) stdv = abs ( b . rolling ( window = window , center = center , min_periods = min_periods ) . apply ( std )) return b [ d < 3 * stdv ] def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"poly_trans\" , \"add\" , \"sub\" , \"slope\" , \"filter\" ]","title":"Module hielen3.tools.calc"},{"location":"reference/hielen3/tools/calc/#functions","text":"","title":"Functions"},{"location":"reference/hielen3/tools/calc/#add","text":"def add ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"add"},{"location":"reference/hielen3/tools/calc/#filter","text":"def filter ( b , window = 50 , center = True , min_periods = 1 ) View Source def filter ( b , window = 50 , center = True , min_periods = 1 ): d = abs ( b - b . rolling ( window = window , center = center , min_periods = min_periods ). apply ( mean )) stdv = abs ( b . rolling ( window = window , center = center , min_periods = min_periods ). apply ( std )) return b [ d < 3 * stdv ]","title":"filter"},{"location":"reference/hielen3/tools/calc/#poly_trans","text":"def poly_trans ( S0 , ** kwargs ) View Source def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ). replace ( \"e\" , \"\" ) return f \"{w}*S0**{k}\" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator )","title":"poly_trans"},{"location":"reference/hielen3/tools/calc/#slope","text":"def slope ( S0 , unit , radius ) View Source def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = radians ( S0 ) unit = \"rad\" if unit == \"rad\" : S0 = sin ( S0 ) return S0 * radius","title":"slope"},{"location":"reference/hielen3/tools/calc/#sub","text":"def sub ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"sub"}]}