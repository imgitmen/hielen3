{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CHANGELOG v2.0.8 23 Marzo 2021 unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per dtingure tra [\"data\",\"maps\",\"clouds\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/maps GET /query/clouds/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\" 19 Marzo 2021 Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard) v2.0.7 15 Marzo 2021 API: GET /maps/ per la generazione delle mappe. 11 Marzo 2011 Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache) 3 Marzo 2021 API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati 25 Febbraio 2021 Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis. 18 Febbraio 2021 Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe 12 Febbraio 2021 Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds v2.0.6 7 Febbraio 2021 Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter 27 Gennaio 2021 Inserita la validazione dei campi delle action 25 Gennaio 2021 Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati. 22 Gennaio 2021 Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0 20 Gennaio 2021 modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False ) 18 Gennaio 2021 Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] } 15 Gennaio 2021 modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False) 13 Gennaio 2021 rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla 10 Gennaio 2021 Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\" 30 Dicembre 2020 sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug) 22 Dicembre 20202 Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli. 20 Dicembre 2020 Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr . 15 Dicembre 2020 Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata. v2.0.5 9 Dicembre 2020 Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } } 7 Dicembre 2020 Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare. 2 Dicembre 2020 Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere) 24 Novembre 2020 Implementate dummy /actions/{feature}/ e /actions/{feature}/{form} 23 Novembre 2020 Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale 19 Novembre 2020 riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ . 17 Novembre 2020 Implementata dummy POST /actions/{feature}/{form} : v2.0.4 16 Novembre 2020 per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature 13 Novembre 2020 rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature. 12 Novembre 2020 ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] } v2.0.3 11 Novembre 2020 Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata. 9 Novembre 2020 Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink 6 Novembre 2020 L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db) v2.0.2 4 Novembre 2020 Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"Home"},{"location":"#changelog","text":"","title":"CHANGELOG"},{"location":"#v208","text":"","title":"v2.0.8"},{"location":"#23-marzo-2021","text":"unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per dtingure tra [\"data\",\"maps\",\"clouds\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/maps GET /query/clouds/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\"","title":"23 Marzo 2021"},{"location":"#19-marzo-2021","text":"Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard)","title":"19 Marzo 2021"},{"location":"#v207","text":"","title":"v2.0.7"},{"location":"#15-marzo-2021","text":"API: GET /maps/ per la generazione delle mappe.","title":"15 Marzo 2021"},{"location":"#11-marzo-2011","text":"Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache)","title":"11 Marzo 2011"},{"location":"#3-marzo-2021","text":"API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati","title":"3 Marzo 2021"},{"location":"#25-febbraio-2021","text":"Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis.","title":"25 Febbraio 2021"},{"location":"#18-febbraio-2021","text":"Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe","title":"18 Febbraio 2021"},{"location":"#12-febbraio-2021","text":"Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds","title":"12 Febbraio 2021"},{"location":"#v206","text":"","title":"v2.0.6"},{"location":"#7-febbraio-2021","text":"Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter","title":"7 Febbraio 2021"},{"location":"#27-gennaio-2021","text":"Inserita la validazione dei campi delle action","title":"27 Gennaio 2021"},{"location":"#25-gennaio-2021","text":"Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati.","title":"25 Gennaio 2021"},{"location":"#22-gennaio-2021","text":"Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0","title":"22 Gennaio 2021"},{"location":"#20-gennaio-2021","text":"modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False )","title":"20 Gennaio 2021"},{"location":"#18-gennaio-2021","text":"Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] }","title":"18 Gennaio 2021"},{"location":"#15-gennaio-2021","text":"modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False)","title":"15 Gennaio 2021"},{"location":"#13-gennaio-2021","text":"rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla","title":"13 Gennaio 2021"},{"location":"#10-gennaio-2021","text":"Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\"","title":"10 Gennaio 2021"},{"location":"#30-dicembre-2020","text":"sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug)","title":"30 Dicembre 2020"},{"location":"#22-dicembre-20202","text":"Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli.","title":"22 Dicembre 20202"},{"location":"#20-dicembre-2020","text":"Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr .","title":"20 Dicembre 2020"},{"location":"#15-dicembre-2020","text":"Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata.","title":"15 Dicembre 2020"},{"location":"#v205","text":"","title":"v2.0.5"},{"location":"#9-dicembre-2020","text":"Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } }","title":"9 Dicembre 2020"},{"location":"#7-dicembre-2020","text":"Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare.","title":"7 Dicembre 2020"},{"location":"#2-dicembre-2020","text":"Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere)","title":"2 Dicembre 2020"},{"location":"#24-novembre-2020","text":"Implementate dummy /actions/{feature}/ e /actions/{feature}/{form}","title":"24 Novembre 2020"},{"location":"#23-novembre-2020","text":"Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale","title":"23 Novembre 2020"},{"location":"#19-novembre-2020","text":"riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ .","title":"19 Novembre 2020"},{"location":"#17-novembre-2020","text":"Implementata dummy POST /actions/{feature}/{form} :","title":"17 Novembre 2020"},{"location":"#v204","text":"","title":"v2.0.4"},{"location":"#16-novembre-2020","text":"per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature","title":"16 Novembre 2020"},{"location":"#13-novembre-2020","text":"rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature.","title":"13 Novembre 2020"},{"location":"#12-novembre-2020","text":"ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] }","title":"12 Novembre 2020"},{"location":"#v203","text":"","title":"v2.0.3"},{"location":"#11-novembre-2020","text":"Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata.","title":"11 Novembre 2020"},{"location":"#9-novembre-2020","text":"Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink","title":"9 Novembre 2020"},{"location":"#6-novembre-2020","text":"L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db)","title":"6 Novembre 2020"},{"location":"#v202","text":"","title":"v2.0.2"},{"location":"#4-novembre-2020","text":"Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"4 Novembre 2020"},{"location":"CHANGELOG/","text":"CHANGELOG v2.0.8 23 Marzo 2021 unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per dtingure tra [\"data\",\"maps\",\"clouds\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/maps GET /query/clouds/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\" 19 Marzo 2021 Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard) v2.0.7 15 Marzo 2021 API: GET /maps/ per la generazione delle mappe. 11 Marzo 2011 Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache) 3 Marzo 2021 API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati 25 Febbraio 2021 Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis. 18 Febbraio 2021 Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe 12 Febbraio 2021 Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds v2.0.6 7 Febbraio 2021 Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter 27 Gennaio 2021 Inserita la validazione dei campi delle action 25 Gennaio 2021 Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati. 22 Gennaio 2021 Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0 20 Gennaio 2021 modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False ) 18 Gennaio 2021 Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] } 15 Gennaio 2021 modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False) 13 Gennaio 2021 rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla 10 Gennaio 2021 Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\" 30 Dicembre 2020 sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug) 22 Dicembre 20202 Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli. 20 Dicembre 2020 Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr . 15 Dicembre 2020 Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata. v2.0.5 9 Dicembre 2020 Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } } 7 Dicembre 2020 Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare. 2 Dicembre 2020 Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere) 24 Novembre 2020 Implementate dummy /actions/{feature}/ e /actions/{feature}/{form} 23 Novembre 2020 Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale 19 Novembre 2020 riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ . 17 Novembre 2020 Implementata dummy POST /actions/{feature}/{form} : v2.0.4 16 Novembre 2020 per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature 13 Novembre 2020 rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature. 12 Novembre 2020 ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] } v2.0.3 11 Novembre 2020 Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata. 9 Novembre 2020 Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink 6 Novembre 2020 L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db) v2.0.2 4 Novembre 2020 Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"Home"},{"location":"CHANGELOG/#changelog","text":"","title":"CHANGELOG"},{"location":"CHANGELOG/#v208","text":"","title":"v2.0.8"},{"location":"CHANGELOG/#23-marzo-2021","text":"unificata la struttura di backend che gestisce le chiamate alle serie (dati, mappe e in futuro clouds): Eliminati moduli hielen2.data.data_access_layer e hielen2.maps.data_access_layer e sostituiti entrambi con hielen2.query , il modulo dichiara la classe hielen2.quert.Series che prevede il parametro capability per dtingure tra [\"data\",\"maps\",\"clouds\"]. riviste le api GET /maps/ e GET /data/ , unificate sotto l'api GET /query/ in questo modo: GET /query/data/ GET /query/maps GET /query/clouds/ (futura) la parametrizzazione di \"datamap\" viene modificata eliminando \"timeto\" e \"timefrom\" ed inserendo \"times\" come slice temporale (vedi 11 Marzo 2021) ATTENZIONE: Nel caso venga richesto in risposta un mimetype \"txt\" il separatore dei campi passa da \",\" a \";\"","title":"23 Marzo 2021"},{"location":"CHANGELOG/#19-marzo-2021","text":"Revisione dell'ambiente di produzione e accenzione delle istanze su server Nhazca. Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard)","title":"19 Marzo 2021"},{"location":"CHANGELOG/#v207","text":"","title":"v2.0.7"},{"location":"CHANGELOG/#15-marzo-2021","text":"API: GET /maps/ per la generazione delle mappe.","title":"15 Marzo 2021"},{"location":"CHANGELOG/#11-marzo-2011","text":"Introdotti gli slice temporali come estenzione di marshmallow.field mappati sulla classe slice di python: Provides python object which performs selection on narry . It axcept a three filed string separated by \":\" . \":\" presence is managed as : \"start:stop:step\" ie .: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start implementato /maps/data_access_layer.py per la gestione angostica delle mappe (utilizzo della datacache)","title":"11 Marzo 2011"},{"location":"CHANGELOG/#3-marzo-2021","text":"API: DELETE /actions/{feature}/{*} agganciata a datacache (vengono tolte dalla cache le elaborazioni dipendenti da config) API: DELETE /features/{feature} pulizia cache e serie dati","title":"3 Marzo 2021"},{"location":"CHANGELOG/#25-febbraio-2021","text":"Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con json e csv su flesystem. Potr\u00e0 essere implementato con Redis.","title":"25 Febbraio 2021"},{"location":"CHANGELOG/#18-febbraio-2021","text":"Implementazione metodo astratto map che viene invocato in modo agnostico sull'istanza di un tipo con capability \"map\" per produrre le immagini elaborate. Risponde in modo standard creando l'immagine in posizione definita. Nota: Deve diventare metodo di classe","title":"18 Febbraio 2021"},{"location":"CHANGELOG/#12-febbraio-2021","text":"Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). Esteso il concetto di interrogazione con risultanza di series per data, maps, e clouds","title":"12 Febbraio 2021"},{"location":"CHANGELOG/#v206","text":"","title":"v2.0.6"},{"location":"CHANGELOG/#7-febbraio-2021","text":"Sviluppo Tinsar Implementata la richiesta di Nhazca: - Anticipata analisi di potree e generazione / colorazione clouds. - Implementato mockup 3D funzionante - Compilazione e utilizzo di PotreConverter","title":"7 Febbraio 2021"},{"location":"CHANGELOG/#27-gennaio-2021","text":"Inserita la validazione dei campi delle action","title":"27 Gennaio 2021"},{"location":"CHANGELOG/#25-gennaio-2021","text":"Inserito il campo \"hint\" nella risposta di GET /actionschemata[/{feature}[/{action}]] Implementata astrazione di DELETE /actions/{feature}/{action}/ . Prima della rimozione della specifica azione dal db, vengono chimati i metodi preposti alla gestione della rimozione delle informazioni in cache, che si presuppone siano implemetati dai relativi moduli. I moduli possono implementare questi metodi solo se necessario. Sintassi: Invocando il metodo deleteActionValues(self,action,timestamp) della superclasse Hielen2.Source, essa tenter\u00e0 di utilizzare il metodo della sottoclasse il cui nome \u00e8 cotruito dal'unione della parola \"delete\" + il nome dell'azione con la prima lettera maiuscola: es: \"deleteConfig\". la superclasse passer\u00e0 sempre un timestamp per individuare l'azione specifica Implementato il metodo \"deleteConfig\" della classe Hielen2.ext.source_PhotoMonitoring Corretto bug minore di gestione delle azioni in caso esse producano errori non preventivati.","title":"25 Gennaio 2021"},{"location":"CHANGELOG/#22-gennaio-2021","text":"Ristrutturata la pagina di TODO , inserita categorizzazione e valutazione delle tempistica delle attivit\u00e0","title":"22 Gennaio 2021"},{"location":"CHANGELOG/#20-gennaio-2021","text":"modulo hielen2.ext.source_PhotoMonitoring : rimodellato sulla base del modulo hielen2.source . definite le classi schema per le azioni: ## action 'config' (Completamente Funzionante) class ConfigSchema ( ActionSchema ): master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Str ( required = False , default = \"8\" ) window_size_change = fields . Str ( required = False , default = \"0\" ) geo_reference_file = LocalFile ( required = False , default = None ) crs = fields . Str ( required = False , default = None ) ## action 'feed' class FeedSchema ( ActionSchema ): reference_time = fields . Str ( required = False , allow_none = False ) NS_displacement = LocalFile ( required = False , allow_none = False ) EW_displacement = LocalFile ( required = False , allow_none = False ) Coer = LocalFile ( required = False , allow_none = False )","title":"20 Gennaio 2021"},{"location":"CHANGELOG/#18-gennaio-2021","text":"Revisione concettuale delle API e modifiche: GET /parametes : lo schema di ritorno \u00e8 il seguente (semplicemente \"param\" al posto di \"name\" ): { ..., \"data\": { \"ARCCE01\": [ { \"series\": \"ARCCE01_Rotazione_X\", \"param\": \"Rotazione X\", \"unit\": \"mm/m\"}, ..... } ] } actionSchemata \u00e8 l'api che fornir\u00e0 gli schemi per le azioni e va a sostituire quella che era \"prototypes\". Questa esiste ancora e mantiene il legame tra prototipo e modulo ma pi\u00f9 che altro le informazioni che stanno nella relativa tabella mi servono per il back-end GET ../actionschemata[/{prototypes}[/{actions}]] action come prima, \u00e8 l'api che gestisce le azioni: La versione POST nella sostanza non \u00e8 cambiata a parte il fatto che un'azione dichiarer\u00e0 sempre un timestamp per default. Ma questa cosa al front-end non interessa dal momento che le info le recupera da actionSchemanta. E' invece importante nella scrittura dei plugin perch\u00e9 in questo modo le azioni possono essere gestite temporalmente. La versione GET , invece cambia sostanzialmente: non fornir\u00e0 pi\u00f9 i default per la post MA potr\u00e0 fornire una serie temporale di azioni associate a dei valori di elaborazione che danno informazioni all'utente. in questo formato: GET ../actions[/{feature}[/{action}]] ritorna: [ { \"timestamp\":....,\"value\":.... }, { \"timestamp\":...., \"value\":.... }, .... ] esempio: GET .. / actions / featurecode / config { \"meta\" : { \"response\" : \"ok\" , \"message\" : \"\" , \"data_type\" : \"GET /actions/ciaociaociao4/config\" } , \"data\" : [ [ { \"timestamp\" : \"2020-12-30 01:00:05\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=14, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010005\" , \"crs\" : null } } , { \"timestamp\" : \"2020-12-30 01:00:07\" , \"value\" : { \"master_image\" : \"TIFF image data, little-endian, direntries=16, height=1842, bps=16, compression=none, PhotometricIntepretation=BlackIsZero, width=3545\" , \"timestamp\" : \"2020-12-30 01:00:07\" , \"step_size\" : \"35\" , \"window_size_change\" : \"10\" , \"transform\" : [ 15 . 0 , 0 . 0 , 464947 . 5 , 0 . 0 , - 15 . 0 , 7977067 . 5 ], \"cache\" : \"20201230010007\" , \"crs\" : \"EPSG:32622\" } } ] ] }","title":"18 Gennaio 2021"},{"location":"CHANGELOG/#15-gennaio-2021","text":"modulo hielene2.source : Implementato il metodo sourceFactory per la generazione degli ogetti HeielenSource in base ai prototipi che sfrutta il cariacmanto dinamico dei moduli specifici (metodo loadModule ) Implementati i metodi e le classi per la gestione agnostica delle azioni ed il recupero degli schemi: getActionSchema , moduleAction , HielenSource.execAction , HielenSource.getActionValues Implementata la gestione dell'ambiente di cache dedicato alle singole istanze di HielenSource: HielenSource.makeCachePath , HielenSource.getRelativePath Definita la classe primitiva per i modelli di schema per le azioni che impone la definizione della marcatura temporale: class ActionSchema(Schema): timestamp = fields.Str(required=True, allow_none=False)","title":"15 Gennaio 2021"},{"location":"CHANGELOG/#13-gennaio-2021","text":"rimodellato il db: dalla tabella \"features\" sono state eliminate le colonne \"a priori\" delle azioni. Queste ultime sono state inserite in una nuova tabella \"actions\" con chiave multipla (\"feature\",\"action\",\"timestamp\"). Rivista l'interfaccia db per permettere l'interrogazione su chiave multipla","title":"13 Gennaio 2021"},{"location":"CHANGELOG/#10-gennaio-2021","text":"Progettazione della gestione temporale delle azioni e separazione del concetto di form da quello di risultato della azione: ogni azione ha uno schema di input e dei risultati in output con uno schema non necessariamente coincidente. Quello che viene fornito alle form sono i dati necessari ad intraprendere un'azione. I risultati dell'azione devono essere registrati con una marcatura temporale. In questo modo ogni azione \u00e8 univocamente determinata e gestibile con un modello del tipo (\"feature\",\"action\",\"timestamp\"), con una cardinalit\u00e0 1-a-molti tra features e azioni Portata a termine la migrazione della gestione delle azioni che vengono ora completamente affidate ai singoli moduli. L'iterfaccia di alto livello \u00e8 ora in grado di gestire agonsticamente le chiamate ad azioni arbitrarie purch\u00e8 ben definite all'interno dei moduli. In questo modo cade il vincolo di definizione do azione \"a priori\"","title":"10 Gennaio 2021"},{"location":"CHANGELOG/#30-dicembre-2020","text":"sviluppo (non completo) di config hielen2.ext.PhotoMonitoring: Implementato il metodo di recupero e settaggio delle informazioni geometriche/geografiche dell'immagine in ingresso Aggancio del codice originale per la gesgione del netcdf (in debug)","title":"30 Dicembre 2020"},{"location":"CHANGELOG/#22-dicembre-20202","text":"Delineata la gestione di mappa delle immagini prodotte: Ogni immagine prodotta sar\u00e0 sempre associata al suo crs e la matrice di trasformazione affine, anche nele caso in cui queste informazioni non dovessero essere passate in configurazione. In questo caso si assume un piano cartesiano con udm in m e una matrice identit\u00e0 per le trasformazioni affini. Sar\u00e0 dunque sempre possibile gestire le immagini come mappe (slippy maps) e sfruttare la tassellazione, il cacheing dei tasselli.","title":"22 Dicembre 20202"},{"location":"CHANGELOG/#20-dicembre-2020","text":"Modificata l'api POST /actions/{feature}/{form} in modo da interrogare la Source (per ora solo PhotoMonitoring) sulla definizione delle azioni: Implementate le classi di Schema per config e feed per il modulo hielen2.ext.PhotoMonitoring . ATTENZIONE per config : introdotto il campo \"timestamp\", eliminati i campi espliciti relativi al word_file ( word_file mantenuto), modificato il campo epsg in csr .","title":"20 Dicembre 2020"},{"location":"CHANGELOG/#15-dicembre-2020","text":"Delineato il modello di scrittura dei Source plugin secondo un template univoco. Ogni plugin potr\u00e0 essere un modulo python definito come segue: deve definire tante classi marshmallow.Schema quante sono le azioni che vengono prese in carico dal Template. Marsmallow \u00e8 un serializzatore di oggetti python. Lo schema definito servir\u00e0 per definire i campi in ingresso per ogni azione e fare i check dei valori in ingresso. Il nome delle classi Schema deve seguire questa sintassi: class {Action}Schema(marshmallow.Schema) dove {Action} \u00e8 il nome dell'azione (es.: config, feed, ..) con l'iniziale maiuscola . Nella classe vengono definiti i tipi dei campi ( marshmallow.fields cfr. https://marshmallow.readthedocs.io/en/stable/ ). ATTENZIONE: in caso fosse necessario l'ingresso di file o comunque oggetti blob dovr\u00e0 essere utilizzato come field la classe hielen2.utils.LocalFile . In questo modo il sistema risolver\u00e0 la chiamata API salvando in locale lo stream dei dati associato a quel determinato field, il quale sar\u00e0 accessibile al template attraverso un path che verr\u00e0 fornito insieme agli altri campi al momento della chiamata del metodo di gestione dell'azione (vedi sotto). deve implementare una classe Source(hielen2.datalink.HielenSource) che esponga tanti metodi quante sono le dichiarazioni di Schema seguendo questa sintassi: il metodo di gestione dell'azione deve chiamarsi come l'azione stessa ( tutto in minuscolo ). Le classi estese sfrutteranno il metodo __init__ della superclasse in modo da avere a disposizione tutto quello di cui necessitano. Questo modello permette di svincolare i template dalla necessit\u00e0 di conoscere a priori le azioni ammmissibili per il sistema. Infatti, facendo introspezione su un template che segua le regole di sintassi sar\u00e0 sempre possibile conoscere le azioni definite ed esternalizzarle al front-end che in base alle definizioni delle classi di Schema delle azioni, sar\u00e0 sempre in grado di instanziare una form adeguata.","title":"15 Dicembre 2020"},{"location":"CHANGELOG/#v205","text":"","title":"v2.0.5"},{"location":"CHANGELOG/#9-dicembre-2020","text":"Implementata working POST /actions/{feature}/{form} tramite content-type/multipart dinamico definito dal prototipo: L'api \u00e8 collegata ai moduli reali delle tipologie definiti come templates, con la funzionalit\u00e0 minima di salvare i parametri in ingresso. I moduli sono in fase di sviluppo e man mano che vengono implementati le funzionalit\u00e0 aumenteranno. Implementato Loading dinamico dei moduli di elaborazione definiti come estensioni di hielen2.datalink.HielenSource Implementata working GET /actions/{feature}[/{form}] : Per ogni form richiesta, risponde con tutti i parametri definiti nel relativo prototipo, riempiti con i valori definiti tramite la POST della stessa api. I valori non precedentemente forniti vengono impostati a null Riveduta e corretta GET prototypes/{prototype}/forms[/form] : ATTENZIONE adesso risponde con TUTTI i campi dentro il dizionario \"args\" e comunica i campi obbligatori attraverso l'array \"mandatory\". Questa struttura \u00e8 pi\u00f9 versatile in quanto, una volta definito il set completo degli argomenti, \u00e8 possibile definire un numero arbitrario di sottoinsiemi predicativi non necessariamente distiniti: Oltre al sottoinsieme \"mandatory\" si potrebbe, ad esempio, definire un sottoinsieme di immutabili. Qui sotto una struttura di esempio: { \"data\": { \"args\": { \"epsg\": \"string\", \"master_image\": \"file\", \"negative_pixel_y_size\": \"string\", \"pixel_x_size\": \"string\", \"rotation_about_the_x_axis\": \"string\", \"rotation_about_the_y_axis\": \"string\", \"step_size\": \"string\", \"window_size_change\": \"string\", \"world_file\": \"file\", \"x_coordinate_of_upper_left_pixel_center\": \"string\", \"y_coordinate_of_upper_left_pixel_center\": \"string\" }, \"mandatory\": [ \"master_image\", \"step_size\", \"window_size_change\" ] }, \"meta\": { \"data_type\": \"GET /prototypes/PhotoMonitoring/forms/config\", \"message\": \"\", \"response\": \"ok\" } }","title":"9 Dicembre 2020"},{"location":"CHANGELOG/#7-dicembre-2020","text":"Rimodellato il feature db per contenere gli argomenti delle actions Riveduto il feature_proto db: Inserito il modulo di riferimento tra le info del prototipo (il modulo contenete la classe estesa di hielen2.datalink.HielenSource ) Definita la superclasse hielen2.datalink.HielenSource con definizione univoca di __init__ con questo footprint: (self,featureobject,environment) . La classe definisce inotre i metodi astratti che vengono utilizzati dal sistema che ogni estensione di questa dovr\u00e0 implementare.","title":"7 Dicembre 2020"},{"location":"CHANGELOG/#2-dicembre-2020","text":"Struttura definitiva delle features: { \"properties\":\"...\" \"parameters\":\"...\" \"geometry\":\"...\" } dove: properties mantiene tutte le info della feature. Quelle di base: uid , type , classification , location , description e quelle definite per le specifiche azioni definite per la tipologia. In particolare quella di configurzione. parameters mantiene la struttura di accesso alle info e ai dati dei parametri definiti per la feature. geometry fornisce le informazioni geometriche della feature. Rivedute le api /actions , /parameters , /features ( /data da rivedere)","title":"2 Dicembre 2020"},{"location":"CHANGELOG/#24-novembre-2020","text":"Implementate dummy /actions/{feature}/ e /actions/{feature}/{form}","title":"24 Novembre 2020"},{"location":"CHANGELOG/#23-novembre-2020","text":"Riorganizzato il db delle features per permettere una gestione pi\u00f9 razionale","title":"23 Novembre 2020"},{"location":"CHANGELOG/#19-novembre-2020","text":"riorganizzata la struttura per la gestione delle classi estese che necessitano di dynamic loading: nel modulo himada2.ext (cartella) vengono raccoliti per comodit\u00e0 gli oggetti che saranno implementati man mano come estensione di superclassi astratte appositamente definite: per ora hielen2.datalink.Source e hielen2.datalink.DB e hielen2.datalink.DataCache. Oltre alle classi in hielen2.ext, il sitema potr\u00e0 utilizzare moduli esterni che estendano le superclassi elencate. inserito 'timestamp' nello schema json accettato da POST /feature e PUT /feature . risolto bug minore di incoerenza su GET /data/{feature} e /data/{feature}/{parameter} . Quest'ultima continua ad accettare uno tra i nomi dei parametri della feature. Entrambe rispondo intestando le colonne in uscita con lo uid della serie, come GET /data/ .","title":"19 Novembre 2020"},{"location":"CHANGELOG/#17-novembre-2020","text":"Implementata dummy POST /actions/{feature}/{form} :","title":"17 Novembre 2020"},{"location":"CHANGELOG/#v204","text":"","title":"v2.0.4"},{"location":"CHANGELOG/#16-novembre-2020","text":"per coerenza rivisti i parametri di POST /feature : uid:<string> prototype:<string> properties:<json schema Properties> geometry:<json schema GeoJson> analogo discorso per PUT /feature/{uid} : properties:<json schema Properties> geometry:<json schema GeoJson> sistemata la risposta di GET /feature , modificando il livello di \"geometry\" implementata api PUT /features/{uid} . Accetta il paramentro properties con uno schema analogo al parmetro feature di POST /features con queste differenze: nello schema della PUT, uid e prototype NON vengono accettati perch\u00e8 sono campi chiave della feature e non possono essere modificati . lo uid della feature deve essere specificato come url e non come parametro. introduzione dello Schema GeoJson per la validazione modificata POST /features/ per accettare un GeoJson nell'attibuto geometry del Json principale feature","title":"16 Novembre 2020"},{"location":"CHANGELOG/#13-novembre-2020","text":"rinominazione DELETE /elements -> DELETE /features . eliminazione degli alias GET /features/{context} e /features/{context}/{uid} a causa del conflitto l'entry point DELETE /features . Il passaggio del context sar\u00e0 esclusivmante attraverso il parametro cntxt ( nota : questo nome \u00e8 dovuto alla collisione del nome con il campo 'context' dell'oggetto request). In caso lo possiamo cambiare. introduzione dell'alias /features/{uid} per il recupero delle info della specifica Feature.","title":"13 Novembre 2020"},{"location":"CHANGELOG/#12-novembre-2020","text":"ovunque nel mondo il parmetro 'uuid' (universal unique id) diventa 'uid'. rinominazione POST /elements -> POST /features . rinominazione GET /elements -> GET /parameters e modifica uscita in questo schema: { < feature1_UID > :[ { \"series\" : < feature1_param1_series_UID > , \"param\" : < feature1_param1_name > , \"um\" : < feature1_param1_measurement_unit > } , ... { \"series\" : < feature1_paramN_series_UID , \"param\" : < feature1_paramN_name > , \"um\" : < feature1_paramN_meaurement_unit > } ], ... < featureX_UID > :[ { \"series\" : < featureX_param1_series_UID > , \"param\" : < featureX_param1_name > , \"um\" : < featureX_param1_measurement_unit > } , ... { \"series\" : < featureX_paramM_series_UID , \"param\" : < featureX_paramM_name > , \"um\" : < featureX_paramM_meaurement_unit > } ] } introduzione api /features con lo schema usato da Daniele e SimoneD: GET /features GET /features/{context}/ GET /features/{context}/{feature} uscita : nota 1: NON viene introdotto \"context\" , come invece preventivato nota 2: \"cod\" diventa \"label\" . nota 3: \"date\" diventa \"timestamp\" nota 3: dalle properties vengono elminate \"z\" e \"mslm\" . nota 4: \"state\" viene mantenuto ma per ora \u00e8 inutilizzato { \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" :..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } , ... { \"type\" : \"Feature\" , \"properties\" : { \"uid\" : ..., \"label\" : ..., \"context\" : ..., \"date\" : ..., \"type\" : ..., \"style\" : ..., \"state\" : ... } , \"geometry\" : < GeoJson Validable > } ] }","title":"12 Novembre 2020"},{"location":"CHANGELOG/#v203","text":"","title":"v2.0.3"},{"location":"CHANGELOG/#11-novembre-2020","text":"Modificata api POST /elements : la variabile element \u00e8 descritta dalla Classe hielen2.api.data.ElementSchema e validata. In paricolare \u00e8 stato introdotto l'attibuto context Modifcata api GET /data : la variabile datamap \u00e8 descritta dalla Classe hielen2.api.data.DataMapSchema e validata.","title":"11 Novembre 2020"},{"location":"CHANGELOG/#9-novembre-2020","text":"Introdotta la classe hielen2.utils.JsonValidable, per la validazione e documentazione automatica dei parametri delle api (JSON Schema descrition) corretti bug minori in hielen2.datalink","title":"9 Novembre 2020"},{"location":"CHANGELOG/#6-novembre-2020","text":"L'interfaccia DB \u00e8 ora thread safe!!! (almeno per il dummy json db)","title":"6 Novembre 2020"},{"location":"CHANGELOG/#v202","text":"","title":"v2.0.2"},{"location":"CHANGELOG/#4-novembre-2020","text":"Implementata la documentazione automatica delle api Implementate le api POST ../elements e DELETE ../elements L'uscita per tutte le api element (e per tutte le api con risposta json in generale), seguir\u00e0 questo schema: { \"meta\": { \"data_type\": \"DELETE /elements/ciao\", \"response\": \"ok\" \"message\": \"\", }, \"data\":{ ... } } L'api /series diventa /data e cambia il suo comportamento: la variabile di tipo json datamap si aspetta il campo series invece di parameters . In questo campo devono essere inseriti i codici delle serie e non pi\u00f9 il costrutto \"codice_elemento:parametro_elemento\". I codici delle serie si possono recuperarare dall'api /elements (vedi Nota successiva) L'api /elements cambia la sua risposta e per ogni parametro nella lista parameters degli elementi viene agiunto il codice della serie di riferimento che pu\u00f2 essere fornito senza modifiche a /data : { \"series\":<seriescode>, \"name\":<seriesname>, \"um\":<seriesunit> } GET /series GET /series/{el} GET /series/{el}/{param} GET /prototypes GET /prototypes/{type} GET /prototypes/{type}/forms GET /prototypes/{type}/forms/{form} POST /elements GET /elements GET /elements/{el} DELETE /elements/{el}","title":"4 Novembre 2020"},{"location":"MODELLO/","text":"Con Priorit\u00e0 Structure gestore della configurazione di base: modulo utilizzo stato datalink.py livello di astrazione db, interfacce json completo, integrabile utils.py strumenti accessori completo, integrabile source.py astrazione dei moduli di gestione completo, integrabile modello db: tabella descrizione stato features_proto prototipi features info sui moduli completa features persistenza delle features completa actions persistenza delle azioni completa series_proto prototipi serie dati per configurazione dinamica implementazione series peristenza info di elaborazione serie dati avanzato series_cache persistenza serie dati elaborate runtime json utilizzato per mockup modello api: Configurazione Abstraction layer: Produzione Interrogazione First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column Configurazione hielen2.ext.PhotoMonitoring (netCDF) definizione array dimensionali X,Y: 1- creo gli array di dimensione adeguata, 2- applico la matrice di trasformazione affine, 3- applico la proiezione da crs in input a EPSG:3857 salvare file in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) salvare il primo tile a risoluzione adeguata: filecache/{uid}/{map}/base.png salvataggio (stoccaggio) dell'immagine di base in filecache/{uid} (eventualmente compressa) Feed hielen2.ext.PhotoMonitoring analisi dei file csv in ingresso (NS, EW, Correlation se esiste) aggirnamento di filecache/{uid}/multidim.nc Configurazione hielen2.ext.TinSAR analisi della formato della master cloud salvataggio (stoccaggio) della nuvola di base recupero info geografiche in caso non esistano info di proiezione geografica si considera spazio cartesiano con coordinate con adeguate alla nuvola base (da verificare) configurare file netCDF e salvarlo in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) configurare cartella di cache per potree filecache/{uid}/{cloud} (potree) Feed hielen2.ext.TinSAR Analisi file in ingresso aggiornamento filecache/{uid}/multidim.nc aggiornamento filecache/{uid}/{cloud} v2.0.6 Interfacce delle Informazioni con risposta mockup. Intento: agganciare lavoro Daniele GET /bases GET /bases/{feature} GET /timelines GET /timelines/{feature} GET /data/ estensione del modello di datamap per accettare GeoGeson v2.0.7 Rivistazione del modulo PhotMonitoring come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione Photmonitoring alle interfacce v2.0.8 Implementazione del modulo TinSar come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione TinSar alle interfacce v2.0.9 Implementazione delle chiamate di mappa GET /maps/[/z/x/y] GET /maps/{feature}/[z/x/y] v2.0.10 Implementazione chiamate cloud GET /cloud/{feature} Senza priorit\u00e0 Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. ~~ Moduli HielenSource : Definire in backend le form come Marshmallow.Schema in modo da condividere la struttura tra moduli e api~~ Obiettivo: assegnare una timestamp ad ogni informazione: le properties degli ogetti dovranno essere delle serie dati. Concetto di informazione minima. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"MODELLO"},{"location":"MODELLO/#con-priorita","text":"","title":"Con Priorit\u00e0"},{"location":"MODELLO/#structure","text":"gestore della configurazione di base: modulo utilizzo stato datalink.py livello di astrazione db, interfacce json completo, integrabile utils.py strumenti accessori completo, integrabile source.py astrazione dei moduli di gestione completo, integrabile modello db: tabella descrizione stato features_proto prototipi features info sui moduli completa features persistenza delle features completa actions persistenza delle azioni completa series_proto prototipi serie dati per configurazione dinamica implementazione series peristenza info di elaborazione serie dati avanzato series_cache persistenza serie dati elaborate runtime json utilizzato per mockup modello api:","title":"Structure"},{"location":"MODELLO/#configurazione","text":"Abstraction layer:","title":"Configurazione"},{"location":"MODELLO/#produzione","text":"","title":"Produzione"},{"location":"MODELLO/#interrogazione","text":"First Header Second Header Content from cell 1 Content from cell 2 Content in the first column Content in the second column","title":"Interrogazione"},{"location":"MODELLO/#configurazione-hielen2extphotomonitoring-netcdf","text":"definizione array dimensionali X,Y: 1- creo gli array di dimensione adeguata, 2- applico la matrice di trasformazione affine, 3- applico la proiezione da crs in input a EPSG:3857 salvare file in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) salvare il primo tile a risoluzione adeguata: filecache/{uid}/{map}/base.png salvataggio (stoccaggio) dell'immagine di base in filecache/{uid} (eventualmente compressa)","title":"Configurazione hielen2.ext.PhotoMonitoring (netCDF)"},{"location":"MODELLO/#feed-hielen2extphotomonitoring","text":"analisi dei file csv in ingresso (NS, EW, Correlation se esiste) aggirnamento di filecache/{uid}/multidim.nc","title":"Feed hielen2.ext.PhotoMonitoring"},{"location":"MODELLO/#configurazione-hielen2exttinsar","text":"analisi della formato della master cloud salvataggio (stoccaggio) della nuvola di base recupero info geografiche in caso non esistano info di proiezione geografica si considera spazio cartesiano con coordinate con adeguate alla nuvola base (da verificare) configurare file netCDF e salvarlo in filecache/{uid}/multidim.nc (dati) definire percorso di salvataggio tiles: filecache/{uid}/{map}/ (tiles mappe) configurare cartella di cache per potree filecache/{uid}/{cloud} (potree)","title":"Configurazione hielen2.ext.TinSAR"},{"location":"MODELLO/#feed-hielen2exttinsar","text":"Analisi file in ingresso aggiornamento filecache/{uid}/multidim.nc aggiornamento filecache/{uid}/{cloud}","title":"Feed hielen2.ext.TinSAR"},{"location":"MODELLO/#v206-interfacce-delle-informazioni-con-risposta-mockup-intento-agganciare-lavoro-daniele","text":"GET /bases GET /bases/{feature} GET /timelines GET /timelines/{feature} GET /data/ estensione del modello di datamap per accettare GeoGeson","title":"v2.0.6 Interfacce delle Informazioni con risposta mockup. Intento: agganciare lavoro Daniele"},{"location":"MODELLO/#v207-rivistazione-del-modulo-photmonitoring-come-source-intento-agganciare-le-serie-dati-prodotte-dallelaborazione-photmonitoring-alle-interfacce","text":"","title":"v2.0.7 Rivistazione del modulo PhotMonitoring come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione Photmonitoring alle interfacce"},{"location":"MODELLO/#v208-implementazione-del-modulo-tinsar-come-source-intento-agganciare-le-serie-dati-prodotte-dallelaborazione-tinsar-alle-interfacce","text":"","title":"v2.0.8 Implementazione del modulo TinSar come \"source\". Intento: agganciare le serie dati prodotte dall'elaborazione TinSar alle interfacce"},{"location":"MODELLO/#v209-implementazione-delle-chiamate-di-mappa","text":"GET /maps/[/z/x/y] GET /maps/{feature}/[z/x/y]","title":"v2.0.9 Implementazione delle chiamate di mappa"},{"location":"MODELLO/#v2010-implementazione-chiamate-cloud","text":"GET /cloud/{feature}","title":"v2.0.10 Implementazione chiamate cloud"},{"location":"MODELLO/#senza-priorita","text":"Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. ~~ Moduli HielenSource : Definire in backend le form come Marshmallow.Schema in modo da condividere la struttura tra moduli e api~~ Obiettivo: assegnare una timestamp ad ogni informazione: le properties degli ogetti dovranno essere delle serie dati. Concetto di informazione minima. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"Senza priorit\u00e0"},{"location":"TODO/","text":"Nota : I tempi dichiarati sono da intendersi come di \"effettivo lavoro\", sono indicativi e potrebbero variare in base agli sviluppi (in particolare del del Modulo Principale). Inoltre i tempi riguradano esclusivamente lo sviluppo di Back-End. Anche se lo sviluppo di Front-End pu\u00f2 essere portato avanti parallelamente, sar\u00e0 necessario tenere adeguatamente in considerazione i realitivi tempi. MODULO PRICIPALE: astrazione setup di configurazione : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 2 bassa bassa Features Prototypes o Interfaccia di modulo: Integrare informazioni capability: [series,map,cloud] e cachable (non sempre \u00e8 vantaggioso usare la cache) xx - alta Completo Revisione dell'ambiente di produzione e accenzione delle istanze. xx - media Completo Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard) xx - bassa Completo inserire \"suggerimenti\" nei prototipi delle azioni da passare nella nella risposta alla chiamata \"/actionSchemata\" xx - bassa Completo API: DELETE /action/{feature}/{config} 2 2 alta alta Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). 3 2 media media Completare la Progettazione/Implementazione per la generazione delle istanze delle serie dati associate alla feature sulla base dei prototipi. Da gestire in modo omegeneo le info accessorie generate ad esepio dalle configurazioni. 2 1 alta alta Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con jsson e csv su flesystem. Potr\u00e0 essere implementato con Redis. gestione delle serie dati Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - media Completo Rivedere il modello di interrogazione omogeneo per data, maps, cloud: inserire la gesgetione degli slice temporali, Integrazione dell'interrogazione basata su GeoJeson nell'API xx - alta bassa Intergrazione dei modelli di calcolo estempranei astrazione interrogazione data : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 2 bassa alta convergere al modello omgeneo 1 1 media media implementazione della sottoclasse data di source. hielen2.source.Data(hielen2.source.Source) astrazione interrogazione mappa Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 1 bassa alta convergere al modello omgeneo 2 1 bassa alta Implementazione modello di astrazione e API per moduli con capability \"mappa\": classe estesa di source: hielen2.source.Map(hielen2.source.Data) possa essere richiamato dal layer di astrazione e che fornisca in uscita un'immagine georiferita da inserie un path ben codificato. Contestualmente viene prodotto un mapfile associato da passare a mapserver al momento dell'interrogazione (Integrato SM) astrazione interrogazione cloud Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 - alta bassa convergere al modello omgeneo 4 4 bassa media Implementazione API di interrogazione cloud: Attualmente il \"prodotto\" atteso \u00e8 una pagina html generata in automatico da fornire in front-end. 4 3 media alta Potree: installazione e gestione del software, Implementazione modulo wrapper (Integrare nel sistema lo sviluppo di GC) (1^ CONSEGNA NHAZCA) MODULO ESTESO hielen2.ext.source_PhotoMonitoring azione config : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - media Completo Attivit\u00e0 di configurazione e persistenza dati 2 2 media media Inserire il colorrange di riferimento azione feed : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - bassa Completo Aggancio del codice gi\u00e0 implementato come prototipo per Tisma + revisione interrogazione dati Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 2 1 bassa alta Agganco del codice gi\u00e0 implementato come prototipo per Tisma 4 3 media media Estrazione dati su interpolazione areale interrogazione mappa Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 3 1 media Completo Agganco del codice gi\u00e0 implementato come prototipo per Tisma + revisione 1 2 bassa associare colorrange in uscita (2^ CONSEGNA NHAZCA) MODULO ESTESO hielen2.ext.source_TinSAR azione config : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 5 3 media alta Analisi info master cloud, strutture di persistenza (verificare matrici sparse), potree run (Integrare sviluppo GC) 1 3 bassa alta Salvataggio delle info sul modello di source_PhotoMonitoring azione feed : Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 2 4 media alta Analisi file in ingresso ed elaborazione file in ingresso (parzialmente implementato) 3 4 media media Aggiornamento strutture di persistenza interrogazione series Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 3 5 media bassa Interazione tramite modello di astrazione (interrogazione tramite GeoJeson mutuabile da source_Photomonitoring). Nota : Estrazione puntuale del front-end parzialmente implementata (Integrare sviluppo GC + DD). Estendere con estrazione punti in area e volume (Potree ritorna sempre un set di punti) interrogazione mappa Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - alta bassa Proiezione della nuvola su piano x,y: Da trovare un modello efficiente di proiezione. Una volta proiettata l'immagine il resto rientra nel modello generale. interrogazione cloud Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 4 5 media media Restituire in output il prodotto \"html\" della nuvola di punti. Nota : Produzione html parzialmente implementato da sviluppo di GC. ALTRO SENZA PRIORITA' Gestione degli schemi del db: Definendo gli schemi Marshmallow per le tabelle dei DB \u00e8 possibile utilizzare Dump e Load per aggirare la non seriabilit\u00e0 di datetime Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"TODO"},{"location":"TODO/#modulo-pricipale","text":"","title":"MODULO PRICIPALE:"},{"location":"TODO/#astrazione-setup-di-configurazione","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 2 bassa bassa Features Prototypes o Interfaccia di modulo: Integrare informazioni capability: [series,map,cloud] e cachable (non sempre \u00e8 vantaggioso usare la cache) xx - alta Completo Revisione dell'ambiente di produzione e accenzione delle istanze. xx - media Completo Mapserver: istanza mapserver con workers (vedi Ecoplame) per la gestione delle mappe statiche tassellate (chiamate wms standard) xx - bassa Completo inserire \"suggerimenti\" nei prototipi delle azioni da passare nella nella risposta alla chiamata \"/actionSchemata\" xx - bassa Completo API: DELETE /action/{feature}/{config} 2 2 alta alta Revisione del modello di Source con sottoclassi source->data->map->cloud: Ogni sottoclasse estende le funzionalit\u00e0 in modo da avere livlli di capabilities gerarchici (\"cloud\" \u2283 \"map\" \u2283 \"data\"). Di fatto si pu\u00f2 intendere ogni tipologia di elaborazione come timeseries la cui produzione \u00e8 legata alla specifica capability della tipologia di sorgente (es: le mappe elaborate del parametro \"displacement\" di una specifica feature da una certa data ad un'altra ). 3 2 media media Completare la Progettazione/Implementazione per la generazione delle istanze delle serie dati associate alla feature sulla base dei prototipi. Da gestire in modo omegeneo le info accessorie generate ad esepio dalle configurazioni. 2 1 alta alta Impelementazione del modulo astratto datacache. Necessario per lo storing delle serie dati. Attualmente implementato con jsson e csv su flesystem. Potr\u00e0 essere implementato con Redis.","title":"astrazione setup di configurazione:"},{"location":"TODO/#gestione-delle-serie-dati","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - media Completo Rivedere il modello di interrogazione omogeneo per data, maps, cloud: inserire la gesgetione degli slice temporali, Integrazione dell'interrogazione basata su GeoJeson nell'API xx - alta bassa Intergrazione dei modelli di calcolo estempranei","title":"gestione delle serie dati"},{"location":"TODO/#astrazione-interrogazione-data","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 2 bassa alta convergere al modello omgeneo 1 1 media media implementazione della sottoclasse data di source. hielen2.source.Data(hielen2.source.Source)","title":"astrazione interrogazione data:"},{"location":"TODO/#astrazione-interrogazione-mappa","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 1 bassa alta convergere al modello omgeneo 2 1 bassa alta Implementazione modello di astrazione e API per moduli con capability \"mappa\": classe estesa di source: hielen2.source.Map(hielen2.source.Data) possa essere richiamato dal layer di astrazione e che fornisca in uscita un'immagine georiferita da inserie un path ben codificato. Contestualmente viene prodotto un mapfile associato da passare a mapserver al momento dell'interrogazione (Integrato SM)","title":"astrazione interrogazione mappa"},{"location":"TODO/#astrazione-interrogazione-cloud","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 1 - alta bassa convergere al modello omgeneo 4 4 bassa media Implementazione API di interrogazione cloud: Attualmente il \"prodotto\" atteso \u00e8 una pagina html generata in automatico da fornire in front-end. 4 3 media alta Potree: installazione e gestione del software, Implementazione modulo wrapper (Integrare nel sistema lo sviluppo di GC)","title":"astrazione interrogazione cloud"},{"location":"TODO/#1-consegna-nhazca-modulo-esteso-hielen2extsource_photomonitoring","text":"","title":"(1^ CONSEGNA NHAZCA) MODULO ESTESO hielen2.ext.source_PhotoMonitoring"},{"location":"TODO/#azione-config","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - media Completo Attivit\u00e0 di configurazione e persistenza dati 2 2 media media Inserire il colorrange di riferimento","title":"azione config:"},{"location":"TODO/#azione-feed","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - bassa Completo Aggancio del codice gi\u00e0 implementato come prototipo per Tisma + revisione","title":"azione feed:"},{"location":"TODO/#interrogazione-dati","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 2 1 bassa alta Agganco del codice gi\u00e0 implementato come prototipo per Tisma 4 3 media media Estrazione dati su interpolazione areale","title":"interrogazione dati"},{"location":"TODO/#interrogazione-mappa","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 3 1 media Completo Agganco del codice gi\u00e0 implementato come prototipo per Tisma + revisione 1 2 bassa associare colorrange in uscita","title":"interrogazione mappa"},{"location":"TODO/#2-consegna-nhazca-modulo-esteso-hielen2extsource_tinsar","text":"","title":"(2^ CONSEGNA NHAZCA) MODULO ESTESO hielen2.ext.source_TinSAR"},{"location":"TODO/#azione-config_1","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 5 3 media alta Analisi info master cloud, strutture di persistenza (verificare matrici sparse), potree run (Integrare sviluppo GC) 1 3 bassa alta Salvataggio delle info sul modello di source_PhotoMonitoring","title":"azione config:"},{"location":"TODO/#azione-feed_1","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 2 4 media alta Analisi file in ingresso ed elaborazione file in ingresso (parzialmente implementato) 3 4 media media Aggiornamento strutture di persistenza","title":"azione feed:"},{"location":"TODO/#interrogazione-series","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 3 5 media bassa Interazione tramite modello di astrazione (interrogazione tramite GeoJeson mutuabile da source_Photomonitoring). Nota : Estrazione puntuale del front-end parzialmente implementata (Integrare sviluppo GC + DD). Estendere con estrazione punti in area e volume (Potree ritorna sempre un set di punti)","title":"interrogazione series"},{"location":"TODO/#interrogazione-mappa_1","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 xx - alta bassa Proiezione della nuvola su piano x,y: Da trovare un modello efficiente di proiezione. Una volta proiettata l'immagine il resto rientra nel modello generale.","title":"interrogazione mappa"},{"location":"TODO/#interrogazione-cloud","text":"Giorni/Uomo effettivi Priorit\u00e0 Complessit\u00e0 Copertura Attivit\u00e0 4 5 media media Restituire in output il prodotto \"html\" della nuvola di punti. Nota : Produzione html parzialmente implementato da sviluppo di GC.","title":"interrogazione cloud"},{"location":"TODO/#altro-senza-priorita","text":"Gestione degli schemi del db: Definendo gli schemi Marshmallow per le tabelle dei DB \u00e8 possibile utilizzare Dump e Load per aggirare la non seriabilit\u00e0 di datetime Moduli HielenSource : attualmente, per comodit\u00e0, vengono sviluppati come sotto moduli di hielen2 ma il modo corretto \u00e8 quello di separare lo sviluppo. Sar\u00e0 sempre possibile farlo dal momento che le strutture vengono sviluppate con l'obiettivo della separazione. Implementare procedura di testing delle api verificare il default dei campi marshmallow (sembra non prenderlo in considerazione, prob non arriva null ma \"\") POST /prototypes Migliorare l'output dei doc del JsonValidable Gestire i filed Nested nei doc del JsonValidable","title":"ALTRO SENZA PRIORITA'"},{"location":"docs/API%20Reference/actions/","text":"Actions /actions/{feature} GET params : feature : Basic text / string value actions : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione /actions/{feature}/{action} GET params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Recupero dello stato corrente per una specifica azione di una specifica feature** DELETE params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Eliminazione di una determinata azione di una specifica feature** POST params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default.","title":"Actions"},{"location":"docs/API%20Reference/actions/#actions","text":"","title":"Actions"},{"location":"docs/API%20Reference/actions/#actionsfeature","text":"","title":"/actions/{feature}"},{"location":"docs/API%20Reference/actions/#get","text":"params : feature : Basic text / string value actions : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione","title":"GET"},{"location":"docs/API%20Reference/actions/#actionsfeatureaction","text":"","title":"/actions/{feature}/{action}"},{"location":"docs/API%20Reference/actions/#get_1","text":"params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Recupero dello stato corrente per una specifica azione di una specifica feature**","title":"GET"},{"location":"docs/API%20Reference/actions/#delete","text":"params : feature : Basic text / string value action : Basic text / string value timestamp : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Eliminazione di una determinata azione di una specifica feature**","title":"DELETE"},{"location":"docs/API%20Reference/actions/#post","text":"params : feature : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default.","title":"POST"},{"location":"docs/API%20Reference/actionschemata/","text":"Actionschemata /actionschemata/ GET params : prototypes : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, /actionschemata/{prototype} GET params : prototype : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni di uno specifico prototipo /actionschemata/{prototype}/{action} GET params : prototype : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo","title":"ActionSchemata"},{"location":"docs/API%20Reference/actionschemata/#actionschemata","text":"","title":"Actionschemata"},{"location":"docs/API%20Reference/actionschemata/#actionschemata_1","text":"","title":"/actionschemata/"},{"location":"docs/API%20Reference/actionschemata/#get","text":"params : prototypes : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... },","title":"GET"},{"location":"docs/API%20Reference/actionschemata/#actionschemataprototype","text":"","title":"/actionschemata/{prototype}"},{"location":"docs/API%20Reference/actionschemata/#get_1","text":"params : prototype : Basic text / string value actions : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni di uno specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/actionschemata/#actionschemataprototypeaction","text":"","title":"/actionschemata/{prototype}/{action}"},{"location":"docs/API%20Reference/actionschemata/#get_2","text":"params : prototype : Basic text / string value action : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/data/","text":"Data /data/ GET params : datamap : JSON Schema [{ series : [str|bytes], timeto : str|bytes, timefrom : str|bytes}] content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8 /data/{feature}/ GET params : feature : Basic text / string value par : Basic text / string value timefrom : Basic text / string value timeto : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8 /data/{feature}/{par} GET params : feature : Basic text / string value par : Basic text / string value timefrom : Basic text / string value timeto : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"Data"},{"location":"docs/API%20Reference/data/#data","text":"","title":"Data"},{"location":"docs/API%20Reference/data/#data_1","text":"","title":"/data/"},{"location":"docs/API%20Reference/data/#get","text":"params : datamap : JSON Schema [{ series : [str|bytes], timeto : str|bytes, timefrom : str|bytes}] content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/data/#datafeature","text":"","title":"/data/{feature}/"},{"location":"docs/API%20Reference/data/#get_1","text":"params : feature : Basic text / string value par : Basic text / string value timefrom : Basic text / string value timeto : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/data/#datafeaturepar","text":"","title":"/data/{feature}/{par}"},{"location":"docs/API%20Reference/data/#get_2","text":"params : feature : Basic text / string value par : Basic text / string value timefrom : Basic text / string value timeto : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/features/","text":"Features /features/ POST params : uid : Basic text / string value prototype : Basic text / string value properties : JSON Schema { location : str|bytes, label : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, style : str|bytes, context : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Creazione delle Features. Ogni feature deve avere il suo codice univoco uid e il suo prototipo prototype . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. GET params : uids : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } nota : Al contrario di quanto detto nel TODO non viene inserito il context a livello \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' interno delle properties delle singole features. Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri /features/{uid} GET params : uid : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di recupero informazioni della specifica feature** PUT params : uid : Basic text / string value properties : JSON Schema { location : str|bytes, label : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, style : str|bytes, context : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. DELETE params : uid : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente.","title":"Features"},{"location":"docs/API%20Reference/features/#features","text":"","title":"Features"},{"location":"docs/API%20Reference/features/#features_1","text":"","title":"/features/"},{"location":"docs/API%20Reference/features/#post","text":"params : uid : Basic text / string value prototype : Basic text / string value properties : JSON Schema { location : str|bytes, label : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, style : str|bytes, context : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Creazione delle Features. Ogni feature deve avere il suo codice univoco uid e il suo prototipo prototype . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente.","title":"POST"},{"location":"docs/API%20Reference/features/#get","text":"params : uids : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } nota : Al contrario di quanto detto nel TODO non viene inserito il context a livello \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' interno delle properties delle singole features. Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri","title":"GET"},{"location":"docs/API%20Reference/features/#featuresuid","text":"","title":"/features/{uid}"},{"location":"docs/API%20Reference/features/#get_1","text":"params : uid : Basic text / string value cntxt : Basic text / string value info : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di recupero informazioni della specifica feature**","title":"GET"},{"location":"docs/API%20Reference/features/#put","text":"params : uid : Basic text / string value properties : JSON Schema { location : str|bytes, label : str|bytes, timestamp : str|bytes, status : str|bytes, description : str|bytes, style : str|bytes, context : str|bytes} geometry : JSON Schema {} result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente.","title":"PUT"},{"location":"docs/API%20Reference/features/#delete","text":"params : uid : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente.","title":"DELETE"},{"location":"docs/API%20Reference/mapping/","text":"Mapping /mapping/ GET params : datamap : JSON Schema [{ timeref : str|bytes, times : , refresh : bool, series : [str|bytes]}] content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8 /mapping/{feature}/ GET params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8 /mapping/{feature}/{par} GET params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"Mapping"},{"location":"docs/API%20Reference/mapping/#mapping","text":"","title":"Mapping"},{"location":"docs/API%20Reference/mapping/#mapping_1","text":"","title":"/mapping/"},{"location":"docs/API%20Reference/mapping/#get","text":"params : datamap : JSON Schema [{ timeref : str|bytes, times : , refresh : bool, series : [str|bytes]}] content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/mapping/#mappingfeature","text":"","title":"/mapping/{feature}/"},{"location":"docs/API%20Reference/mapping/#get_1","text":"params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/mapping/#mappingfeaturepar","text":"","title":"/mapping/{feature}/{par}"},{"location":"docs/API%20Reference/mapping/#get_2","text":"params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: Free form UTF-8 text, JSON (Javascript Serialized Object Notation) content_type : text/plain; charset=utf-8, application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/maps/","text":"Maps /maps/ GET params : datamap : JSON Schema [{ series : [str|bytes], refresh : bool, timeref : str|bytes, times : }] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /maps/{feature}/ GET params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /maps/{feature}/{par} GET params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"Maps"},{"location":"docs/API%20Reference/maps/#maps","text":"","title":"Maps"},{"location":"docs/API%20Reference/maps/#maps_1","text":"","title":"/maps/"},{"location":"docs/API%20Reference/maps/#get","text":"params : datamap : JSON Schema [{ series : [str|bytes], refresh : bool, timeref : str|bytes, times : }] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/maps/#mapsfeature","text":"","title":"/maps/{feature}/"},{"location":"docs/API%20Reference/maps/#get_1","text":"params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/maps/#mapsfeaturepar","text":"","title":"/maps/{feature}/{par}"},{"location":"docs/API%20Reference/maps/#get_2","text":"params : feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/parameters/","text":"Parameters /parameters/ GET params : uids : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : ** Ricerca dei parametri associati alle features ** . __nota__ : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo : { \"<fetUID>\" :[ { \"series\" : \"<series_UID>\" , \"param\" : \"<param_name>\" , \"um\" : \"<mearurement_unit>\" } ... ] ... } Possibili risposte : - _404 Not Found_ : Nel caso in cui nessun parametro risponda ai criteri /parameters/{uid} GET params : uid : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dei Parametri della specifica Feature** /parameters/{uid}/{param} GET params : uid : Basic text / string value param : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**","title":"Parameters"},{"location":"docs/API%20Reference/parameters/#parameters","text":"","title":"Parameters"},{"location":"docs/API%20Reference/parameters/#parameters_1","text":"","title":"/parameters/"},{"location":"docs/API%20Reference/parameters/#get","text":"params : uids : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : ** Ricerca dei parametri associati alle features ** . __nota__ : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo : { \"<fetUID>\" :[ { \"series\" : \"<series_UID>\" , \"param\" : \"<param_name>\" , \"um\" : \"<mearurement_unit>\" } ... ] ... } Possibili risposte : - _404 Not Found_ : Nel caso in cui nessun parametro risponda ai criteri","title":"GET"},{"location":"docs/API%20Reference/parameters/#parametersuid","text":"","title":"/parameters/{uid}"},{"location":"docs/API%20Reference/parameters/#get_1","text":"params : uid : Basic text / string value params : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dei Parametri della specifica Feature**","title":"GET"},{"location":"docs/API%20Reference/parameters/#parametersuidparam","text":"","title":"/parameters/{uid}/{param}"},{"location":"docs/API%20Reference/parameters/#get_2","text":"params : uid : Basic text / string value param : Basic text / string value cntxt : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**","title":"GET"},{"location":"docs/API%20Reference/prepare/","text":"Prepare /prepare/map/ GET params : features : Basic text / string value timestamp : Basic text / string value paramser : Basic text / string value timeref : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : /prepare/map/{feature} GET params : feature : Basic text / string value timestamp : Basic text / string value paramser : Basic text / string value timeref : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8","title":"Prepare"},{"location":"docs/API%20Reference/prepare/#prepare","text":"","title":"Prepare"},{"location":"docs/API%20Reference/prepare/#preparemap","text":"","title":"/prepare/map/"},{"location":"docs/API%20Reference/prepare/#get","text":"params : features : Basic text / string value timestamp : Basic text / string value paramser : Basic text / string value timeref : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description :","title":"GET"},{"location":"docs/API%20Reference/prepare/#preparemapfeature","text":"","title":"/prepare/map/{feature}"},{"location":"docs/API%20Reference/prepare/#get_1","text":"params : feature : Basic text / string value timestamp : Basic text / string value paramser : Basic text / string value timeref : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/prototypes/","text":"Prototypes /prototypes/ POST params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Definizione di nuovi prototipi PLACEHOLDER: Non ancora implementato GET result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero di tutte le informazioni dei prototipi ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } } /prototypes/{prototype}/struct GET params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico prototipo","title":"Prototypes"},{"location":"docs/API%20Reference/prototypes/#prototypes","text":"","title":"Prototypes"},{"location":"docs/API%20Reference/prototypes/#prototypes_1","text":"","title":"/prototypes/"},{"location":"docs/API%20Reference/prototypes/#post","text":"params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Definizione di nuovi prototipi PLACEHOLDER: Non ancora implementato","title":"POST"},{"location":"docs/API%20Reference/prototypes/#get","text":"result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Recupero di tutte le informazioni dei prototipi ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } }","title":"GET"},{"location":"docs/API%20Reference/prototypes/#prototypesprototypestruct","text":"","title":"/prototypes/{prototype}/struct"},{"location":"docs/API%20Reference/prototypes/#get_1","text":"params : prototype : Basic text / string value result : format : JSON (Javascript Serialized Object Notation) content_type : application/json; charset=utf-8 description : Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico prototipo","title":"GET"},{"location":"docs/API%20Reference/query/","text":"Query /query/{capability} GET params : capability : Basic text / string value datamap : JSON Schema [{ refresh : bool, timeref : str|bytes, times : , geometry : , series : [str|bytes]}] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /query/{capability}/{feature}/ GET params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8 /query/{capability}/{feature}/{par} GET params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"Query"},{"location":"docs/API%20Reference/query/#query","text":"","title":"Query"},{"location":"docs/API%20Reference/query/#querycapability","text":"","title":"/query/{capability}"},{"location":"docs/API%20Reference/query/#get","text":"params : capability : Basic text / string value datamap : JSON Schema [{ refresh : bool, timeref : str|bytes, times : , geometry : , series : [str|bytes]}] content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/query/#querycapabilityfeature","text":"","title":"/query/{capability}/{feature}/"},{"location":"docs/API%20Reference/query/#get_1","text":"params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"docs/API%20Reference/query/#querycapabilityfeaturepar","text":"","title":"/query/{capability}/{feature}/{par}"},{"location":"docs/API%20Reference/query/#get_2","text":"params : capability : Basic text / string value feature : Basic text / string value par : Basic text / string value times : Basic text / string value timeref : Basic text / string value refresh : Basic text / string value content_type : Basic text / string value result : format : Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text content_type : application/json; charset=utf-8, text/plain; charset=utf-8","title":"GET"},{"location":"reference/hielen2/","text":"Module hielen2 View Source # coding=utf-8 __name__ = 'hielen2' __version__ = '2.0.8' __author__ = 'Alessandro Modesti' __email__ = 'it@img-srl.com' __description__ = 'Multidimention Hierarichical Elaboration Engine' __license__ = 'MIT' __uri__ = '' import warnings import json from .datalink import dbinit # , cacheinit def _initconf ( confile , envfile ): env = None with open ( envfile ) as ef : env = json . load ( ef ) with open ( confile ) as cf : confstr = cf . read () for k , w in env . items (): placeholder = \"{{\" + k + \"}}\" confstr = confstr . replace ( placeholder , w ) return json . loads ( confstr ) conf = _initconf ( \"./conf/hielen.json\" , \"./conf/env.json\" ) db = dbinit ( conf ) def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"conf\" , \"db\" ] Sub-modules hielen2.api hielen2.data hielen2.datalink hielen2.ext hielen2.mapmanager hielen2.query hielen2.source hielen2.utils Variables conf db","title":"Index"},{"location":"reference/hielen2/#module-hielen2","text":"View Source # coding=utf-8 __name__ = 'hielen2' __version__ = '2.0.8' __author__ = 'Alessandro Modesti' __email__ = 'it@img-srl.com' __description__ = 'Multidimention Hierarichical Elaboration Engine' __license__ = 'MIT' __uri__ = '' import warnings import json from .datalink import dbinit # , cacheinit def _initconf ( confile , envfile ): env = None with open ( envfile ) as ef : env = json . load ( ef ) with open ( confile ) as cf : confstr = cf . read () for k , w in env . items (): placeholder = \"{{\" + k + \"}}\" confstr = confstr . replace ( placeholder , w ) return json . loads ( confstr ) conf = _initconf ( \"./conf/hielen.json\" , \"./conf/env.json\" ) db = dbinit ( conf ) def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"conf\" , \"db\" ]","title":"Module hielen2"},{"location":"reference/hielen2/#sub-modules","text":"hielen2.api hielen2.data hielen2.datalink hielen2.ext hielen2.mapmanager hielen2.query hielen2.source hielen2.utils","title":"Sub-modules"},{"location":"reference/hielen2/#variables","text":"conf db","title":"Variables"},{"location":"reference/hielen2/datalink/","text":"Module hielen2.datalink View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series , read_json , NaT , read_csv from abc import ABC , abstractmethod from hielen2.utils import loadjsonfile , savejsonfile , newinstanceof , hashfile from filelock import Timeout , FileLock from numpy import nan from pathlib import Path from hashlib import md5 from shutil import rmtree import os def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ] . items () } class DB ( ABC ): @abstractmethod def __init__ ( self , connection ): pass @abstractmethod def __getitem__ ( self , key ): pass @abstractmethod def __setitem__ ( self , key , value ): pass @abstractmethod def pop ( self , key ): pass class JsonDB ( DB ): def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ): self . jsonfile = connection self . lock = FileLock ( f \" { connection } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { connection } .md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ): try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ({}, columns = self . schema [ 'columns' ]) self . db = self . db . set_index ( self . schema [ 'primary_key' ]) def __chk_and_reload_jsondb ( self , force = False ): \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ): \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key, raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key { key } to remove does not exist\" ) else : # Request to insert key, raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )): key = [ key ] if key . __len__ () < primarykey . __len__ (): raise ValueError ( f \"key { key !r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ], key )) value . update ( keydict ) df = DataFrame ([ value . values ()]) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ]) try : self . db = self . db . append ( df , verify_integrity = True ) . sort_index () except ValueError : raise ValueError ( f \"key { key } to insert exists\" ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ): out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ): out = out . to_frame () . T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index () . to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ): self . __chk_and_reload_jsondb () if isinstance ( key , list ): try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ): return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ): self . __write_jsondb ( key , value ) ''' class JsonCache(DB): def __init__(self, connection): self.cache = ( read_json(connection, convert_dates=False) .set_index([\"uid\", \"timestamp\"])[\"value\"] .sort_index() ) self.filename = connection def __getitem__(self, key): return self.cache[key] def __setitem__(self, key, value): pass def pop(self, key): pass def save(self): self.cache.reset_index().to_json(self.filename, orient=\"records\") ''' class seriescode (): def __init__ ( self , * args , ** kwargs ): self . h = [ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f ' { self . h } ' . encode () ) . hexdigest () def __repr__ ( self ): return self . h class fsHielenCache ( JsonDB ): def __init__ ( self , connection , lock_timeout_seconds = 10 ): self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" :[ \"uid\" , \"info\" ], \"primary_key\" :[ \"uid\" ]} connfile = str ( Path ( connection ) / \"index.json\" ) super () . __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ): info = super () . __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ) . get ( force_reload = True ) def __setitem__ ( self , key , value ): if value is not None and not isinstance ( value , Series ): raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key { key } doesn't seems to match requirement format\" ) #testing existence (stops if exits) if value is not None : super () . __setitem__ ( key ,{}) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics else : super () . __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ) . drop () except FileNotFoundError as e : pass def update ( self , key , value ): if value is not None and not isinstance ( value , Series ): #if value is not None and not isinstance(value,DataFrame): raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super () . __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \" { item } .csv\" ) self . lock = FileLock ( f \" { self . csv } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { self . csv } .md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try : self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e : self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e : ## refershing hash try : self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) except FileNotFoundError as e : pass self . __brute_load_cache () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ) . sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db Variables nan Functions dbinit def dbinit ( conf ) View Source def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ]. items () } Classes CsvCache class CsvCache ( cachepath , item , lock_timeout_seconds = 10 ) View Source class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \"{item}.csv\" ) self . lock = FileLock ( f \"{self.csv}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{self.csv}.md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try: self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e: self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try: self . lock . acquire () try: if force: raise FileNotFoundError () with open ( self . md5file ) as o: md5 = o . read () if not md5 == self . md5: self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e: ## refershing hash try: self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) except FileNotFoundError as e: pass self . __brute_load_cache () finally: self . lock . release () except Timeout: pass def save ( self ): try: self . lock . acquire () try: self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def drop ( self ): try: self . lock . acquire () try: os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def update ( self , value:Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try: self . lock . acquire () try: self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e: error = e finally: self . lock . release () except Timeout as e: error = e if error is not None: raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db Methods drop def drop ( self ) View Source def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e get def get ( self , force_reload = False ) View Source def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e update def update ( self , value : pandas . core . series . Series ) Needs to lock for writing json-database View Source def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error DB class DB ( connection ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DB ( ABC ) : @abstractmethod def __init__ ( self , connection ) : pass @abstractmethod def __getitem__ ( self , key ) : pass @abstractmethod def __setitem__ ( self , key , value ) : pass @abstractmethod def pop ( self , key ) : pass Ancestors (in MRO) abc.ABC Descendants hielen2.datalink.JsonDB Methods pop def pop ( self , key ) View Source @abstractmethod def pop ( self , key ) : pass JsonDB class JsonDB ( connection , schema , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class JsonDB ( DB ) : def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ) : self . jsonfile = connection self . lock = FileLock ( f \"{connection}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{connection}.md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ) : try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ( {} , columns = self . schema [ 'columns' ] ) self . db = self . db . set_index ( self . schema [ 'primary_key' ] ) def __chk_and_reload_jsondb ( self , force = False ) : \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ) : try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ) : \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key , raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key {key} to remove does not exist\" ) else : # Request to insert key , raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )) : key =[ key ] if key . __len__ () < primarykey . __len__ () : raise ValueError ( f \"key {key!r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ] , key )) value . update ( keydict ) df = DataFrame ( [ value.values() ] ) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ] ) try : self . db = self . db . append ( df , verify_integrity = True ). sort_index () except ValueError : raise ValueError ( f \"key {key} to insert exists\" ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ) : out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ) : out = out . to_frame (). T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index (). to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ) : self . __chk_and_reload_jsondb () if isinstance ( key , list ) : try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ) : return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ) : self . __write_jsondb ( key , value ) Ancestors (in MRO) hielen2.datalink.DB abc.ABC Descendants hielen2.datalink.fsHielenCache Methods pop def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None ) save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e fsHielenCache class fsHielenCache ( connection , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class fsHielenCache ( JsonDB ) : def __init__ ( self , connection , lock_timeout_seconds = 10 ) : self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" : [ \"uid\",\"info\" ] , \"primary_key\" : [ \"uid\" ] } connfile = str ( Path ( connection ) / \"index.json\" ) super (). __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ) : info = super (). __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ). get ( force_reload = True ) def __setitem__ ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key {key} doesn't seems to match requirement format\" ) #testing existence ( stops if exits ) if value is not None : super (). __setitem__ ( key , {} ) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics else : super (). __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ). drop () except FileNotFoundError as e : pass def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics Ancestors (in MRO) hielen2.datalink.JsonDB hielen2.datalink.DB abc.ABC Methods pop def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None ) save def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e update def update ( self , key , value ) View Source def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics seriescode class seriescode ( * args , ** kwargs ) View Source class seriescode (): def __init__ ( self ,* args ,** kwargs ): self . h =[ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f' { self . h }'. encode () ). hexdigest () def __repr__ ( self ): return self . h","title":"Datalink"},{"location":"reference/hielen2/datalink/#module-hielen2datalink","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series , read_json , NaT , read_csv from abc import ABC , abstractmethod from hielen2.utils import loadjsonfile , savejsonfile , newinstanceof , hashfile from filelock import Timeout , FileLock from numpy import nan from pathlib import Path from hashlib import md5 from shutil import rmtree import os def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ] . items () } class DB ( ABC ): @abstractmethod def __init__ ( self , connection ): pass @abstractmethod def __getitem__ ( self , key ): pass @abstractmethod def __setitem__ ( self , key , value ): pass @abstractmethod def pop ( self , key ): pass class JsonDB ( DB ): def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ): self . jsonfile = connection self . lock = FileLock ( f \" { connection } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { connection } .md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ): try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ({}, columns = self . schema [ 'columns' ]) self . db = self . db . set_index ( self . schema [ 'primary_key' ]) def __chk_and_reload_jsondb ( self , force = False ): \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ): \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key, raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key { key } to remove does not exist\" ) else : # Request to insert key, raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )): key = [ key ] if key . __len__ () < primarykey . __len__ (): raise ValueError ( f \"key { key !r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ], key )) value . update ( keydict ) df = DataFrame ([ value . values ()]) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ]) try : self . db = self . db . append ( df , verify_integrity = True ) . sort_index () except ValueError : raise ValueError ( f \"key { key } to insert exists\" ) self . db . replace ({ nan : None , NaT : None }, inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ): out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ): out = out . to_frame () . T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index () . to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ): self . __chk_and_reload_jsondb () if isinstance ( key , list ): try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ): return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ): self . __write_jsondb ( key , value ) ''' class JsonCache(DB): def __init__(self, connection): self.cache = ( read_json(connection, convert_dates=False) .set_index([\"uid\", \"timestamp\"])[\"value\"] .sort_index() ) self.filename = connection def __getitem__(self, key): return self.cache[key] def __setitem__(self, key, value): pass def pop(self, key): pass def save(self): self.cache.reset_index().to_json(self.filename, orient=\"records\") ''' class seriescode (): def __init__ ( self , * args , ** kwargs ): self . h = [ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f ' { self . h } ' . encode () ) . hexdigest () def __repr__ ( self ): return self . h class fsHielenCache ( JsonDB ): def __init__ ( self , connection , lock_timeout_seconds = 10 ): self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" :[ \"uid\" , \"info\" ], \"primary_key\" :[ \"uid\" ]} connfile = str ( Path ( connection ) / \"index.json\" ) super () . __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ): info = super () . __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ) . get ( force_reload = True ) def __setitem__ ( self , key , value ): if value is not None and not isinstance ( value , Series ): raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key { key } doesn't seems to match requirement format\" ) #testing existence (stops if exits) if value is not None : super () . __setitem__ ( key ,{}) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics else : super () . __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ) . drop () except FileNotFoundError as e : pass def update ( self , key , value ): if value is not None and not isinstance ( value , Series ): #if value is not None and not isinstance(value,DataFrame): raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super () . __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ] = statistics class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \" { item } .csv\" ) self . lock = FileLock ( f \" { self . csv } .lock\" , timeout = lock_timeout_seconds ) self . md5file = f \" { self . csv } .md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try : self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e : self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e : ## refershing hash try : self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) except FileNotFoundError as e : pass self . __brute_load_cache () finally : self . lock . release () except Timeout : pass def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ) . sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"Module hielen2.datalink"},{"location":"reference/hielen2/datalink/#variables","text":"nan","title":"Variables"},{"location":"reference/hielen2/datalink/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/datalink/#dbinit","text":"def dbinit ( conf ) View Source def dbinit ( conf ): return { k : newinstanceof ( w . pop ( \"klass\" ), ** w ) for k , w in conf [ \"db\" ]. items () }","title":"dbinit"},{"location":"reference/hielen2/datalink/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/datalink/#csvcache","text":"class CsvCache ( cachepath , item , lock_timeout_seconds = 10 ) View Source class CsvCache (): def __init__ ( self , cachepath , item , lock_timeout_seconds = 10 ): self . cachepath = Path ( cachepath ) / item [ 0 : 8 ] / item [ 8 : 16 ] / item [ 16 : 24 ] / item [ 24 : 32 ] self . db = None self . csv = str ( self . cachepath / f \"{item}.csv\" ) self . lock = FileLock ( f \"{self.csv}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{self.csv}.md5\" self . md5 = None #self.__chk_and_reload_cache(force=True) def __repr__ ( self ): return self . db . __repr__ () def __brute_load_cache ( self ): try: self . db = read_csv ( self . csv , header = None , sep = \";\" , index_col = 0 , parse_dates = True )[ 1 ] except Exception as e: self . db = Series () self . db . name = \"s\" def __chk_and_reload_cache ( self , force = False ): \"\"\" Needs to check for cache file changes in a thread safe way!! \"\"\" md5 = None error = None try: self . lock . acquire () try: if force: raise FileNotFoundError () with open ( self . md5file ) as o: md5 = o . read () if not md5 == self . md5: self . md5 = md5 self . __brute_load_cache () except FileNotFoundError as e: ## refershing hash try: self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) except FileNotFoundError as e: pass self . __brute_load_cache () finally: self . lock . release () except Timeout: pass def save ( self ): try: self . lock . acquire () try: self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o: o . write ( self . md5 ) finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def drop ( self ): try: self . lock . acquire () try: os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally: self . lock . release () except Timeout as e: # Just to remind Timout error here raise e def update ( self , value:Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try: self . lock . acquire () try: self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e: error = e finally: self . lock . release () except Timeout as e: error = e if error is not None: raise error def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"CsvCache"},{"location":"reference/hielen2/datalink/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/datalink/#drop","text":"def drop ( self ) View Source def drop ( self ): try : self . lock . acquire () try : os . unlink ( self . csv ) os . unlink ( self . md5file ) self . db = None finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"drop"},{"location":"reference/hielen2/datalink/#get","text":"def get ( self , force_reload = False ) View Source def get ( self , force_reload = False ): self . __chk_and_reload_cache ( force = force_reload ) return self . db","title":"get"},{"location":"reference/hielen2/datalink/#save","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_csv ( self . csv , header = None , sep = \";\" ) self . md5 = hashfile ( self . csv ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen2/datalink/#update","text":"def update ( self , value : pandas . core . series . Series ) Needs to lock for writing json-database View Source def update ( self , value : Series ): \"\"\" Needs to lock for writing json-database \"\"\" error = None try : self . lock . acquire () try : self . __chk_and_reload_cache () self . db . drop ( value . index , errors = 'ignore' , inplace = True ) value . name = 's' self . db = self . db . append ( value ). sort_index () self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error","title":"update"},{"location":"reference/hielen2/datalink/#db","text":"class DB ( connection ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DB ( ABC ) : @abstractmethod def __init__ ( self , connection ) : pass @abstractmethod def __getitem__ ( self , key ) : pass @abstractmethod def __setitem__ ( self , key , value ) : pass @abstractmethod def pop ( self , key ) : pass","title":"DB"},{"location":"reference/hielen2/datalink/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/datalink/#descendants","text":"hielen2.datalink.JsonDB","title":"Descendants"},{"location":"reference/hielen2/datalink/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/datalink/#pop","text":"def pop ( self , key ) View Source @abstractmethod def pop ( self , key ) : pass","title":"pop"},{"location":"reference/hielen2/datalink/#jsondb","text":"class JsonDB ( connection , schema , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class JsonDB ( DB ) : def __init__ ( self , connection , schema , lock_timeout_seconds = 10 ) : self . jsonfile = connection self . lock = FileLock ( f \"{connection}.lock\" , timeout = lock_timeout_seconds ) self . md5file = f \"{connection}.md5\" self . md5 = None self . schema = schema self . __chk_and_reload_jsondb ( force = True ) def __brute_load_jsondb ( self ) : try : self . db = read_json ( self . jsonfile , orient = 'table' , convert_dates = False ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) except Exception as e : self . db = DataFrame () if self . db . empty : self . db = DataFrame ( {} , columns = self . schema [ 'columns' ] ) self . db = self . db . set_index ( self . schema [ 'primary_key' ] ) def __chk_and_reload_jsondb ( self , force = False ) : \"\"\" Needs to check for json-database file changes in a thread safe way!! \"\"\" md5 = None error = None try : self . lock . acquire () try : if force : raise FileNotFoundError () with open ( self . md5file ) as o : md5 = o . read () if not md5 == self . md5 : self . md5 = md5 self . __brute_load_jsondb () except FileNotFoundError as e : ## refershing hash self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) self . __brute_load_jsondb () finally : self . lock . release () except Timeout : pass def save ( self ) : try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e def __write_jsondb ( self , key , value ) : \"\"\" Needs to lock for writing json-database \"\"\" item = None error = None try : self . lock . acquire () try : self . __chk_and_reload_jsondb () if value is None : # Request to remove key , raises KeyError item = self . __getitem__ ( key ) try : self . db = self . db . drop ( key , axis = 0 ) except KeyError : raise KeyError ( f \"key {key} to remove does not exist\" ) else : # Request to insert key , raises ValueError primarykey = self . schema [ 'primary_key' ] if not isinstance ( key ,( list , set , tuple )) : key =[ key ] if key . __len__ () < primarykey . __len__ () : raise ValueError ( f \"key {key!r} is not fully determinated\" ) keydict = dict ( zip ( self . schema [ 'primary_key' ] , key )) value . update ( keydict ) df = DataFrame ( [ value.values() ] ) df . columns = value . keys () df = df . set_index ( self . schema [ 'primary_key' ] ) try : self . db = self . db . append ( df , verify_integrity = True ). sort_index () except ValueError : raise ValueError ( f \"key {key} to insert exists\" ) self . db . replace ( { nan : None , NaT : None } , inplace = True ) item = self . __brute_getitem ( key ) self . save () except Exception as e : error = e finally : self . lock . release () except Timeout as e : error = e if error is not None : raise error return item def __brute_getitem ( self , key = None ) : out = None if key is None : out = self . db else : out = self . db . loc [ key ] if isinstance ( out , Series ) : out = out . to_frame (). T out . index . names = self . schema [ 'primary_key' ] out = out . reset_index (). to_dict ( orient = 'records' ) if out . __len__ () == 1 : out = out [ 0 ] return out def __getitem__ ( self , key = None ) : self . __chk_and_reload_jsondb () if isinstance ( key , list ) : try : key = list ( filter ( None , key )) except TypeError : pass return self . __brute_getitem ( key ) def pop ( self , key ) : return self . __write_jsondb ( key , None ) def __setitem__ ( self , key = None , value = None ) : self . __write_jsondb ( key , value )","title":"JsonDB"},{"location":"reference/hielen2/datalink/#ancestors-in-mro_1","text":"hielen2.datalink.DB abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/datalink/#descendants_1","text":"hielen2.datalink.fsHielenCache","title":"Descendants"},{"location":"reference/hielen2/datalink/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen2/datalink/#pop_1","text":"def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None )","title":"pop"},{"location":"reference/hielen2/datalink/#save_1","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen2/datalink/#fshielencache","text":"class fsHielenCache ( connection , lock_timeout_seconds = 10 ) Helper class that provides a standard way to create an ABC using inheritance. View Source class fsHielenCache ( JsonDB ) : def __init__ ( self , connection , lock_timeout_seconds = 10 ) : self . cachepath = connection self . lts = lock_timeout_seconds schema = { \"columns\" : [ \"uid\",\"info\" ] , \"primary_key\" : [ \"uid\" ] } connfile = str ( Path ( connection ) / \"index.json\" ) super (). __init__ ( connfile , schema , self . lts ) def __getitem__ ( self , key ) : info = super (). __getitem__ ( key ) return CsvCache ( self . cachepath , key , self . lts ). get ( force_reload = True ) def __setitem__ ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : raise ValueError ( \"pandas.Series required\" ) try : assert isinstance ( key , str ) assert key . __len__ () == 32 except AssertionError as e : raise ValueError ( f \"key {key} doesn't seems to match requirement format\" ) #testing existence ( stops if exits ) if value is not None : super (). __setitem__ ( key , {} ) item = CsvCache ( self . cachepath , key , self . lts ) os . makedirs ( item . cachepath , exist_ok = True ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics else : super (). __setitem__ ( key , None ) try : CsvCache ( self . cachepath , key , self . lts ). drop () except FileNotFoundError as e : pass def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics","title":"fsHielenCache"},{"location":"reference/hielen2/datalink/#ancestors-in-mro_2","text":"hielen2.datalink.JsonDB hielen2.datalink.DB abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/datalink/#methods_3","text":"","title":"Methods"},{"location":"reference/hielen2/datalink/#pop_2","text":"def pop ( self , key ) View Source def pop ( self , key ): return self . __write_jsondb ( key , None )","title":"pop"},{"location":"reference/hielen2/datalink/#save_2","text":"def save ( self ) View Source def save ( self ): try : self . lock . acquire () try : self . db . to_json ( self . jsonfile , orient = 'table' ) self . md5 = hashfile ( self . jsonfile ) with open ( self . md5file , \"w\" ) as o : o . write ( self . md5 ) finally : self . lock . release () except Timeout as e : # Just to remind Timout error here raise e","title":"save"},{"location":"reference/hielen2/datalink/#update_1","text":"def update ( self , key , value ) View Source def update ( self , key , value ) : if value is not None and not isinstance ( value , Series ) : #if value is not None and not isinstance ( value , DataFrame ) : raise ValueError ( \"pandas.Series required\" ) if value is not None : info = super (). __getitem__ ( key ) item = CsvCache ( self . cachepath , key , self . lts ) item . update ( value ) #TODO MAKE STATITICS statistics = {} self . db . loc [ key ]= statistics","title":"update"},{"location":"reference/hielen2/datalink/#seriescode","text":"class seriescode ( * args , ** kwargs ) View Source class seriescode (): def __init__ ( self ,* args ,** kwargs ): self . h =[ * args ] self . h . extend ( list ( kwargs . values ())) self . h = '' . join ([ str ( a ) for a in self . h ]) self . h = md5 ( f' { self . h }'. encode () ). hexdigest () def __repr__ ( self ): return self . h","title":"seriescode"},{"location":"reference/hielen2/mapmanager/","text":"Module hielen2.mapmanager View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 #!/usr/bin/env python # coding=utf-8 import mappyfile import re from hielen2 import conf from abc import ABC , abstractmethod from pathlib import Path from hielen2.source import SourceStorage class Mapmanager ( ABC ): def __init__ ( self , feature , mapname , * args , ** kwargs ): subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ], str ( subpath )) @property def mapfile ( self ): return self . mapcache / \"mapfile.map\" @property def mapurl ( self ): return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams (): pass @abstractmethod def geturl (): pass class Multiraster ( Mapmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 3 , scale = [ '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ): inmapf = conf [ 'maptemplates' ][ self . maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ): scale = [ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ] = [ f 'BANDS= { tbands } ' ] for i in range ( 0 , bands ): layer [ 'processing' ] . append ( f \"SCALE_ { i + 1 } = { scale [ i ] } \" ) layer [ \"projection\" ] = f \"init= { str ( crs ) . lower () } \" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ) . upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ): url = [ str ( self . mapurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile= {} + {} + {} \" , ] return \"\" . join ( url ) Variables conf Classes Mapmanager class Mapmanager ( feature , mapname , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Mapmanager ( ABC ) : def __init__ ( self , feature , mapname , * args , ** kwargs ) : subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ] , str ( subpath )) @property def mapfile ( self ) : return self . mapcache / \"mapfile.map\" @property def mapurl ( self ) : return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams () : pass @abstractmethod def geturl () : pass Ancestors (in MRO) abc.ABC Descendants hielen2.mapmanager.Multiraster Instance variables mapfile mapurl Methods geturl def geturl ( ) View Source @abstractmethod def geturl () : pass setMFparams def setMFparams ( ) View Source @abstractmethod def setMFparams () : pass Multiraster class Multiraster ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Multiraster ( Mapmanager ) : def __init__ ( self , * args , ** kwargs ) : super (). __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 3 , scale =[ '0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ) : url =[ str(self.mapurl), \"?SERVICE=WMS&VERSION=1.1.1\", \"&imgfile=\"+ str(imgname), \"&layers=imglyr\", \"&transparent=true\", \"&format=image/png\", \"&mode=tile\", \"&tilemode=gmap\", \"&tile={}+{}+{}\", ] return \"\" . join ( url ) Ancestors (in MRO) hielen2.mapmanager.Mapmanager abc.ABC Instance variables mapfile mapurl Methods geturl def geturl ( self , imgname ) View Source def geturl ( self , imgname ): url = [ str ( self . mapurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile={}+{}+{}\" , ] return \"\" . join ( url ) setMFparams def setMFparams ( self , bands = 3 , scale = [ '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = 'http://pippo&' ) View Source def setMFparams ( self , bands = 3 , scale =[ '0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 )","title":"Mapmanager"},{"location":"reference/hielen2/mapmanager/#module-hielen2mapmanager","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 #!/usr/bin/env python # coding=utf-8 import mappyfile import re from hielen2 import conf from abc import ABC , abstractmethod from pathlib import Path from hielen2.source import SourceStorage class Mapmanager ( ABC ): def __init__ ( self , feature , mapname , * args , ** kwargs ): subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ], str ( subpath )) @property def mapfile ( self ): return self . mapcache / \"mapfile.map\" @property def mapurl ( self ): return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams (): pass @abstractmethod def geturl (): pass class Multiraster ( Mapmanager ): def __init__ ( self , * args , ** kwargs ): super () . __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 3 , scale = [ '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ): inmapf = conf [ 'maptemplates' ][ self . maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ): scale = [ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ] = [ f 'BANDS= { tbands } ' ] for i in range ( 0 , bands ): layer [ 'processing' ] . append ( f \"SCALE_ { i + 1 } = { scale [ i ] } \" ) layer [ \"projection\" ] = f \"init= { str ( crs ) . lower () } \" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ) . upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ): url = [ str ( self . mapurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile= {} + {} + {} \" , ] return \"\" . join ( url )","title":"Module hielen2.mapmanager"},{"location":"reference/hielen2/mapmanager/#variables","text":"conf","title":"Variables"},{"location":"reference/hielen2/mapmanager/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/mapmanager/#mapmanager","text":"class Mapmanager ( feature , mapname , * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Mapmanager ( ABC ) : def __init__ ( self , feature , mapname , * args , ** kwargs ) : subpath = Path ( feature ) / mapname self . mapbaseurl = Path ( conf [ 'mapurl' ] ) / subpath self . mapcache = SourceStorage ( conf [ 'syscache' ][ 'mapcache' ] , str ( subpath )) @property def mapfile ( self ) : return self . mapcache / \"mapfile.map\" @property def mapurl ( self ) : return self . mapbaseurl / \"mapfile.map\" @abstractmethod def setMFparams () : pass @abstractmethod def geturl () : pass","title":"Mapmanager"},{"location":"reference/hielen2/mapmanager/#ancestors-in-mro","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/mapmanager/#descendants","text":"hielen2.mapmanager.Multiraster","title":"Descendants"},{"location":"reference/hielen2/mapmanager/#instance-variables","text":"mapfile mapurl","title":"Instance variables"},{"location":"reference/hielen2/mapmanager/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/mapmanager/#geturl","text":"def geturl ( ) View Source @abstractmethod def geturl () : pass","title":"geturl"},{"location":"reference/hielen2/mapmanager/#setmfparams","text":"def setMFparams ( ) View Source @abstractmethod def setMFparams () : pass","title":"setMFparams"},{"location":"reference/hielen2/mapmanager/#multiraster","text":"class Multiraster ( * args , ** kwargs ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Multiraster ( Mapmanager ) : def __init__ ( self , * args , ** kwargs ) : super (). __init__ ( * args , ** kwargs ) self . maptype = 'multiraster' def setMFparams ( self , bands = 3 , scale =[ '0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 ) def geturl ( self , imgname ) : url =[ str(self.mapurl), \"?SERVICE=WMS&VERSION=1.1.1\", \"&imgfile=\"+ str(imgname), \"&layers=imglyr\", \"&transparent=true\", \"&format=image/png\", \"&mode=tile\", \"&tilemode=gmap\", \"&tile={}+{}+{}\", ] return \"\" . join ( url )","title":"Multiraster"},{"location":"reference/hielen2/mapmanager/#ancestors-in-mro_1","text":"hielen2.mapmanager.Mapmanager abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/mapmanager/#instance-variables_1","text":"mapfile mapurl","title":"Instance variables"},{"location":"reference/hielen2/mapmanager/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/mapmanager/#geturl_1","text":"def geturl ( self , imgname ) View Source def geturl ( self , imgname ): url = [ str ( self . mapurl ), \"?SERVICE=WMS&VERSION=1.1.1\" , \"&imgfile=\" + str ( imgname ), \"&layers=imglyr\" , \"&transparent=true\" , \"&format=image/png\" , \"&mode=tile\" , \"&tilemode=gmap\" , \"&tile={}+{}+{}\" , ] return \"\" . join ( url )","title":"geturl"},{"location":"reference/hielen2/mapmanager/#setmfparams_1","text":"def setMFparams ( self , bands = 3 , scale = [ '0,255' , '0,255' , '0,255' ], crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = 'http://pippo&' ) View Source def setMFparams ( self , bands = 3 , scale =[ '0,255','0,255','0,255' ] , crs = 'EPSG:3857' , lyrext = '-20026376.39 -20048966.10 20026376.39 20048966.10' , datadir = '' , um = 'METERS' , ows_onlineresources = \"http://pippo&\" ) : inmapf = conf [ 'maptemplates' ][ self.maptype ] self . mapcache . mkdir () mapfile = mappyfile . open ( inmapf ) mapfile [ \"shapepath\" ] = datadir mapfile [ \"web\" ][ \"metadata\" ][ \"ows_onlineresource\" ] = ows_onlineresources if ( bands == 1 ) : scale =[ '0,65536' ] layer = mapfile [ \"layers\" ][ 0 ] tbands = ',' . join ( map ( str ,( range ( 1 , bands + 1 )))) layer [ 'processing' ]=[ f'BANDS={tbands}' ] for i in range ( 0 , bands ) : layer [ 'processing' ] . append ( f \"SCALE_{i+1}={scale[i]}\" ) layer [ \"projection\" ] = f \"init={str(crs).lower()}\" layer [ \"units\" ] = re . sub ( 'METRES?' , 'METERS' , um . upper ()) layer [ \"metadata\" ][ \"ows_srs\" ] = str ( crs ). upper () layer [ \"metadata\" ][ \"ows_extent\" ] = lyrext mappyfile . save ( mapfile , self . mapfile , 2 )","title":"setMFparams"},{"location":"reference/hielen2/query/","text":"Module hielen2.query View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique from importlib import import_module from hielen2 import db from hielen2.utils import isot2ut , ut2isot from hielen2.source import sourceFactory def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class Series : def __init__ ( self , uid , orient = \"data\" ): series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ): return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ): try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(isot2ut(timefrom2),isot2ut(timefrom) or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self . uid ] = out out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ): self . orient = orient self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source). { self . orient } (**operands)\" self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items (): \"\"\" trying to extract a series \"\"\" try : self . opernads [ key ] = Series ( value , self . orient ) next except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]] next except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ): operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series )} ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ({ k : w . result () for k , w in runners . items ()}) #operands.update( { k:w.data(**kwargs) for k,w in self.operands.items() if isinstance(w,Series) } ) #print('OPERANDI',operands) #print('OPERATORE', self.operator) return eval ( self . operator ) Variables db nan Classes Generator class Generator ( source = None , modules = None , operator = None , operands = None , orient = 'data' ) View Source class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ) : self . orient = orient self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source).{self.orient}(**operands)\" self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items () : \"\"\" trying to extract a series \"\"\" try : self . opernads [ key ]= Series ( value , self . orient ) next except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] next except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ) : operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series ) } ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ( { k : w . result () for k , w in runners . items () } ) #operands . update ( { k : w . data ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } ) #print ( 'OPERANDI' , operands ) #print ( 'OPERATORE' , self . operator ) return eval ( self . operator ) Series class Series ( uid , orient = 'data' ) View Source class Series : def __init__ ( self , uid , orient = \"data\" ) : series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out out . index . name = \"timestamp\" return out Methods data def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out map def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out out . index . name = \"timestamp\" return out thdata def thdata ( self , ** kwargs ) View Source @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs )","title":"Query"},{"location":"reference/hielen2/query/#module-hielen2query","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame , Series from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique from importlib import import_module from hielen2 import db from hielen2.utils import isot2ut , ut2isot from hielen2.source import sourceFactory def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class Series : def __init__ ( self , uid , orient = \"data\" ): series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ): return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ): try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(isot2ut(timefrom2),isot2ut(timefrom) or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ): try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self . uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out . columns [ 0 ]] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self . uid ] = out out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ): self . orient = orient self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source). { self . orient } (**operands)\" self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items (): \"\"\" trying to extract a series \"\"\" try : self . opernads [ key ] = Series ( value , self . orient ) next except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]] next except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ): operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series )} ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ({ k : w . result () for k , w in runners . items ()}) #operands.update( { k:w.data(**kwargs) for k,w in self.operands.items() if isinstance(w,Series) } ) #print('OPERANDI',operands) #print('OPERATORE', self.operator) return eval ( self . operator )","title":"Module hielen2.query"},{"location":"reference/hielen2/query/#variables","text":"db nan","title":"Variables"},{"location":"reference/hielen2/query/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/query/#generator","text":"class Generator ( source = None , modules = None , operator = None , operands = None , orient = 'data' ) View Source class Generator : def __init__ ( self , source = None , modules = None , operator = None , operands = None , orient = \"data\" ) : self . orient = orient self . source = operands . pop ( \"source\" ) self . operator = operator or f \"sourceFactory(self.source).{self.orient}(**operands)\" self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} try : for key , value in operands . items () : \"\"\" trying to extract a series \"\"\" try : self . opernads [ key ]= Series ( value , self . orient ) next except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 self . operands [ key ] = db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] next except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" self . operands [ key ] = value except AttributeError as e : pass def _generate ( self , ** kwargs ) : operands = kwargs operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series ) } ) runners = { k : w . thdata ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ( { k : w . result () for k , w in runners . items () } ) #operands . update ( { k : w . data ( ** kwargs ) for k , w in self . operands . items () if isinstance ( w , Series ) } ) #print ( 'OPERANDI' , operands ) #print ( 'OPERATORE' , self . operator ) return eval ( self . operator )","title":"Generator"},{"location":"reference/hielen2/query/#series","text":"class Series ( uid , orient = 'data' ) View Source class Series : def __init__ ( self , uid , orient = \"data\" ) : series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo , orient = orient ) @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs ) def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out out . index . name = \"timestamp\" return out","title":"Series"},{"location":"reference/hielen2/query/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/query/#data","text":"def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , refresh = None , geometry = None , ** kwargs ) : try : timefrom = times . start timeto = times . stop except AttributeError : timefrom = None timeto = None if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out","title":"data"},{"location":"reference/hielen2/query/#map","text":"def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) View Source def map ( self , times = None , timeref = None , geometry = None , refresh = None , ** kwargs ) : try : if refresh is not None and refresh : raise KeyError out = db [ \"datacache\" ][ self.uid ][ times ] except KeyError : out = self . generator . _generate ( ** kwargs ) try : out = out [ out.columns[0 ] ] except AttributeError : pass try : db [ \"datacache\" ] . update ( self . uid , out ) except KeyError as e : db [ \"datacache\" ][ self.uid ]= out out . index . name = \"timestamp\" return out","title":"map"},{"location":"reference/hielen2/query/#thdata","text":"def thdata ( self , ** kwargs ) View Source @_threadpool def thdata ( self , ** kwargs ) : return self . __getattribute__ ( self . generator . orient )( ** kwargs )","title":"thdata"},{"location":"reference/hielen2/source/","text":"Module hielen2.source View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 #!/usr/bin/env python # coding=utf-8 import os , re from glob import glob from pathlib import Path , os from inspect import ismodule from abc import ABC , abstractmethod from importlib import import_module from hielen2 import db , conf from hielen2.utils import getSchemaDict from marshmallow import Schema , fields , ValidationError from numpy import datetime64 , isnat from shutil import rmtree import traceback def loadModule ( proto ): if ismodule ( proto ): return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : traceback . print_exc () return proto def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ) . lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \" { action . capitalize () } Schema\" ) def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]) . Source ( feature = feat ) class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' timestamp = StringTime ( required = True , allow_none = False ) class SourceStorage (): def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ) . replace ( f \" { self . cache }{ os . sep } \" , \"\" ) return self . cache / other def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath ) def _agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception as e : t = None return t class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class HielenSource ( ABC ): def __init__ ( self , feature ): self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ], self . uid ) def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass () . load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ): if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self . uid , action , timestamp ] if not isinstance ( out , list ): out = [ out ] except KeyError : return [] return out def deleteActionValues ( self , action = None , timestamp = None ): out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ): out = [ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean { a . capitalize () } \" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self . uid , a , t ] = None except Exception as e : raise ValueError ( e ) return out def _timeline_add ( self , timestamp ): print ( timestamp ) timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) feat_info = db [ 'features_info' ][ self . uid ] try : timeline = feat_info [ 'timeline' ] except KeyError : timeline = [] timeline . append ( timestamp ) timeline . sort () feat_info [ 'timeline' ] = timeline db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info def _timeline_remove ( self , timestamp ): timestamp = _agoodtime ( value ) if timestamp is not None : try : feature_info = db [ 'features_info' ][ self . uid ] timeline = feature_info [ \"timeline\" ] timeline . pop ( timeline . index ( timestamp )) feature_info [ \"timeline\" ] = timeline db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info except Exception as e : traceback . print_exc () pass class DataSource ( HielenSource ): @abstractmethod def data ( ** kwargs ): pass class MapSource ( DataSource ): def _set_map_info ( self , map_info ): try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : traceback . print_exc () pass @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass class CloudSource ( MapSource ): @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass Variables conf db isnat Functions getActionSchema def getActionSchema ( proto , action ) View Source def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) getActionSchemaClass def getActionSchemaClass ( proto , action ) View Source def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \"{action.capitalize()}Schema\" ) loadModule def loadModule ( proto ) View Source def loadModule ( proto ) : if ismodule ( proto ) : return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : traceback . print_exc () return proto moduleActions def moduleActions ( proto ) View Source def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ). lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] sourceFactory def sourceFactory ( feat ) View Source def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]). Source ( feature = feat ) Classes ActionSchema class ActionSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' timestamp = StringTime ( required = True , allow_none = False ) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Descendants hielen2.ext.source_photomonitoring.phm.ConfigSchema hielen2.ext.source_photomonitoring.phm.FeedSchema hielen2.ext.source_tinsar.ConfigSchema hielen2.ext.source_tinsar.FeedSchema Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts timestamp Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} CloudSource class CloudSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class CloudSource ( MapSource ) : @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass Ancestors (in MRO) hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC Methods cloud def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out map def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass DataSource class DataSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DataSource ( HielenSource ) : @abstractmethod def data ( ** kwargs ) : pass Ancestors (in MRO) hielen2.source.HielenSource abc.ABC Descendants hielen2.source.MapSource Methods data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out HielenSource class HielenSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class HielenSource ( ABC ) : def __init__ ( self , feature ) : self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ] , self . uid ) def execAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) def getActionSchema ( self , action ) : return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out def _timeline_add ( self , timestamp ) : print ( timestamp ) timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) feat_info = db [ 'features_info' ][ self.uid ] try : timeline = feat_info [ 'timeline' ] except KeyError : timeline = [] timeline . append ( timestamp ) timeline . sort () feat_info [ 'timeline' ]= timeline db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info def _timeline_remove ( self , timestamp ) : timestamp = _agoodtime ( value ) if timestamp is not None : try : feature_info = db [ 'features_info' ][ self.uid ] timeline = feature_info [ \"timeline\" ] timeline . pop ( timeline . index ( timestamp )) feature_info [ \"timeline\" ]= timeline db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info except Exception as e : traceback . print_exc () pass Ancestors (in MRO) abc.ABC Descendants hielen2.source.DataSource hielen2.ext.source_tinsar.Source Methods deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out MapSource class MapSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class MapSource ( DataSource ) : def _set_map_info ( self , map_info ) : try : feature_info = db [ 'features_info' ][ self.uid ] feature_info [ 'map' ]= map_info db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feature_info except Exception as e : traceback . print_exc () pass @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass Ancestors (in MRO) hielen2.source.DataSource hielen2.source.HielenSource abc.ABC Descendants hielen2.source.CloudSource hielen2.ext.source_photomonitoring.phm.Source Methods data def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out map def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass SourceStorage class SourceStorage ( syspath , subpath = '' ) View Source class SourceStorage (): def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ). replace ( f \"{self.cache}{os.sep}\" , \"\" ) return self . cache / other def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath ) Methods mkdir def mkdir ( self , path = '' ) View Source def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath rmdir def rmdir ( self , path = '' ) View Source def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath ) StringTime class StringTime ( format : Union [ str , NoneType ] = None , ** kwargs ) A formatted datetime string. Example: '2014-12-22T03:12:58.019077+00:00' :param format: Either \"rfc\" (for RFC822), \"iso\" (for ISO8601), or a date format string. If None , defaults to \"iso\". :param kwargs: The same keyword arguments that :class: Field receives. .. versionchanged:: 3.0.0rc9 Does not modify timezone information on (de)serialization. View Source class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super (). _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) Ancestors (in MRO) marshmallow.fields.DateTime marshmallow.fields.Field marshmallow.base.FieldABC Class variables DEFAULT_FORMAT DESERIALIZATION_FUNCS OBJ_TYPE SCHEMA_OPTS_VAR_NAME SERIALIZATION_FUNCS default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"Source"},{"location":"reference/hielen2/source/#module-hielen2source","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 #!/usr/bin/env python # coding=utf-8 import os , re from glob import glob from pathlib import Path , os from inspect import ismodule from abc import ABC , abstractmethod from importlib import import_module from hielen2 import db , conf from hielen2.utils import getSchemaDict from marshmallow import Schema , fields , ValidationError from numpy import datetime64 , isnat from shutil import rmtree import traceback def loadModule ( proto ): if ismodule ( proto ): return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : traceback . print_exc () return proto def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ) . lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return [] def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \" { action . capitalize () } Schema\" ) def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )()) def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]) . Source ( feature = feat ) class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' timestamp = StringTime ( required = True , allow_none = False ) class SourceStorage (): def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ) . replace ( f \" { self . cache }{ os . sep } \" , \"\" ) return self . cache / other def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath ) def _agoodtime ( t ): try : t = datetime64 ( t ) assert not isnat ( t ) t = str ( t ) except Exception as e : t = None return t class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super () . _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value ) class HielenSource ( ABC ): def __init__ ( self , feature ): self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ], self . uid ) def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass () . load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ): if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self . uid , action , timestamp ] if not isinstance ( out , list ): out = [ out ] except KeyError : return [] return out def deleteActionValues ( self , action = None , timestamp = None ): out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ): out = [ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean { a . capitalize () } \" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self . uid , a , t ] = None except Exception as e : raise ValueError ( e ) return out def _timeline_add ( self , timestamp ): print ( timestamp ) timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) feat_info = db [ 'features_info' ][ self . uid ] try : timeline = feat_info [ 'timeline' ] except KeyError : timeline = [] timeline . append ( timestamp ) timeline . sort () feat_info [ 'timeline' ] = timeline db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info def _timeline_remove ( self , timestamp ): timestamp = _agoodtime ( value ) if timestamp is not None : try : feature_info = db [ 'features_info' ][ self . uid ] timeline = feature_info [ \"timeline\" ] timeline . pop ( timeline . index ( timestamp )) feature_info [ \"timeline\" ] = timeline db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feat_info except Exception as e : traceback . print_exc () pass class DataSource ( HielenSource ): @abstractmethod def data ( ** kwargs ): pass class MapSource ( DataSource ): def _set_map_info ( self , map_info ): try : feature_info = db [ 'features_info' ][ self . uid ] feature_info [ 'map' ] = map_info db [ 'features_info' ][ self . uid ] = None db [ 'features_info' ][ self . uid ] = feature_info except Exception as e : traceback . print_exc () pass @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass class CloudSource ( MapSource ): @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ): pass","title":"Module hielen2.source"},{"location":"reference/hielen2/source/#variables","text":"conf db isnat","title":"Variables"},{"location":"reference/hielen2/source/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/source/#getactionschema","text":"def getActionSchema ( proto , action ) View Source def getActionSchema ( proto , action ): return getSchemaDict ( getActionSchemaClass ( proto , action )())","title":"getActionSchema"},{"location":"reference/hielen2/source/#getactionschemaclass","text":"def getActionSchemaClass ( proto , action ) View Source def getActionSchemaClass ( proto , action ): mod = loadModule ( proto ) return mod . __getattribute__ ( f \"{action.capitalize()}Schema\" )","title":"getActionSchemaClass"},{"location":"reference/hielen2/source/#loadmodule","text":"def loadModule ( proto ) View Source def loadModule ( proto ) : if ismodule ( proto ) : return proto mod = db [ \"features_proto\" ][ proto ][ \"module\" ] try : return import_module ( mod ) except Exception as e : traceback . print_exc () return proto","title":"loadModule"},{"location":"reference/hielen2/source/#moduleactions","text":"def moduleActions ( proto ) View Source def moduleActions ( proto ): mod = loadModule ( proto ) try : return [ k . replace ( 'Schema' , '' ). lower () for k in mod . __dict__ . keys () if 'Schema' in k ] except Exception as e : return []","title":"moduleActions"},{"location":"reference/hielen2/source/#sourcefactory","text":"def sourceFactory ( feat ) View Source def sourceFactory ( feat ): if isinstance ( feat , str ): feat = db [ 'features' ][ feat : feat ] return loadModule ( feat [ 'type' ]). Source ( feature = feat )","title":"sourceFactory"},{"location":"reference/hielen2/source/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/source/#actionschema","text":"class ActionSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ActionSchema ( Schema ): ''' Minimal ActionSchema object. Used to define at least a timestamp ''' timestamp = StringTime ( required = True , allow_none = False )","title":"ActionSchema"},{"location":"reference/hielen2/source/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#descendants","text":"hielen2.ext.source_photomonitoring.phm.ConfigSchema hielen2.ext.source_photomonitoring.phm.FeedSchema hielen2.ext.source_tinsar.ConfigSchema hielen2.ext.source_tinsar.FeedSchema","title":"Descendants"},{"location":"reference/hielen2/source/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts timestamp","title":"Class variables"},{"location":"reference/hielen2/source/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/source/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/source/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/source/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/source/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/source/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/source/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/source/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/source/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/source/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/source/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/source/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/source/#cloudsource","text":"class CloudSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class CloudSource ( MapSource ) : @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"CloudSource"},{"location":"reference/hielen2/source/#ancestors-in-mro_1","text":"hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/source/#cloud","text":"def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def cloud ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"cloud"},{"location":"reference/hielen2/source/#data","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen2/source/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/source/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/source/#getactionschema_1","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/source/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/source/#map","text":"def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"map"},{"location":"reference/hielen2/source/#datasource","text":"class DataSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class DataSource ( HielenSource ) : @abstractmethod def data ( ** kwargs ) : pass","title":"DataSource"},{"location":"reference/hielen2/source/#ancestors-in-mro_2","text":"hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#descendants_1","text":"hielen2.source.MapSource","title":"Descendants"},{"location":"reference/hielen2/source/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen2/source/#data_1","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen2/source/#deleteactionvalues_1","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/source/#execaction_1","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/source/#getactionschema_2","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/source/#getactionvalues_1","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/source/#hielensource","text":"class HielenSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class HielenSource ( ABC ) : def __init__ ( self , feature ) : self . __dict__ . update ( feature ) self . module = import_module ( self . __module__ ) #TODO possibili problemi di sicurezza self . filecache = SourceStorage ( conf [ 'syscache' ][ 'filecache' ] , self . uid ) def execAction ( self , action , ** kwargs ) : aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) def getActionSchema ( self , action ) : return getActionSchema ( self . module , action ) def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out def _timeline_add ( self , timestamp ) : print ( timestamp ) timestamp = _agoodtime ( timestamp ) if timestamp is None : raise ValueError ( timestamp ) feat_info = db [ 'features_info' ][ self.uid ] try : timeline = feat_info [ 'timeline' ] except KeyError : timeline = [] timeline . append ( timestamp ) timeline . sort () feat_info [ 'timeline' ]= timeline db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info def _timeline_remove ( self , timestamp ) : timestamp = _agoodtime ( value ) if timestamp is not None : try : feature_info = db [ 'features_info' ][ self.uid ] timeline = feature_info [ \"timeline\" ] timeline . pop ( timeline . index ( timestamp )) feature_info [ \"timeline\" ]= timeline db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feat_info except Exception as e : traceback . print_exc () pass","title":"HielenSource"},{"location":"reference/hielen2/source/#ancestors-in-mro_3","text":"abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#descendants_2","text":"hielen2.source.DataSource hielen2.ext.source_tinsar.Source","title":"Descendants"},{"location":"reference/hielen2/source/#methods_3","text":"","title":"Methods"},{"location":"reference/hielen2/source/#deleteactionvalues_2","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/source/#execaction_2","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/source/#getactionschema_3","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/source/#getactionvalues_2","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/source/#mapsource","text":"class MapSource ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class MapSource ( DataSource ) : def _set_map_info ( self , map_info ) : try : feature_info = db [ 'features_info' ][ self.uid ] feature_info [ 'map' ]= map_info db [ 'features_info' ][ self.uid ]= None db [ 'features_info' ][ self.uid ]= feature_info except Exception as e : traceback . print_exc () pass @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"MapSource"},{"location":"reference/hielen2/source/#ancestors-in-mro_4","text":"hielen2.source.DataSource hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#descendants_3","text":"hielen2.source.CloudSource hielen2.ext.source_photomonitoring.phm.Source","title":"Descendants"},{"location":"reference/hielen2/source/#methods_4","text":"","title":"Methods"},{"location":"reference/hielen2/source/#data_2","text":"def data ( ** kwargs ) View Source @abstractmethod def data ( ** kwargs ) : pass","title":"data"},{"location":"reference/hielen2/source/#deleteactionvalues_3","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/source/#execaction_3","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/source/#getactionschema_4","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/source/#getactionvalues_3","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/source/#map_1","text":"def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) View Source @abstractmethod def map ( timefrom = None , timeto = None , geom = None , ** kwargs ) : pass","title":"map"},{"location":"reference/hielen2/source/#sourcestorage","text":"class SourceStorage ( syspath , subpath = '' ) View Source class SourceStorage (): def __init__ ( self , syspath , subpath = '' ): self . cache = Path ( syspath ) / subpath def __truediv__ ( self , other ): other = str ( other ). replace ( f \"{self.cache}{os.sep}\" , \"\" ) return self . cache / other def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath )","title":"SourceStorage"},{"location":"reference/hielen2/source/#methods_5","text":"","title":"Methods"},{"location":"reference/hielen2/source/#mkdir","text":"def mkdir ( self , path = '' ) View Source def mkdir ( self , path = '' ): outpath = self / path os . makedirs ( outpath , exist_ok = True ) return outpath","title":"mkdir"},{"location":"reference/hielen2/source/#rmdir","text":"def rmdir ( self , path = '' ) View Source def rmdir ( self , path = '' ): outpath = self / path rmtree ( outpath )","title":"rmdir"},{"location":"reference/hielen2/source/#stringtime","text":"class StringTime ( format : Union [ str , NoneType ] = None , ** kwargs ) A formatted datetime string. Example: '2014-12-22T03:12:58.019077+00:00' :param format: Either \"rfc\" (for RFC822), \"iso\" (for ISO8601), or a date format string. If None , defaults to \"iso\". :param kwargs: The same keyword arguments that :class: Field receives. .. versionchanged:: 3.0.0rc9 Does not modify timezone information on (de)serialization. View Source class StringTime ( fields . DateTime ): def _deserialize ( self , value , attr , data , ** kwargs ): return str ( super (). _deserialize ( value , attr , data , ** kwargs )) def _serialize ( self , value , attr , obj , ** kwargs ): return _agoodtime ( value )","title":"StringTime"},{"location":"reference/hielen2/source/#ancestors-in-mro_5","text":"marshmallow.fields.DateTime marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/source/#class-variables_1","text":"DEFAULT_FORMAT DESERIALIZATION_FUNCS OBJ_TYPE SCHEMA_OPTS_VAR_NAME SERIALIZATION_FUNCS default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen2/source/#instance-variables_1","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen2/source/#methods_6","text":"","title":"Methods"},{"location":"reference/hielen2/source/#deserialize","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen2/source/#fail","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen2/source/#get_value","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen2/source/#make_error","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen2/source/#serialize","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen2/utils/","text":"Module hielen2.utils View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 #!/usr/bin/env python # coding=utf-8 from datetime import datetime from re import split , sub , findall from time import mktime import json from importlib import import_module from falcon import HTTPNotAcceptable from hashlib import md5 from marshmallow import Schema , fields def hug_output_format_conten_type ( handlers = [], error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ): \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ): try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items (): if par . split ( \";\" )[ 0 ] == k . split ( \";\" )[ 0 ]: handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0} \" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type def newinstanceof ( klass , * args , ** kwargs ): klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [: - 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , ** kwargs ) def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , t )))) return int ( mktime ( dt . timetuple ())) def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f ' { h } ' . encode () ) . hexdigest () def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () ### MARSHMALLOW def getSchemaDict ( schema ): out = { \"fields\" :{}, \"required\" :[], \"hint\" : schema . __doc__ } for k , w in schema . dump_fields . items (): out [ 'fields' ][ k ] = w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention \"\"\" pass class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \":\". \":\" presence is managed as: \"start:stop:step\" ie.: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try : if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice ( * value [ 0 : 3 ]) #return value[0:3] except Exception as e : raise ValueError ( e ) class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ): required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field . __class__ ]) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[ { f } ]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \" {{ { kf } , { vf } }} \" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ): flds = [] for n , f in self . schema . fields . items (): types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds.append( f\"**{n}**{required}{allow_none}: {types}\") flds . append ( f \"** { n } **: { types } \" ) fields = \", \" . join ( flds ) fields = f \" {{ { fields } }} \" if self . schema . many : fields = f \"[ { fields } ]\" return f \"JSON Schema { fields } \" def __init__ ( self , schema ): self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items (): try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k ))[ 0 ]) except KeyError : self . TYPE_MAPPING [ w ] = [ findall ( r \"'(.*)'\" , str ( k ))[ 0 ]] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ): if type ( value ) is list : # If Falcon is set to comma-separate entries, this segment joins them again. fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value ) Functions eprint def eprint ( * args , fname = 'error' , ** kwargs ) View Source def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) getSchemaDict def getSchemaDict ( schema ) View Source def getSchemaDict ( schema ) : out = { \"fields\" :{} , \"required\" :[] , \"hint\" : schema . __doc__ } for k , w in schema . dump_fields . items () : out [ 'fields' ][ k ]= w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out hasher def hasher ( * args , ** kwargs ) View Source def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f '{h}' . encode () ). hexdigest () hashfile def hashfile ( filename ) View Source def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () hug_output_format_conten_type def hug_output_format_conten_type ( handlers = [], error = 'The requested format does not match any of those allowed' , ctpar = 'content_type' ) Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised View Source def hug_output_format_conten_type ( handlers = [] , error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ) : \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ) : try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items () : if par . split ( \";\" ) [ 0 ] == k . split ( \";\" ) [ 0 ] : handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ) : handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0}\" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type isot2ut def isot2ut ( t = None ) View Source def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , t )))) return int ( mktime ( dt . timetuple ())) loadjsonfile def loadjsonfile ( filename ) View Source def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) newinstanceof def newinstanceof ( klass , * args , ** kwargs ) View Source def newinstanceof ( klass , * args , **kwargs ) : klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [:- 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , **kwargs ) savejsonfile def savejsonfile ( filename , struct ) View Source def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) ut2isot def ut2isot ( u = None ) View Source def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) Classes JsonValidable class JsonValidable ( schema ) JSON Validator class. It is initailzed with a marshmallow.Schema instance. When call function is invoked, uses marshmallow facilities to validate the json and raise errors. Once initalized, changes doc in order to descibe the json accepted. View Source class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ) : required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field.__class__ ] ) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[{f}]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \"{{{kf},{vf}}}\" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ) : flds = [] for n , f in self . schema . fields . items () : types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds . append ( f \"**{n}**{required}{allow_none}: {types}\" ) flds . append ( f \"**{n}**: {types}\" ) fields = \", \" . join ( flds ) fields = f \"{{{fields}}}\" if self . schema . many : fields = f \"[{fields}]\" return f \"JSON Schema {fields}\" def __init__ ( self , schema ) : self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items () : try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k )) [ 0 ] ) except KeyError : self . TYPE_MAPPING [ w ] = [ findall(r\"'(.*)'\", str(k))[0 ] ] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ) : if type ( value ) is list : # If Falcon is set to comma - separate entries , this segment joins them again . fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value ) LocalFile class LocalFile ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention View Source class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention \"\"\" pass Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs ) Selection class Selection ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Provides python object which pertims selection on narry. It axcept a three filed string separated by \":\". \":\" presence is managed as: \"start:stop:step\" ie.: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start View Source class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \" : \". \" : \" presence is managed as: \" start:stop:step \" ie.: \" start:stop \" - extracts from start to stop \" start: \" - extracts from start to max \" start \" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try: if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice (* value [ 0 : 3 ]) #return value[0:3] except Exception as e: raise ValueError ( e ) Ancestors (in MRO) marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC Class variables default_error_messages name parent Instance variables context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields. Methods deserialize def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output fail def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs ) get_value def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default ) make_error def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg ) serialize def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"Utils"},{"location":"reference/hielen2/utils/#module-hielen2utils","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 #!/usr/bin/env python # coding=utf-8 from datetime import datetime from re import split , sub , findall from time import mktime import json from importlib import import_module from falcon import HTTPNotAcceptable from hashlib import md5 from marshmallow import Schema , fields def hug_output_format_conten_type ( handlers = [], error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ): \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ): try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items (): if par . split ( \";\" )[ 0 ] == k . split ( \";\" )[ 0 ]: handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0} \" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type def newinstanceof ( klass , * args , ** kwargs ): klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [: - 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , ** kwargs ) def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u )) def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , t )))) return int ( mktime ( dt . timetuple ())) def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf ) def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf ) def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs ) def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f ' { h } ' . encode () ) . hexdigest () def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest () ### MARSHMALLOW def getSchemaDict ( schema ): out = { \"fields\" :{}, \"required\" :[], \"hint\" : schema . __doc__ } for k , w in schema . dump_fields . items (): out [ 'fields' ][ k ] = w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention \"\"\" pass class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \":\". \":\" presence is managed as: \"start:stop:step\" ie.: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try : if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice ( * value [ 0 : 3 ]) #return value[0:3] except Exception as e : raise ValueError ( e ) class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ): required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field . __class__ ]) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[ { f } ]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \" {{ { kf } , { vf } }} \" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ): flds = [] for n , f in self . schema . fields . items (): types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds.append( f\"**{n}**{required}{allow_none}: {types}\") flds . append ( f \"** { n } **: { types } \" ) fields = \", \" . join ( flds ) fields = f \" {{ { fields } }} \" if self . schema . many : fields = f \"[ { fields } ]\" return f \"JSON Schema { fields } \" def __init__ ( self , schema ): self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items (): try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k ))[ 0 ]) except KeyError : self . TYPE_MAPPING [ w ] = [ findall ( r \"'(.*)'\" , str ( k ))[ 0 ]] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ): if type ( value ) is list : # If Falcon is set to comma-separate entries, this segment joins them again. fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value )","title":"Module hielen2.utils"},{"location":"reference/hielen2/utils/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/utils/#eprint","text":"def eprint ( * args , fname = 'error' , ** kwargs ) View Source def eprint ( * args , fname = \"error\" , ** kwargs ): with open ( fname , \"a\" ) as f : print ( * args , file = f , ** kwargs )","title":"eprint"},{"location":"reference/hielen2/utils/#getschemadict","text":"def getSchemaDict ( schema ) View Source def getSchemaDict ( schema ) : out = { \"fields\" :{} , \"required\" :[] , \"hint\" : schema . __doc__ } for k , w in schema . dump_fields . items () : out [ 'fields' ][ k ]= w . __class__ . __name__ w . __dict__ [ 'required' ] and out [ \"required\" ] . append ( k ) return out","title":"getSchemaDict"},{"location":"reference/hielen2/utils/#hasher","text":"def hasher ( * args , ** kwargs ) View Source def hasher ( * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return md5 ( f '{h}' . encode () ). hexdigest ()","title":"hasher"},{"location":"reference/hielen2/utils/#hashfile","text":"def hashfile ( filename ) View Source def hashfile ( filename ): BLOCKSIZE = 65536 hasher = md5 () with open ( filename , \"rb\" ) as afile : buf = afile . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = afile . read ( BLOCKSIZE ) return hasher . hexdigest ()","title":"hashfile"},{"location":"reference/hielen2/utils/#hug_output_format_conten_type","text":"def hug_output_format_conten_type ( handlers = [], error = 'The requested format does not match any of those allowed' , ctpar = 'content_type' ) Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised View Source def hug_output_format_conten_type ( handlers = [] , error = \"The requested format does not match any of those allowed\" , ctpar = \"content_type\" , ) : \"\"\"Returns a different handler depending on the input param ctpar If none match and no default is given falcon.HTTPNotAcceptable(error) is raised \"\"\" try : default = handlers [ 0 ] except Exception : default = None handlers = { h . content_type : h for h in handlers } def requested_output_type ( request = None ) : try : par = request . _params [ ctpar ] handler = None for k , h in handlers . items () : if par . split ( \";\" ) [ 0 ] == k . split ( \";\" ) [ 0 ] : handler = h break except Exception : if default is not None : handler = default if handler is None : raise HTTPNotAcceptable ( error ) return handler def output_type ( data , request , response ) : handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) output_type . __doc__ = \"Supports any of the following formats: {0}\" . format ( \", \" . join ( function . __doc__ for function in handlers . values ()) ) output_type . content_type = \", \" . join ( handlers . keys ()) output_type . requested = requested_output_type return output_type","title":"hug_output_format_conten_type"},{"location":"reference/hielen2/utils/#isot2ut","text":"def isot2ut ( t = None ) View Source def isot2ut ( t = None ): t = t or \"1970-01-01T01:00:01.00000Z\" dt = datetime ( * map ( int , split ( \"[^\\d]\" , sub ( \"[^\\d]$\" , \"\" , t )))) return int ( mktime ( dt . timetuple ()))","title":"isot2ut"},{"location":"reference/hielen2/utils/#loadjsonfile","text":"def loadjsonfile ( filename ) View Source def loadjsonfile ( filename ): with open ( filename ) as jf : return json . load ( jf )","title":"loadjsonfile"},{"location":"reference/hielen2/utils/#newinstanceof","text":"def newinstanceof ( klass , * args , ** kwargs ) View Source def newinstanceof ( klass , * args , **kwargs ) : klass_ar = klass . split ( \".\" ) module = \".\" . join ( klass_ar [:- 1 ]) klass = klass_ar [ - 1 ] return getattr ( import_module ( module ), klass )( * args , **kwargs )","title":"newinstanceof"},{"location":"reference/hielen2/utils/#savejsonfile","text":"def savejsonfile ( filename , struct ) View Source def savejsonfile ( filename , struct ): with open ( filename , \"w\" ) as jf : json . dump ( struct , jf )","title":"savejsonfile"},{"location":"reference/hielen2/utils/#ut2isot","text":"def ut2isot ( u = None ) View Source def ut2isot ( u = None ): u = u or 1 return str ( datetime . fromtimestamp ( u ))","title":"ut2isot"},{"location":"reference/hielen2/utils/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/utils/#jsonvalidable","text":"class JsonValidable ( schema ) JSON Validator class. It is initailzed with a marshmallow.Schema instance. When call function is invoked, uses marshmallow facilities to validate the json and raise errors. Once initalized, changes doc in order to descibe the json accepted. View Source class JsonValidable : \"\"\" JSON Validator class. It is initailzed with a marshmallow.Schema instance. When __call__ function is invoked, \\ uses marshmallow facilities to validate the json and raise errors. Once initalized, changes __doc__ in order to descibe the json accepted. \"\"\" def __field_doc__ ( self , field ) : required = field . required and \"!\" or \"\" allow_none = not field . allow_none and \"!\" or \"\" try : types = \"|\" . join ( self . TYPE_MAPPING [ field.__class__ ] ) except KeyError : if field . __class__ is fields . List : f , required , allow_none = self . __field_doc__ ( field . inner ) types = f \"[{f}]\" elif field . __class__ is fields . Dict : kf , required , allow_none = self . __field_doc__ ( field . key_field ) vf , required , allow_none = self . __field_doc__ ( field . value_field ) types = f \"{{{kf},{vf}}}\" else : types = \"\" return ( types , required , allow_none ) def __schema_doc__ ( self ) : flds = [] for n , f in self . schema . fields . items () : types , required , allow_none = self . __field_doc__ ( f ) # TODO formattare required e allow_none # flds . append ( f \"**{n}**{required}{allow_none}: {types}\" ) flds . append ( f \"**{n}**: {types}\" ) fields = \", \" . join ( flds ) fields = f \"{{{fields}}}\" if self . schema . many : fields = f \"[{fields}]\" return f \"JSON Schema {fields}\" def __init__ ( self , schema ) : self . schema = schema self . TYPE_MAPPING = {} for k , w in self . schema . TYPE_MAPPING . items () : try : self . TYPE_MAPPING [ w ] . append ( findall ( r \"'(.*)'\" , str ( k )) [ 0 ] ) except KeyError : self . TYPE_MAPPING [ w ] = [ findall(r\"'(.*)'\", str(k))[0 ] ] self . __doc__ = str ( self . __schema_doc__ ()) def __call__ ( self , value ) : if type ( value ) is list : # If Falcon is set to comma - separate entries , this segment joins them again . fixed_value = \",\" . join ( value ) else : fixed_value = value return self . schema . loads ( fixed_value )","title":"JsonValidable"},{"location":"reference/hielen2/utils/#localfile","text":"class LocalFile ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention View Source class LocalFile ( fields . String ): \"\"\" Local Filepath manager used to identify a file into the system. Mainliy usefull for action Schema declaration in hielen2.HielenSource extention \"\"\" pass","title":"LocalFile"},{"location":"reference/hielen2/utils/#ancestors-in-mro","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/utils/#class-variables","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen2/utils/#instance-variables","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen2/utils/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/utils/#deserialize","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen2/utils/#fail","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen2/utils/#get_value","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen2/utils/#make_error","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen2/utils/#serialize","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen2/utils/#selection","text":"class Selection ( * , default : Any = < marshmallow . missing > , missing : Any = < marshmallow . missing > , data_key : Union [ str , NoneType ] = None , attribute : Union [ str , NoneType ] = None , validate : Union [ Callable [[ Any ], Any ], Iterable [ Callable [[ Any ], Any ]], NoneType ] = None , required : bool = False , allow_none : Union [ bool , NoneType ] = None , load_only : bool = False , dump_only : bool = False , error_messages : Union [ Dict [ str , str ], NoneType ] = None , ** metadata ) Provides python object which pertims selection on narry. It axcept a three filed string separated by \":\". \":\" presence is managed as: \"start:stop:step\" ie.: \"start:stop\" - extracts from start to stop \"start:\" - extracts from start to max \"start\" - extract exactly start View Source class Selection ( fields . String ): \"\"\" Provides python object which pertims selection on narry. It axcept a three filed \\ string separated by \" : \". \" : \" presence is managed as: \" start:stop:step \" ie.: \" start:stop \" - extracts from start to stop \" start: \" - extracts from start to max \" start \" - extract exactly start \"\"\" def _deserialize ( self , value , attr , data , ** kwargs ): try: if value is None or value == \"\" : #return [None,None,None] return slice ( None , None , None ) value = [ v or None for v in value . split ( ';' ) ] if value . __len__ () == 1 : return slice ( value [ 0 ], value [ 0 ]) return slice (* value [ 0 : 3 ]) #return value[0:3] except Exception as e: raise ValueError ( e )","title":"Selection"},{"location":"reference/hielen2/utils/#ancestors-in-mro_1","text":"marshmallow.fields.String marshmallow.fields.Field marshmallow.base.FieldABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/utils/#class-variables_1","text":"default_error_messages name parent","title":"Class variables"},{"location":"reference/hielen2/utils/#instance-variables_1","text":"context The context dictionary for the parent :class: Schema . root Reference to the Schema that this field belongs to even if it is buried in a container field (e.g. List ). Return None for unbound fields.","title":"Instance variables"},{"location":"reference/hielen2/utils/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/utils/#deserialize_1","text":"def deserialize ( self , value : Any , attr : Union [ str , NoneType ] = None , data : Union [ Mapping [ str , Any ], NoneType ] = None , ** kwargs ) Deserialize value . :param value: The value to deserialize. :param attr: The attribute/key in data to deserialize. :param data: The raw input data passed to Schema.load . :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. View Source def deserialize ( self , value : typing . Any , attr : typing . Optional [ str ] = None , data : typing . Optional [ typing . Mapping [ str , typing . Any ]] = None , ** kwargs ): \"\"\"Deserialize ``value``. :param value: The value to deserialize. :param attr: The attribute/key in `data` to deserialize. :param data: The raw input data passed to `Schema.load`. :param kwargs: Field-specific keyword arguments. :raise ValidationError: If an invalid value is passed or if a required value is missing. \"\"\" # Validate required fields, deserialize, then validate # deserialized value self . _validate_missing ( value ) if value is missing_ : _miss = self . missing return _miss () if callable ( _miss ) else _miss if getattr ( self , \"allow_none\" , False ) is True and value is None : return None output = self . _deserialize ( value , attr , data , ** kwargs ) self . _validate ( output ) return output","title":"deserialize"},{"location":"reference/hielen2/utils/#fail_1","text":"def fail ( self , key : str , ** kwargs ) Helper method that raises a ValidationError with an error message from self.error_messages . .. deprecated:: 3.0.0 Use make_error <marshmallow.fields.Field.make_error> instead. View Source def fail ( self , key : str , ** kwargs ): \"\"\"Helper method that raises a `ValidationError` with an error message from ``self.error_messages``. .. deprecated:: 3.0.0 Use `make_error <marshmallow.fields.Field.make_error>` instead. \"\"\" warnings . warn ( '`Field.fail` is deprecated. Use `raise self.make_error(\"{}\", ...)` instead.' . format ( key ), RemovedInMarshmallow4Warning , ) raise self . make_error ( key = key , ** kwargs )","title":"fail"},{"location":"reference/hielen2/utils/#get_value_1","text":"def get_value ( self , obj , attr , accessor = None , default =< marshmallow . missing > ) Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in obj to get the value from. :param callable accessor: A callable used to retrieve the value of attr from the object obj . Defaults to marshmallow.utils.get_value . View Source def get_value ( self , obj , attr , accessor = None , default = missing_ ): \"\"\"Return the value for a given key from an object. :param object obj: The object to get the value from. :param str attr: The attribute/key in `obj` to get the value from. :param callable accessor: A callable used to retrieve the value of `attr` from the object `obj`. Defaults to `marshmallow.utils.get_value`. \"\"\" # NOTE: Use getattr instead of direct attribute access here so that # subclasses aren't required to define `attribute` member attribute = getattr ( self , \"attribute\" , None ) accessor_func = accessor or utils . get_value check_key = attr if attribute is None else attribute return accessor_func ( obj , check_key , default )","title":"get_value"},{"location":"reference/hielen2/utils/#make_error_1","text":"def make_error ( self , key : str , ** kwargs ) -> marshmallow . exceptions . ValidationError Helper method to make a ValidationError with an error message from self.error_messages . View Source def make_error ( self , key : str , ** kwargs ) -> ValidationError : \"\"\"Helper method to make a `ValidationError` with an error message from ``self.error_messages``. \"\"\" try : msg = self . error_messages [ key ] except KeyError as error : class_name = self . __class__ . __name__ message = ( \"ValidationError raised by `{class_name}`, but error key `{key}` does \" \"not exist in the `error_messages` dictionary.\" ). format ( class_name = class_name , key = key ) raise AssertionError ( message ) from error if isinstance ( msg , ( str , bytes )): msg = msg . format ( ** kwargs ) return ValidationError ( msg )","title":"make_error"},{"location":"reference/hielen2/utils/#serialize_1","text":"def serialize ( self , attr : str , obj : Any , accessor : Union [ Callable [[ Any , str , Any ], Any ], NoneType ] = None , ** kwargs ) Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from obj . :param kwargs: Field-specific keyword arguments. View Source def serialize ( self , attr : str , obj : typing . Any , accessor : typing . Optional [ typing . Callable [[ typing . Any , str , typing . Any ], typing . Any ] ] = None , ** kwargs ): \"\"\"Pulls the value for the given key from the object, applies the field's formatting and returns the result. :param attr: The attribute/key to get from the object. :param obj: The object to access the attribute/key from. :param accessor: Function used to access values from ``obj``. :param kwargs: Field-specific keyword arguments. \"\"\" if self . _CHECK_ATTRIBUTE : value = self . get_value ( obj , attr , accessor = accessor ) if value is missing_ and hasattr ( self , \"default\" ): default = self . default value = default () if callable ( default ) else default if value is missing_ : return value else : value = None return self . _serialize ( value , attr , obj , ** kwargs )","title":"serialize"},{"location":"reference/hielen2/api/","text":"Module hielen2.api Sub-modules hielen2.api.actions hielen2.api.actionschemata hielen2.api.features hielen2.api.glob hielen2.api.parameters hielen2.api.prototypes hielen2.api.query","title":"Index"},{"location":"reference/hielen2/api/#module-hielen2api","text":"","title":"Module hielen2.api"},{"location":"reference/hielen2/api/#sub-modules","text":"hielen2.api.actions hielen2.api.actionschemata hielen2.api.features hielen2.api.glob hielen2.api.parameters hielen2.api.prototypes hielen2.api.query","title":"Sub-modules"},{"location":"reference/hielen2/api/actions/","text":"Module hielen2.api.actions View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 #!/usr/bin/env python # coding=utf-8 import hug import tempfile import falcon import os import time import json from hielen2 import db , conf import hielen2.source as sourceman from streaming_form_data import StreamingFormDataParser from streaming_form_data.targets import FileTarget , ValueTarget from himada.api import ResponseFormatter from urllib.parse import unquote from importlib import import_module from pathlib import Path , PosixPath import traceback @hug . get ( \"/ {feature} \" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] ___nota 3___ :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . get ( \"/ {feature} / {action} \" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) @hug . delete ( \"/ {feature} / {action} \" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ): \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . post ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): if isinstance ( w , PosixPath ): v = os . path . exists ( w ) and str ( w ) or None else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema [ \"required\" ] if kwargs [ m ] is None ] if m . __len__ (): out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters { m } not supplied\" out . format ( request = request , response = response ) return # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) return except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) return except Exception as e : traceback . print_exc () try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return Variables conf db Functions feature_action_delete def feature_action_delete ( feature , action , timestamp , request = None , response = None ) Eliminazione di una determinata azione di una specifica feature View Source @hug . delete ( \"/{feature}/{action}\" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ) : \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return feature_action_values def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) Recupero dello stato corrente per una specifica azione di una specifica feature View Source @hug . get ( \"/{feature}/{action}\" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) : \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) features_actions_values def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ) Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione View Source @ hug . get ( \"/{feature}\" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, ... ] ___nota 3___ :(*) I campi \" feature \" e \" action \" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \" timestamp \" e \" value \" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return make_action def make_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . post ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : if isinstance ( w , PosixPath ) : v = os . path . exists ( w ) and str ( w ) or None else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema[\"required\" ] if kwargs [ m ] is None ] if m . __len__ () : out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters {m} not supplied\" out . format ( request = request , response = response ) return # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) return except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) return except Exception as e : traceback . print_exc () try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"Actions"},{"location":"reference/hielen2/api/actions/#module-hielen2apiactions","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 #!/usr/bin/env python # coding=utf-8 import hug import tempfile import falcon import os import time import json from hielen2 import db , conf import hielen2.source as sourceman from streaming_form_data import StreamingFormDataParser from streaming_form_data.targets import FileTarget , ValueTarget from himada.api import ResponseFormatter from urllib.parse import unquote from importlib import import_module from pathlib import Path , PosixPath import traceback @hug . get ( \"/ {feature} \" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] ___nota 3___ :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . get ( \"/ {feature} / {action} \" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response ) @hug . delete ( \"/ {feature} / {action} \" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ): \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return @hug . post ( \"/ {feature} / {action} \" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ): \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { feature } ' does not exists or it is misconfigured: { e } \" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype ' { featobj . type } ' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype ' { featobj . type } ' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items (): if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \" { feature } . { k } . { timenow } .part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items (): if isinstance ( w , PosixPath ): v = os . path . exists ( w ) and str ( w ) or None else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema [ \"required\" ] if kwargs [ m ] is None ] if m . __len__ (): out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters { m } not supplied\" out . format ( request = request , response = response ) return # CHECKS request checks ALL RIGHT. Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action ' { action } ' not implemented.\" out . format ( request = request , response = response ) return except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: { e } .\" out . format ( request = request , response = response ) return except Exception as e : traceback . print_exc () try : db [ \"actions\" ][ feature , action , result [ 'timestamp' ]] = { \"value\" : result } except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"Module hielen2.api.actions"},{"location":"reference/hielen2/api/actions/#variables","text":"conf db","title":"Variables"},{"location":"reference/hielen2/api/actions/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/actions/#feature_action_delete","text":"def feature_action_delete ( feature , action , timestamp , request = None , response = None ) Eliminazione di una determinata azione di una specifica feature View Source @hug . delete ( \"/{feature}/{action}\" ) def feature_action_delete ( feature , action , timestamp , request = None , response = None ) : \"\"\" **Eliminazione di una determinata azione di una specifica feature**\"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . deleteActionValues ( action , timestamp ) except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"feature_action_delete"},{"location":"reference/hielen2/api/actions/#feature_action_values","text":"def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) Recupero dello stato corrente per una specifica azione di una specifica feature View Source @hug . get ( \"/{feature}/{action}\" ) def feature_action_values ( feature , action , timestamp = None , request = None , response = None ) : \"\"\" **Recupero dello stato corrente per una specifica azione di una specifica feature**\"\"\" return features_actions_values ( feature , action , timestamp , request = request , response = response )","title":"feature_action_values"},{"location":"reference/hielen2/api/actions/#features_actions_values","text":"def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ) Recupero dello stato corrente delle azioni effettuate su una feature L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione nota 1 : actions accetta valori multipli separati da virgola nota 2 : A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, { \"feature\"*:..., \"action_name*\":..., \"timestamp\": ..., \"value\":{...} }, ... ] nota 3 :(*) I campi \"feature\" e \"action\" potrebbero non essere restituiti nella struttura nel caso in cui essi risultino non ambigui. \"timestamp\" e \"value\" vengono sempre restituiti Possibili risposte: 404 Not Found : Nel non venga trovata la feature richiesta o essa abbia un problema di configurazione View Source @ hug . get ( \"/{feature}\" ) def features_actions_values ( feature , actions = None , timestamp = None , request = None , response = None ): \"\"\" **Recupero dello stato corrente delle azioni effettuate su una feature** L'intento di questa api \u00e8 quello di fornire i valori richiesti secondo lo schema dell'azione ___nota 1___: `actions` accetta valori multipli separati da virgola ___nota 2___: A seconda dell'action richiesta, alcuni parametri potrebbero essere utilizzati in fase \\ di input ma non registrati. Il che vuol dire che per quei parametri il valore di ritorno sar\u00e0 null viene restituito una struttura di questo tipo: [ { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, { \" feature \"*:..., \" action_name * \":..., \" timestamp \": ..., \" value \":{...} }, ... ] ___nota 3___ :(*) I campi \" feature \" e \" action \" potrebbero non essere restituiti nella struttura \\ nel caso in cui essi risultino non ambigui. \" timestamp \" e \" value \" vengono sempre restituiti Possibili risposte: - _404 Not Found_: Nel non venga trovata la feature richiesta o essa abbia un problema di \\ configurazione \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) out . data = featobj . getActionValues ( actions , timestamp ) if not isinstance ( out . data , list ): out . data = [ out . data ] except Exception as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"features_actions_values"},{"location":"reference/hielen2/api/actions/#make_action","text":"def make_action ( feature , action , request = None , response = None ) Esecuzione delle azioni Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni necessarie attraverso una form dinamica dedicata. Oltre ai due parametri feature e form , timestamp , indicati nella url, accetta un multipart/form-data basato sulla specifica form, selezionata tramite i due parametri espliciti. Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: 200 OK : Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. 404 Not Found : Nel caso la feature non esista o non sia definita per essa l'azione richiesta. 500 Internal Server Error : Nel caso pessimo che il modulo dichiarato non esista. 501 Not Implemented' : Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo meccanismo permette di svluppare i moduli a partire da un template con risposta di default. View Source @hug . post ( \"/{feature}/{action}\" , parse_body = False ) @hug . default_input_format ( content_type = \"multipart/form-data\" ) def make_action ( feature , action , request = None , response = None ) : \"\"\" **Esecuzione delle azioni** Richiede l'esecuzione di una specifica azione su una feature, fornendo tutte le informazioni \\ necessarie attraverso una form dinamica dedicata. - Oltre ai due parametri `feature` e `form`, `timestamp`, indicati nella url, accetta un \\ _multipart/form-data_ basato sulla specifica form, selezionata tramite i due parametri espliciti. - Tutto il content \u00e8 scaricato attarverso i chunk dello stream ('100 continue') per evitare il \\ timeout dei workers in caso di contenuti di grandi dimensioni. Possibili risposte: - _200 OK_: Nel caso in cui l'azione vada a buon fine. L'azione richiesta viene presa in carico ma \\ potrebbe avere un tempo di esecuzione arbitrario. L'azione quindi viene splittata su un altro processo. - _404 Not Found_: Nel caso la feature non esista o non sia definita per essa l'azione richiesta. - _500 Internal Server Error_: Nel caso pessimo che il modulo dichiarato non esista. - _501 Not Implemented'_: Nel caso la tipologia non fornisse ancora l'iplementazione di uno o tutti \\ i moduli di gestione E' stato implementato il meccanismo minimo di gestione che prevede il salvataggio delle info \\ fornite che possono essere fornite tali e quali in uscita (vedi metodo GET dell'api). Questo \\ meccanismo permette di svluppare i moduli a partire da un template con risposta di default. \"\"\" out = ResponseFormatter () # Trying to manage income feature request and its prototype configuration try : featobj = sourceman . sourceFactory ( feature ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{feature}' does not exists or it is misconfigured: {e}\" out . format ( request = request , response = response ) return try : schema = featobj . getActionSchema ( action ) except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Prototype '{featobj.type}' actions not implemented.\" out . format ( request = request , response = response ) return except ModuleNotFoundError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = f \"Prototype '{featobj.type}' module not found.\" out . format ( request = request , response = response ) return parser = StreamingFormDataParser ( headers = request . headers ) values = {} # TODO Differenziazione delle tipologie di input for k , w in schema [ \"fields\" ] . items () : if w == \"LocalFile\" : timenow = time . perf_counter () filepath = Path ( tempfile . gettempdir (), f \"{feature}.{k}.{timenow}.part\" ) target = FileTarget ( filepath ) parser . register ( k , target ) values [ k ] = filepath else : target = ValueTarget () parser . register ( k , target ) values [ k ] = target while True : chunk = request . stream . read ( 8192 ) if not chunk : break parser . data_received ( chunk ) kwargs = {} for k , w in values . items () : if isinstance ( w , PosixPath ) : v = os . path . exists ( w ) and str ( w ) or None else : v = unquote ( w . value . decode ( \"utf8\" )) or None kwargs [ k ] = v m = [ m for m in schema[\"required\" ] if kwargs [ m ] is None ] if m . __len__ () : out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Required parameters {m} not supplied\" out . format ( request = request , response = response ) return # CHECKS request checks ALL RIGHT . Continuing with code loading # Trying to initialize feature action manager module try : result = featobj . execAction ( action , ** kwargs ) except AttributeError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_IMPLEMENTED out . message = f \"Action '{action}' not implemented.\" out . format ( request = request , response = response ) return except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = f \"Action values error: {e}.\" out . format ( request = request , response = response ) return except Exception as e : traceback . print_exc () try : db [ \"actions\" ][ feature,action,result['timestamp' ] ] = { \"value\" : result } except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_INTERNAL_SERVER_ERROR out . message = str ( e ) out . format ( request = request , response = response ) except ValueError as e : traceback . print_exc () out . status = falcon . HTTP_BAD_REQUEST out . message = str ( e ) out . format ( request = request , response = response ) return out . format ( request = request , response = response ) return","title":"make_action"},{"location":"reference/hielen2/api/actionschemata/","text":"Module hielen2.api.actionschemata View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db , source from himada.api import ResponseFormatter @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ): \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions = [ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ): protos = [ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ] = {} for a in [ act for act in source . moduleActions ( uid ) if actions is None or act in actions ]: out . data [ uid ][ a ] = source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) @hug . get ( \"/ {prototype} / {action} \" ) def get_proto_schema ( prototype , action , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response ) Variables db Functions get_proto_schema def get_proto_schema ( prototype , action , request = None , response = None ) Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo View Source @hug . get ( \"/{prototype}/{action}\" ) def get_proto_schema ( prototype , action , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response ) get_proto_schemata def get_proto_schemata ( prototype , actions = None , request = None , response = None ) Alias per il recupero di tutte le informazioni di uno specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) get_protos_schemata def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, View Source @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) : \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \" NomePrototipo1 \": { \" action1 \": { \" args \": { \" arg1 .1 \": \" type_arg1 .1 \", \" arg1 .2 \": \" type_arg1 .2 \", ... }, \" mandatory \": [ args keys sublist ] }, \" action2 \": { \" args \": { \" arg2 .1 \": \" type_arg2 .1 \", \" arg2 .2 \": \" type_arg2 .2 \", ... }, }, ... }, \" NomePrototipo3 \": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions =[ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ) : protos =[ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ]= {} for a in [ act for act in source.moduleActions(uid) if actions is None or act in actions ] : out . data [ uid ][ a ]= source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request )","title":"Actionschemata"},{"location":"reference/hielen2/api/actionschemata/#module-hielen2apiactionschemata","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db , source from himada.api import ResponseFormatter @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ): \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions = [ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ): protos = [ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ] = {} for a in [ act for act in source . moduleActions ( uid ) if actions is None or act in actions ]: out . data [ uid ][ a ] = source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} \" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response ) @hug . get ( \"/ {prototype} / {action} \" ) def get_proto_schema ( prototype , action , request = None , response = None ): \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response )","title":"Module hielen2.api.actionschemata"},{"location":"reference/hielen2/api/actionschemata/#variables","text":"db","title":"Variables"},{"location":"reference/hielen2/api/actionschemata/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/actionschemata/#get_proto_schema","text":"def get_proto_schema ( prototype , action , request = None , response = None ) Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo View Source @hug . get ( \"/{prototype}/{action}\" ) def get_proto_schema ( prototype , action , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni delle form di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , action , request , response )","title":"get_proto_schema"},{"location":"reference/hielen2/api/actionschemata/#get_proto_schemata","text":"def get_proto_schemata ( prototype , actions = None , request = None , response = None ) Alias per il recupero di tutte le informazioni di uno specifico prototipo View Source @hug . get ( \"/{prototype}\" ) def get_proto_schemata ( prototype , actions = None , request = None , response = None ) : \"\"\" **Alias per il recupero di tutte le informazioni di uno specifico prototipo** \"\"\" return get_protos_schemata ( prototype , actions , request , response )","title":"get_proto_schemata"},{"location":"reference/hielen2/api/actionschemata/#get_protos_schemata","text":"def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) Recupero dello schema dei parametri per inizializare le forms delle azioni ritorna una struttura json di questo tipo: { \"NomePrototipo1\": { \"action1\": { \"args\": { \"arg1.1\": \"type_arg1.1\", \"arg1.2\": \"type_arg1.2\", ... }, \"mandatory\": [ args keys sublist ] }, \"action2\": { \"args\": { \"arg2.1\": \"type_arg2.1\", \"arg2.2\": \"type_arg2.2\", ... }, }, ... }, \"NomePrototipo3\": { ... }, ... }, View Source @hug . get ( \"/\" ) def get_protos_schemata ( prototypes = None , actions = None , request = None , response = None ) : \"\"\" **Recupero dello schema dei parametri per inizializare le forms delle azioni** ritorna una struttura json di questo tipo: { \" NomePrototipo1 \": { \" action1 \": { \" args \": { \" arg1 .1 \": \" type_arg1 .1 \", \" arg1 .2 \": \" type_arg1 .2 \", ... }, \" mandatory \": [ args keys sublist ] }, \" action2 \": { \" args \": { \" arg2 .1 \": \" type_arg2 .1 \", \" arg2 .2 \": \" type_arg2 .2 \", ... }, }, ... }, \" NomePrototipo3 \": { ... }, ... }, \"\"\" out = ResponseFormatter () out . data = {} try : if actions is not None and actions is not list : actions =[ actions ] protos = db [ \"features_proto\" ][ prototypes ] if not isinstance ( protos , list ) : protos =[ protos ] for p in protos : uid = p [ 'uid' ] out . data [ uid ]= {} for a in [ act for act in source.moduleActions(uid) if actions is None or act in actions ] : out . data [ uid ][ a ]= source . getActionSchema ( uid , a ) except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) raise e response = out . format ( response = response , request = request )","title":"get_protos_schemata"},{"location":"reference/hielen2/api/features/","text":"Module hielen2.api.features View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from hielen2.utils import JsonValidable , hasher import hielen2.source as sourceman from marshmallow import Schema , fields from himada.api import ResponseFormatter from marshmallow_geojson import GeoJSONSchema import traceback class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) @hug . post ( \"/\" ) def create_feature ( uid , prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0 , 0 ]}, request = None , response = None , ): \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo codice univoco `uid` e il suo prototipo `prototype`. Questi due \\ campi sono immutabli (vedi PUT `/feature/{uid}`). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) db [ \"features\" ][ uid ] = feature feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ] = feature_info . pop ( \"classification\" ) feature_info [ \"geometry\" ] = geometry feature_info . update ({ \"data\" : None , \"map\" : None , \"cloud\" : None }) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ) . items (): struct [ 'operands' ][ k ] = eval ( w . replace ( '{{new}}' , 'feature' )) db [ 'series' ][ suid ] = struct params [ param ] = suid feature_info [ \"parameters\" ] = params db [ \"features_info\" ][ uid ] = feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : traceback . print_exc () out . message = f \"prototype ' { prototype } ' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : traceback . print_exc () out . message = str ( e ) out . status = falcon . HTTP_CONFLICT response = out . format ( response = response , request = request ) return @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info = [ \"geometry\" , \"capability\" ], request = None , response = None ): \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } ___nota___: Al contrario di quanto detto nel TODO non viene inserito il context a livello \\ \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora \\ per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' \\ interno delle properties delle singole features. Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ): if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ): if info == \"\" : info = None else : info = [ info ] try : out . data = { \"features\" :[]} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ): extract = [ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v [ 'uid' ]] for i in info : if i == 'parameters' : f [ i ] = [] try : for p , s in infos [ i ] . items (): if s is not None : f [ i ] . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ]} ) except AttributeError : pass else : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None out . data [ 'features' ] . append ( f ) except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) return @hug . get ( \"/ {uid} \" ) def feature_info ( uid , cntxt = None , info = [ \"geometry\" , \"capability\" ], request = None , response = None ): \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) @hug . put ( \"/ {uid} \" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = {}, request = None , response = None , ): \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" response = out . format ( response = response , request = request ) return @hug . delete ( \"/ {uid} \" ) def del_feature ( uid , request = None , response = None ): \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] for v in info [ 'parameters' ] . values (): if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ) . deleteActionValues () except Exception as e : traceback . print_exc () try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" response = out . format ( response = response , request = request ) return Variables db Functions create_feature def create_feature ( uid , prototype , properties : < hielen2 . utils . JsonValidable object at 0x7f4dd608a8b0 > = {}, geometry : < hielen2 . utils . JsonValidable object at 0x7f4dd608ad30 > = { 'type' : 'Point' , 'coordinates' : [ 0 , 0 ]}, request = None , response = None ) Creazione delle Features. Ogni feature deve avere il suo codice univoco uid e il suo prototipo prototype . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. View Source @hug . post ( \"/\" ) def create_feature ( uid , prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0, 0 ] } , request = None , response = None , ) : \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo codice univoco `uid` e il suo prototipo `prototype`. Questi due \\ campi sono immutabli (vedi PUT `/feature/{uid}`). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) db [ \"features\" ][ uid ]= feature feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ]= feature_info . pop ( \"classification\" ) feature_info [ \"geometry\" ] = geometry feature_info . update ( { \"data\" : None , \"map\" : None , \"cloud\" : None } ) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ). items () : struct [ 'operands' ][ k ]= eval ( w . replace ( '{{new}}' , 'feature' )) db [ 'series' ][ suid ]= struct params [ param ]= suid feature_info [ \"parameters\" ]= params db [ \"features_info\" ][ uid ]= feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : traceback . print_exc () out . message = f \"prototype '{prototype}' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : traceback . print_exc () out . message = str ( e ) out . status = falcon . HTTP_CONFLICT response = out . format ( response = response , request = request ) return del_feature def del_feature ( uid , request = None , response = None ) Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente. View Source @hug . delete ( \"/{uid}\" ) def del_feature ( uid , request = None , response = None ) : \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] for v in info [ 'parameters' ] . values () : if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ). deleteActionValues () except Exception as e : traceback . print_exc () try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" response = out . format ( response = response , request = request ) return feature_info def feature_info ( uid , cntxt = None , info = [ 'geometry' , 'capability' ], request = None , response = None ) Alias di recupero informazioni della specifica feature View Source @hug . get ( \"/{uid}\" ) def feature_info ( uid , cntxt = None , info =[ \"geometry\",\"capability\" ] , request = None , response = None ) : \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) features_info def features_info ( uids = None , cntxt = None , info = [ 'geometry' , 'capability' ], request = None , response = None ) Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } nota : Al contrario di quanto detto nel TODO non viene inserito il context a livello \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' interno delle properties delle singole features. Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri View Source @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info =[ \"geometry\",\"capability\" ] , request = None , response = None ) : \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \" features \": [ { \" type \": \" Feature \", \" properties \": { ... }, \" geometry \": <GeoJson Validable> }, ... ] } ___nota___: Al contrario di quanto detto nel TODO non viene inserito il context a livello \\ \" features \" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora \\ per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' \\ interno delle properties delle singole features. Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ) : if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ) : if info == \"\" : info = None else : info = [ info ] try : out . data = { \"features\" :[]} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ) : extract =[ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v['uid' ] ] for i in info : if i == 'parameters' : f [ i ]= [] try : for p , s in infos [ i ] . items () : if s is not None : f [ i ] . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] } ) except AttributeError : pass else : try : f [ i ]= infos [ i ] except Exception as e : f [ i ]= None out . data [ 'features' ] . append ( f ) except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) return update_feature def update_feature ( uid , properties : < hielen2 . utils . JsonValidable object at 0x7f4dd608acd0 > = {}, geometry : < hielen2 . utils . JsonValidable object at 0x7f4dd608af70 > = {}, request = None , response = None ) Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. View Source @hug . put ( \"/{uid}\" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = {} , request = None , response = None , ) : \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" response = out . format ( response = response , request = request ) return Classes FeaturePropertiesSchema class FeaturePropertiesSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Base schema class with which to define custom schemas. Example usage: .. code-block:: python import datetime as dt from dataclasses import dataclass from marshmallow import Schema , fields @dataclass class Album : title : str release_date : dt . date class AlbumSchema ( Schema ): title = fields . Str () release_date = fields . Date () album = Album ( \"Beggars Banquet\" , dt . date ( 1968 , 12 , 6 )) schema = AlbumSchema () data = schema . dump ( album ) data # {'release_date': '1968-12-06', 'title': 'Beggars Banquet'} :param only: Whitelist of the declared fields to select when instantiating the Schema. If None, all fields are used. Nested fields can be represented with dot delimiters. :param exclude: Blacklist of the declared fields to exclude when instantiating the Schema. If a field appears in both only and exclude , it is not used. Nested fields can be represented with dot delimiters. :param many: Should be set to True if obj is a collection so that the object will be serialized to a list. :param context: Optional context passed to :class: fields.Method and :class: fields.Function fields. :param load_only: Fields to skip during serialization (write-only fields) :param dump_only: Fields to skip during deserialization (read-only fields) :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . .. versionchanged:: 3.0.0 prefix parameter removed. .. versionchanged:: 2.0.0 __validators__ , __preprocessors__ , and __data_handlers__ are removed in favor of marshmallow.decorators.validates_schema , marshmallow.decorators.pre_load and marshmallow.decorators.post_dump . __accessor__ and __error_handler__ are deprecated. Implement the handle_error and get_attribute methods instead. View Source class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING context description error_messages label location opts status style timestamp Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"Features"},{"location":"reference/hielen2/api/features/#module-hielen2apifeatures","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from hielen2.utils import JsonValidable , hasher import hielen2.source as sourceman from marshmallow import Schema , fields from himada.api import ResponseFormatter from marshmallow_geojson import GeoJSONSchema import traceback class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None ) @hug . post ( \"/\" ) def create_feature ( uid , prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0 , 0 ]}, request = None , response = None , ): \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo codice univoco `uid` e il suo prototipo `prototype`. Questi due \\ campi sono immutabli (vedi PUT `/feature/{uid}`). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) db [ \"features\" ][ uid ] = feature feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ] = feature_info . pop ( \"classification\" ) feature_info [ \"geometry\" ] = geometry feature_info . update ({ \"data\" : None , \"map\" : None , \"cloud\" : None }) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ) . items (): struct [ 'operands' ][ k ] = eval ( w . replace ( '{{new}}' , 'feature' )) db [ 'series' ][ suid ] = struct params [ param ] = suid feature_info [ \"parameters\" ] = params db [ \"features_info\" ][ uid ] = feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : traceback . print_exc () out . message = f \"prototype ' { prototype } ' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : traceback . print_exc () out . message = str ( e ) out . status = falcon . HTTP_CONFLICT response = out . format ( response = response , request = request ) return @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info = [ \"geometry\" , \"capability\" ], request = None , response = None ): \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } ___nota___: Al contrario di quanto detto nel TODO non viene inserito il context a livello \\ \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora \\ per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' \\ interno delle properties delle singole features. Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ): if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ): if info == \"\" : info = None else : info = [ info ] try : out . data = { \"features\" :[]} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ): extract = [ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v [ 'uid' ]] for i in info : if i == 'parameters' : f [ i ] = [] try : for p , s in infos [ i ] . items (): if s is not None : f [ i ] . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ]} ) except AttributeError : pass else : try : f [ i ] = infos [ i ] except Exception as e : f [ i ] = None out . data [ 'features' ] . append ( f ) except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) return @hug . get ( \"/ {uid} \" ) def feature_info ( uid , cntxt = None , info = [ \"geometry\" , \"capability\" ], request = None , response = None ): \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response ) @hug . put ( \"/ {uid} \" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {}, geometry : JsonValidable ( GeoJSONSchema ()) = {}, request = None , response = None , ): \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" response = out . format ( response = response , request = request ) return @hug . delete ( \"/ {uid} \" ) def del_feature ( uid , request = None , response = None ): \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] for v in info [ 'parameters' ] . values (): if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ) . deleteActionValues () except Exception as e : traceback . print_exc () try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature ' { uid } ' not foud.\" response = out . format ( response = response , request = request ) return","title":"Module hielen2.api.features"},{"location":"reference/hielen2/api/features/#variables","text":"db","title":"Variables"},{"location":"reference/hielen2/api/features/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/features/#create_feature","text":"def create_feature ( uid , prototype , properties : < hielen2 . utils . JsonValidable object at 0x7f4dd608a8b0 > = {}, geometry : < hielen2 . utils . JsonValidable object at 0x7f4dd608ad30 > = { 'type' : 'Point' , 'coordinates' : [ 0 , 0 ]}, request = None , response = None ) Creazione delle Features. Ogni feature deve avere il suo codice univoco uid e il suo prototipo prototype . Questi due campi sono immutabli (vedi PUT /feature/{uid} ). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro geometry deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: 409 Conflict : Nel caso in cui il uid fornito esista gi\u00e0. 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 201 Created : Nel caso in cui la feature venga creata correttamente. View Source @hug . post ( \"/\" ) def create_feature ( uid , prototype , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = { \"type\" : \"Point\" , \"coordinates\" : [ 0, 0 ] } , request = None , response = None , ) : \"\"\" **Creazione delle Features.** Ogni feature deve avere il suo codice univoco `uid` e il suo prototipo `prototype`. Questi due \\ campi sono immutabli (vedi PUT `/feature/{uid}`). Il prototipo della feature forisce informazioni per l'inizializazione della struttura. Il parametro `geometry` deve essere un GeoJson Se la feature viene creata correttamente ne restituisce la struttura Possibili risposte: - _409 Conflict_: Nel caso in cui il uid fornito esista gi\u00e0. - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _201 Created_: Nel caso in cui la feature venga creata correttamente. \"\"\" out = ResponseFormatter ( status = falcon . HTTP_CREATED ) try : assert properties [ \"context\" ] is not None except Exception : properties [ \"context\" ] = \"no-context\" try : feature = { \"uid\" : uid , \"type\" : prototype } feature . update ( properties ) db [ \"features\" ][ uid ]= feature feature_info = db [ \"features_proto\" ][ prototype ] feature [ \"classification\" ]= feature_info . pop ( \"classification\" ) feature_info [ \"geometry\" ] = geometry feature_info . update ( { \"data\" : None , \"map\" : None , \"cloud\" : None } ) p = feature_info . pop ( \"parameters\" ) params = {} for v in p : param = v [ 'param' ] struct = v [ 'struct' ] suid = hasher ( uid , param ) try : db [ 'series' ][ suid ] = None except KeyError : pass for k , w in struct . pop ( 'init_operands' ). items () : struct [ 'operands' ][ k ]= eval ( w . replace ( '{{new}}' , 'feature' )) db [ 'series' ][ suid ]= struct params [ param ]= suid feature_info [ \"parameters\" ]= params db [ \"features_info\" ][ uid ]= feature_info out . data = db [ \"features\" ][ uid ] except KeyError as e : traceback . print_exc () out . message = f \"prototype '{prototype}' not found.\" out . status = falcon . HTTP_NOT_FOUND except ValueError as e : traceback . print_exc () out . message = str ( e ) out . status = falcon . HTTP_CONFLICT response = out . format ( response = response , request = request ) return","title":"create_feature"},{"location":"reference/hielen2/api/features/#del_feature","text":"def del_feature ( uid , request = None , response = None ) Cancellazione delle Features Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Accepted : Nel caso in cui la feature venga eliminata correttamente. View Source @hug . delete ( \"/{uid}\" ) def del_feature ( uid , request = None , response = None ) : \"\"\" **Cancellazione delle Features** Se la feature viene cancellata correttamente ne restituisce la struttura Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Accepted_: Nel caso in cui la feature venga eliminata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : out . data = db [ \"features\" ][ uid ] try : info = db [ \"features_info\" ][ uid ] for v in info [ 'parameters' ] . values () : if v is not None : try : db [ 'datacache' ][ v ] = None except KeyError as e : pass try : db [ 'series' ][ v ] = None except KeyError as e : pass sourceman . sourceFactory ( uid ). deleteActionValues () except Exception as e : traceback . print_exc () try : db [ \"features_info\" ][ uid ] = None except Exception as e : pass try : db [ \"features\" ][ uid ] = None except Exception as e : pass except KeyError as e : traceback . print_exc () out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" response = out . format ( response = response , request = request ) return","title":"del_feature"},{"location":"reference/hielen2/api/features/#feature_info","text":"def feature_info ( uid , cntxt = None , info = [ 'geometry' , 'capability' ], request = None , response = None ) Alias di recupero informazioni della specifica feature View Source @hug . get ( \"/{uid}\" ) def feature_info ( uid , cntxt = None , info =[ \"geometry\",\"capability\" ] , request = None , response = None ) : \"\"\" **Alias di recupero informazioni della specifica feature**\"\"\" return features_info ( uid , cntxt , info , request , response )","title":"feature_info"},{"location":"reference/hielen2/api/features/#features_info","text":"def features_info ( uids = None , cntxt = None , info = [ 'geometry' , 'capability' ], request = None , response = None ) Recupero delle informazioni delle features. nota : uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \"features\": [ { \"type\": \"Feature\", \"properties\": { ... }, \"geometry\": <GeoJson Validable> }, ... ] } nota : Al contrario di quanto detto nel TODO non viene inserito il context a livello \"features\" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' interno delle properties delle singole features. Possibili risposte: 404 Not Found : Nel caso in cui nessuna feature risponda ai criteri View Source @hug . get ( \"/\" ) def features_info ( uids = None , cntxt = None , info =[ \"geometry\",\"capability\" ] , request = None , response = None ) : \"\"\" **Recupero delle informazioni delle features.** __nota__: uids accetta valori multipli separati da virgola viene restituito una struttura di questo tipo: { \" features \": [ { \" type \": \" Feature \", \" properties \": { ... }, \" geometry \": <GeoJson Validable> }, ... ] } ___nota___: Al contrario di quanto detto nel TODO non viene inserito il context a livello \\ \" features \" perch\u00e8 in effetti \u00e8 una informazione sempre conosciuta a priori (se si lavora \\ per commesse). Al contrario se si lavora per uids allora ha senso inserie questa info all' \\ interno delle properties delle singole features. Possibili risposte: - _404 Not Found_: Nel caso in cui nessuna feature risponda ai criteri \"\"\" out = ResponseFormatter () if cntxt is not None and not isinstance ( cntxt , list ) : if cntxt == \"\" : cntxt = None else : cntxt = [ cntxt ] if info is not None and not isinstance ( info , list ) : if info == \"\" : info = None else : info = [ info ] try : out . data = { \"features\" :[]} extract = db [ \"features\" ][ uids ] if not isinstance ( extract , list ) : extract =[ extract ] for v in extract : if cntxt is None or v [ \"context\" ] in cntxt : f = { \"type\" : \"Feature\" , \"properties\" : v } if info is not None : infos = db [ \"features_info\" ][ v['uid' ] ] for i in info : if i == 'parameters' : f [ i ]= [] try : for p , s in infos [ i ] . items () : if s is not None : f [ i ] . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] } ) except AttributeError : pass else : try : f [ i ]= infos [ i ] except Exception as e : f [ i ]= None out . data [ 'features' ] . append ( f ) except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) return","title":"features_info"},{"location":"reference/hielen2/api/features/#update_feature","text":"def update_feature ( uid , properties : < hielen2 . utils . JsonValidable object at 0x7f4dd608acd0 > = {}, geometry : < hielen2 . utils . JsonValidable object at 0x7f4dd608af70 > = {}, request = None , response = None ) Modifica delle properties di una feature Possibili risposte: 404 Not Found : Nel caso in cui il prototipo richiesto non esista. 200 Ok : Nel caso in cui la feature venga modificata correttamente. View Source @hug . put ( \"/{uid}\" ) def update_feature ( uid , properties : JsonValidable ( FeaturePropertiesSchema ()) = {} , geometry : JsonValidable ( GeoJSONSchema ()) = {} , request = None , response = None , ) : \"\"\" **Modifica delle properties di una feature** Possibili risposte: - _404 Not Found_: Nel caso in cui il prototipo richiesto non esista. - _200 Ok_: Nel caso in cui la feature venga modificata correttamente. \"\"\" out = ResponseFormatter () if uid is None : out . status = falcon . HTTP_BAD_REQUEST out . message = \"None value not allowed\" try : feat = db [ \"features\" ][ uid ] feat . update ( properties ) db [ \"features\" ][ uid ] = None db [ \"features\" ][ uid ] = feat feat_info = db [ \"features_info\" ][ uid ] feat_info [ \"geometry\" ] . update ( geometry ) db [ \"features_info\" ][ uid ] = None db [ \"features_info\" ][ uid ] = feat_info out . data = db [ \"features\" ][ uid ] except KeyError as e : out . status = falcon . HTTP_NOT_FOUND out . message = f \"feature '{uid}' not foud.\" response = out . format ( response = response , request = request ) return","title":"update_feature"},{"location":"reference/hielen2/api/features/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/api/features/#featurepropertiesschema","text":"class FeaturePropertiesSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Base schema class with which to define custom schemas. Example usage: .. code-block:: python import datetime as dt from dataclasses import dataclass from marshmallow import Schema , fields @dataclass class Album : title : str release_date : dt . date class AlbumSchema ( Schema ): title = fields . Str () release_date = fields . Date () album = Album ( \"Beggars Banquet\" , dt . date ( 1968 , 12 , 6 )) schema = AlbumSchema () data = schema . dump ( album ) data # {'release_date': '1968-12-06', 'title': 'Beggars Banquet'} :param only: Whitelist of the declared fields to select when instantiating the Schema. If None, all fields are used. Nested fields can be represented with dot delimiters. :param exclude: Blacklist of the declared fields to exclude when instantiating the Schema. If a field appears in both only and exclude , it is not used. Nested fields can be represented with dot delimiters. :param many: Should be set to True if obj is a collection so that the object will be serialized to a list. :param context: Optional context passed to :class: fields.Method and :class: fields.Function fields. :param load_only: Fields to skip during serialization (write-only fields) :param dump_only: Fields to skip during deserialization (read-only fields) :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . .. versionchanged:: 3.0.0 prefix parameter removed. .. versionchanged:: 2.0.0 __validators__ , __preprocessors__ , and __data_handlers__ are removed in favor of marshmallow.decorators.validates_schema , marshmallow.decorators.pre_load and marshmallow.decorators.post_dump . __accessor__ and __error_handler__ are deprecated. Implement the handle_error and get_attribute methods instead. View Source class FeaturePropertiesSchema ( Schema ): context = fields . Str ( default = \"no-context\" , allow_none = False ) label = fields . Str ( default = None ) description = fields . Str ( default = None ) location = fields . Str ( default = None ) style = fields . Str ( default = None ) status = fields . Str ( default = None ) timestamp = fields . Str ( default = None )","title":"FeaturePropertiesSchema"},{"location":"reference/hielen2/api/features/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/api/features/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING context description error_messages label location opts status style timestamp","title":"Class variables"},{"location":"reference/hielen2/api/features/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/api/features/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/api/features/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/api/features/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/api/features/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/api/features/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/api/features/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/api/features/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/api/features/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/api/features/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/api/features/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/api/features/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/api/glob/","text":"Module hielen2.api.glob View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 #!/usr/bin/env python # coding=utf-8 import hug from . import parameters , prototypes , query , features , actions , actionschemata import falcon \"\"\" @hug.not_found() def not_found(): return {'error': { 'status': falcon.status.HTTP_NOT_FOUND, 'description': 'URL is invalid.', }} api = hug.get(on_invalid=hug.redirect.not_found) \"\"\" @hug . extend_api ( \"/parameters\" ) def elemman (): \"\"\" parameters manager \"\"\" return [ parameters ] @hug . extend_api ( \"/prototypes\" ) def protoman (): \"\"\" Prototypes manager \"\"\" return [ prototypes ] @hug . extend_api ( \"/features\" ) def featman (): \"\"\" Features manager \"\"\" return [ features ] @hug . extend_api ( \"/actions\" ) def actiman (): \"\"\" Action manager \"\"\" return [ actions ] @hug . extend_api ( \"/actionschemata\" ) def scheman (): \"\"\" Schemata manager \"\"\" return [ actionschemata ] @hug . extend_api ( \"/query\" ) def dataman (): \"\"\" Data manager \"\"\" return [ query ] Functions actiman def actiman ( ) Action manager View Source @hug . extend_api ( \"/actions\" ) def actiman () : \"\"\" Action manager \"\"\" return [ actions ] dataman def dataman ( ) Data manager View Source @hug . extend_api ( \"/query\" ) def dataman () : \"\"\" Data manager \"\"\" return [ query ] elemman def elemman ( ) parameters manager View Source @hug . extend_api ( \"/parameters\" ) def elemman () : \"\"\" parameters manager \"\"\" return [ parameters ] featman def featman ( ) Features manager View Source @hug . extend_api ( \"/features\" ) def featman () : \"\"\" Features manager \"\"\" return [ features ] protoman def protoman ( ) Prototypes manager View Source @hug . extend_api ( \"/prototypes\" ) def protoman () : \"\"\" Prototypes manager \"\"\" return [ prototypes ] scheman def scheman ( ) Schemata manager View Source @hug . extend_api ( \"/actionschemata\" ) def scheman () : \"\"\" Schemata manager \"\"\" return [ actionschemata ]","title":"Glob"},{"location":"reference/hielen2/api/glob/#module-hielen2apiglob","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 #!/usr/bin/env python # coding=utf-8 import hug from . import parameters , prototypes , query , features , actions , actionschemata import falcon \"\"\" @hug.not_found() def not_found(): return {'error': { 'status': falcon.status.HTTP_NOT_FOUND, 'description': 'URL is invalid.', }} api = hug.get(on_invalid=hug.redirect.not_found) \"\"\" @hug . extend_api ( \"/parameters\" ) def elemman (): \"\"\" parameters manager \"\"\" return [ parameters ] @hug . extend_api ( \"/prototypes\" ) def protoman (): \"\"\" Prototypes manager \"\"\" return [ prototypes ] @hug . extend_api ( \"/features\" ) def featman (): \"\"\" Features manager \"\"\" return [ features ] @hug . extend_api ( \"/actions\" ) def actiman (): \"\"\" Action manager \"\"\" return [ actions ] @hug . extend_api ( \"/actionschemata\" ) def scheman (): \"\"\" Schemata manager \"\"\" return [ actionschemata ] @hug . extend_api ( \"/query\" ) def dataman (): \"\"\" Data manager \"\"\" return [ query ]","title":"Module hielen2.api.glob"},{"location":"reference/hielen2/api/glob/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/glob/#actiman","text":"def actiman ( ) Action manager View Source @hug . extend_api ( \"/actions\" ) def actiman () : \"\"\" Action manager \"\"\" return [ actions ]","title":"actiman"},{"location":"reference/hielen2/api/glob/#dataman","text":"def dataman ( ) Data manager View Source @hug . extend_api ( \"/query\" ) def dataman () : \"\"\" Data manager \"\"\" return [ query ]","title":"dataman"},{"location":"reference/hielen2/api/glob/#elemman","text":"def elemman ( ) parameters manager View Source @hug . extend_api ( \"/parameters\" ) def elemman () : \"\"\" parameters manager \"\"\" return [ parameters ]","title":"elemman"},{"location":"reference/hielen2/api/glob/#featman","text":"def featman ( ) Features manager View Source @hug . extend_api ( \"/features\" ) def featman () : \"\"\" Features manager \"\"\" return [ features ]","title":"featman"},{"location":"reference/hielen2/api/glob/#protoman","text":"def protoman ( ) Prototypes manager View Source @hug . extend_api ( \"/prototypes\" ) def protoman () : \"\"\" Prototypes manager \"\"\" return [ prototypes ]","title":"protoman"},{"location":"reference/hielen2/api/glob/#scheman","text":"def scheman ( ) Schemata manager View Source @hug . extend_api ( \"/actionschemata\" ) def scheman () : \"\"\" Schemata manager \"\"\" return [ actionschemata ]","title":"scheman"},{"location":"reference/hielen2/api/parameters/","text":"Module hielen2.api.parameters View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from hielen2.utils import JsonValidable from marshmallow import Schema , fields from himada.api import ResponseFormatter @hug . get ( \"/\" , examples = \"\" ) def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ): \"\"\" **Ricerca dei parametri associati alle features**. __nota__: uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \"<fetUID>\":[ { \"series\":\"<series_UID>\", \"param\":\"<param_name>\", \"um\":\"<mearurement_unit>\" } ... ] ... } Possibili risposte: - _404 Not Found_: Nel caso in cui nessun parametro risponda ai criteri \"\"\" out = ResponseFormatter () try : if not isinstance ( params , ( list , set )) and params is not None : params = [ params ] feats = db [ \"features_info\" ][ uids ] if not isinstance ( feats , list ): feats = [ feats ] out . data = {} for f in feats : if cntxt is None or f [ \"context\" ] == cntxt : parameters = [] try : for p , s in f [ 'parameters' ] . items (): if s is not None and ( params is None or p in params ): parameters . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ]}) except AttributeError : pass out . data [ f [ 'uid' ]] = parameters except KeyError as e : out . status = falcon . HTTP_OK out . message = str ( e ) response = out . format ( response = response , request = request ) return @hug . get ( \"/ {uid} \" ) def context_feature_params ( uid = None , params = None , cntxt = None , request = None , response = None ): \"\"\" **Alias di ricerca dei Parametri della specifica Feature**\"\"\" return features_params ( uid , params , cntxt , request , response ) @hug . get ( \"/ {uid} / {param} \" ) def context_feature_params ( uid , param , cntxt = None , request = None , response = None ): \"\"\" **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**\"\"\" return features_params ( uid , param , cntxt , request , response ) Variables db Functions context_feature_params def context_feature_params ( uid , param , cntxt = None , request = None , response = None ) Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto View Source @hug . get ( \"/{uid}/{param}\" ) def context_feature_params ( uid , param , cntxt = None , request = None , response = None ) : \"\"\" **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**\"\"\" return features_params ( uid , param , cntxt , request , response ) features_params def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ) Ricerca dei parametri associati alle features . nota : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \"<fetUID>\":[ { \"series\":\"<series_UID>\", \"param\":\"<param_name>\", \"um\":\"<mearurement_unit>\" } ... ] ... } Possibili risposte: 404 Not Found : Nel caso in cui nessun parametro risponda ai criteri View Source @hug . get ( \"/\" , examples = \"\" ) def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ) : \"\"\" **Ricerca dei parametri associati alle features**. __nota__: uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \" < fetUID > \":[ { \" series \":\" < series_UID > \", \" param \":\" < param_name > \", \" um \":\" < mearurement_unit > \" } ... ] ... } Possibili risposte: - _404 Not Found_: Nel caso in cui nessun parametro risponda ai criteri \"\"\" out = ResponseFormatter () try : if not isinstance ( params , ( list , set )) and params is not None : params = [ params ] feats = db [ \"features_info\" ][ uids ] if not isinstance ( feats , list ) : feats =[ feats ] out . data = {} for f in feats : if cntxt is None or f [ \"context\" ] == cntxt : parameters = [] try : for p , s in f [ 'parameters' ] . items () : if s is not None and ( params is None or p in params ) : parameters . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] } ) except AttributeError : pass out . data [ f['uid' ] ] = parameters except KeyError as e : out . status = falcon . HTTP_OK out . message = str ( e ) response = out . format ( response = response , request = request ) return","title":"Parameters"},{"location":"reference/hielen2/api/parameters/#module-hielen2apiparameters","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from hielen2.utils import JsonValidable from marshmallow import Schema , fields from himada.api import ResponseFormatter @hug . get ( \"/\" , examples = \"\" ) def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ): \"\"\" **Ricerca dei parametri associati alle features**. __nota__: uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \"<fetUID>\":[ { \"series\":\"<series_UID>\", \"param\":\"<param_name>\", \"um\":\"<mearurement_unit>\" } ... ] ... } Possibili risposte: - _404 Not Found_: Nel caso in cui nessun parametro risponda ai criteri \"\"\" out = ResponseFormatter () try : if not isinstance ( params , ( list , set )) and params is not None : params = [ params ] feats = db [ \"features_info\" ][ uids ] if not isinstance ( feats , list ): feats = [ feats ] out . data = {} for f in feats : if cntxt is None or f [ \"context\" ] == cntxt : parameters = [] try : for p , s in f [ 'parameters' ] . items (): if s is not None and ( params is None or p in params ): parameters . append ({ \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ]}) except AttributeError : pass out . data [ f [ 'uid' ]] = parameters except KeyError as e : out . status = falcon . HTTP_OK out . message = str ( e ) response = out . format ( response = response , request = request ) return @hug . get ( \"/ {uid} \" ) def context_feature_params ( uid = None , params = None , cntxt = None , request = None , response = None ): \"\"\" **Alias di ricerca dei Parametri della specifica Feature**\"\"\" return features_params ( uid , params , cntxt , request , response ) @hug . get ( \"/ {uid} / {param} \" ) def context_feature_params ( uid , param , cntxt = None , request = None , response = None ): \"\"\" **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**\"\"\" return features_params ( uid , param , cntxt , request , response )","title":"Module hielen2.api.parameters"},{"location":"reference/hielen2/api/parameters/#variables","text":"db","title":"Variables"},{"location":"reference/hielen2/api/parameters/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/parameters/#context_feature_params","text":"def context_feature_params ( uid , param , cntxt = None , request = None , response = None ) Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto View Source @hug . get ( \"/{uid}/{param}\" ) def context_feature_params ( uid , param , cntxt = None , request = None , response = None ) : \"\"\" **Alias di ricerca dello specifico Parametro della specifica Feature lo specifico contesto**\"\"\" return features_params ( uid , param , cntxt , request , response )","title":"context_feature_params"},{"location":"reference/hielen2/api/parameters/#features_params","text":"def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ) Ricerca dei parametri associati alle features . nota : uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \"<fetUID>\":[ { \"series\":\"<series_UID>\", \"param\":\"<param_name>\", \"um\":\"<mearurement_unit>\" } ... ] ... } Possibili risposte: 404 Not Found : Nel caso in cui nessun parametro risponda ai criteri View Source @hug . get ( \"/\" , examples = \"\" ) def features_params ( uids = None , params = None , cntxt = None , request = None , response = None ) : \"\"\" **Ricerca dei parametri associati alle features**. __nota__: uid accetta valori multipli separati da virgola viene restituita una struttura di questo tipo: { \" < fetUID > \":[ { \" series \":\" < series_UID > \", \" param \":\" < param_name > \", \" um \":\" < mearurement_unit > \" } ... ] ... } Possibili risposte: - _404 Not Found_: Nel caso in cui nessun parametro risponda ai criteri \"\"\" out = ResponseFormatter () try : if not isinstance ( params , ( list , set )) and params is not None : params = [ params ] feats = db [ \"features_info\" ][ uids ] if not isinstance ( feats , list ) : feats =[ feats ] out . data = {} for f in feats : if cntxt is None or f [ \"context\" ] == cntxt : parameters = [] try : for p , s in f [ 'parameters' ] . items () : if s is not None and ( params is None or p in params ) : parameters . append ( { \"series\" : s , \"param\" : p , \"unit\" : db [ \"series\" ][ s ][ \"mu\" ] } ) except AttributeError : pass out . data [ f['uid' ] ] = parameters except KeyError as e : out . status = falcon . HTTP_OK out . message = str ( e ) response = out . format ( response = response , request = request ) return","title":"features_params"},{"location":"reference/hielen2/api/prototypes/","text":"Module hielen2.api.prototypes View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from himada.api import ResponseFormatter @hug . post ( \"/\" ) def new_protptype ( prototype , request = None , response = None ): \"\"\" ** Definizione di nuovi prototipi ** _PLACEHOLDER: Non ancora implementato_ \"\"\" return \"not yet implemented\" @hug . get ( \"/\" ) def prototypes ( request = None , response = None ): \"\"\" **Recupero di tutte le informazioni dei prototipi** ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } } \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ None ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} /struct\" ) def prototype_struct ( prototype , request = None , response = None ): \"\"\" **Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico \\ prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ][ \"struct\" ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) Variables db Functions new_protptype def new_protptype ( prototype , request = None , response = None ) Definizione di nuovi prototipi PLACEHOLDER: Non ancora implementato View Source @hug . post ( \"/\" ) def new_protptype ( prototype , request = None , response = None ) : \"\"\" ** Definizione di nuovi prototipi ** _PLACEHOLDER: Non ancora implementato_ \"\"\" return \"not yet implemented\" prototype_struct def prototype_struct ( prototype , request = None , response = None ) Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico prototipo View Source @hug . get ( \"/{prototype}/struct\" ) def prototype_struct ( prototype , request = None , response = None ) : \"\"\" **Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico \\ prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ][ \"struct\" ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) prototypes def prototypes ( request = None , response = None ) Recupero di tutte le informazioni dei prototipi ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } } View Source @hug . get ( \"/\" ) def prototypes ( request = None , response = None ) : \"\"\" **Recupero di tutte le informazioni dei prototipi** ritorna una struttura json di questo tipo: { { \" uid1 \": ..., \" module1 \": ..., \" struct \": { \" classification \": ..., \" type \": ..., \" parameters \": { \" par1_1 \": { \" type \": ..., \" operands \": { \" output \": ... } }, \" ... \", \" par1_N \": { \" type \": ..., \" operands \": { \" output \": ... } } } } }, { \" uid2 \": ..., \" module2 \": ..., \" struct \": { \" classification \": ..., \" type \": ..., \" parameters \": { \" par2_1 \": { \" type \": ..., \" operands \": { \" output \": ... } }, \" ... \", \" par2_N \": { \" type \": ..., \" operands \": { \" output \": ... } } } } } } \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ None ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"Prototypes"},{"location":"reference/hielen2/api/prototypes/#module-hielen2apiprototypes","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 #!/usr/bin/env python # coding=utf-8 import hug import falcon from hielen2 import db from himada.api import ResponseFormatter @hug . post ( \"/\" ) def new_protptype ( prototype , request = None , response = None ): \"\"\" ** Definizione di nuovi prototipi ** _PLACEHOLDER: Non ancora implementato_ \"\"\" return \"not yet implemented\" @hug . get ( \"/\" ) def prototypes ( request = None , response = None ): \"\"\" **Recupero di tutte le informazioni dei prototipi** ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } } \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ None ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request ) @hug . get ( \"/ {prototype} /struct\" ) def prototype_struct ( prototype , request = None , response = None ): \"\"\" **Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico \\ prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ][ \"struct\" ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"Module hielen2.api.prototypes"},{"location":"reference/hielen2/api/prototypes/#variables","text":"db","title":"Variables"},{"location":"reference/hielen2/api/prototypes/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/prototypes/#new_protptype","text":"def new_protptype ( prototype , request = None , response = None ) Definizione di nuovi prototipi PLACEHOLDER: Non ancora implementato View Source @hug . post ( \"/\" ) def new_protptype ( prototype , request = None , response = None ) : \"\"\" ** Definizione di nuovi prototipi ** _PLACEHOLDER: Non ancora implementato_ \"\"\" return \"not yet implemented\"","title":"new_protptype"},{"location":"reference/hielen2/api/prototypes/#prototype_struct","text":"def prototype_struct ( prototype , request = None , response = None ) Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico prototipo View Source @hug . get ( \"/{prototype}/struct\" ) def prototype_struct ( prototype , request = None , response = None ) : \"\"\" **Alias per il recupero delle info di inizializzazione delle features legate ad uno specifico \\ prototipo** \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ prototype ][ \"struct\" ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"prototype_struct"},{"location":"reference/hielen2/api/prototypes/#prototypes","text":"def prototypes ( request = None , response = None ) Recupero di tutte le informazioni dei prototipi ritorna una struttura json di questo tipo: { { \"uid1\": ..., \"module1\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par1_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par1_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } }, { \"uid2\": ..., \"module2\": ..., \"struct\": { \"classification\": ..., \"type\": ..., \"parameters\": { \"par2_1\": { \"type\": ..., \"operands\": { \"output\": ... } }, \"...\", \"par2_N\": { \"type\": ..., \"operands\": { \"output\": ... } } } } } } View Source @hug . get ( \"/\" ) def prototypes ( request = None , response = None ) : \"\"\" **Recupero di tutte le informazioni dei prototipi** ritorna una struttura json di questo tipo: { { \" uid1 \": ..., \" module1 \": ..., \" struct \": { \" classification \": ..., \" type \": ..., \" parameters \": { \" par1_1 \": { \" type \": ..., \" operands \": { \" output \": ... } }, \" ... \", \" par1_N \": { \" type \": ..., \" operands \": { \" output \": ... } } } } }, { \" uid2 \": ..., \" module2 \": ..., \" struct \": { \" classification \": ..., \" type \": ..., \" parameters \": { \" par2_1 \": { \" type \": ..., \" operands \": { \" output \": ... } }, \" ... \", \" par2_N \": { \" type \": ..., \" operands \": { \" output \": ... } } } } } } \"\"\" out = ResponseFormatter () try : out . data = db [ \"features_proto\" ][ None ] except KeyError as e : out . status = out . status = falcon . HTTP_NOT_FOUND out . message = str ( e ) response = out . format ( response = response , request = request )","title":"prototypes"},{"location":"reference/hielen2/api/query/","text":"Module hielen2.api.query View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 #!/usr/bin/env python # coding=utf-8 import hug import falcon import json from marshmallow import Schema , fields from numpy import nan , unique from pandas import DataFrame , to_datetime from hielen2 import db from hielen2.query import Series from hielen2.utils import hug_output_format_conten_type , JsonValidable , Selection from himada.api import ResponseFormatter import asyncio from marshmallow_geojson import GeoJSONSchema data_out_handler = hug_output_format_conten_type ( [ hug . output_format . json , hug . output_format . text ] ) CSV = \"text/plain; charset=utf-8\" JSON = \"application/json; charset=utf-8\" class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , reuired = False , allow_none = True ) series = fields . List ( fields . Str , default = []) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . Nested ( GeoJSONSchema , required = False , allow_none = True ) ####### API DATATABLE ####### @hug . get ( \"/ {capability} \" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ): series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys (): series [ p ] = [] try : series [ p ] . append ( Series ( p , orient = capability ) . thdata ( ** query ), ** kwargs ) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items (): ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ) . sort_index () idx = unique ( ser . index . values , return_index = True )[ 1 ] ser = ser . iloc [ idx ] #ser.columns = [param] ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ) . content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) @hug . get ( \"/ {capability} / {feature} /\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ): try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ par ]] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , refresh = refresh ) datamap = DataMapSchema () . loads ( json . dumps ( datamap )) return tabular_data ( capability = capability , datamap = [ datamap ], content_type = content_type , request = request , response = response , ** kwargs ) @hug . get ( \"/ {capability} / {feature} / {par} \" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ): return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , content_type = content_type , request = request , response = response , ** kwargs ) Variables CSV JSON db nan Functions data_out_handler def data_out_handler ( data , request , response ) Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text View Source def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response ) tabular_data def tabular_data ( capability , datamap : < hielen2 . utils . JsonValidable object at 0x7f4dd605ac40 > , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}\" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ) : series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys () : series [ p ] = [] try : series [ p ] . append ( Series ( p , orient = capability ). thdata ( ** query ), ** kwargs ) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items () : ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ). sort_index () idx = unique ( ser . index . values , return_index = True ) [ 1 ] ser = ser . iloc [ idx ] #ser . columns = [ param ] ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ). content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) tabular_data_el def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) : try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ par ] ] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , refresh = refresh ) datamap = DataMapSchema (). loads ( json . dumps ( datamap )) return tabular_data ( capability = capability , datamap =[ datamap ] , content_type = content_type , request = request , response = response , ** kwargs ) tabular_data_par def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/{par}\" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) : return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , content_type = content_type , request = request , response = response , ** kwargs ) Classes DataMapSchema class DataMapSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) View Source class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , reuired = False , allow_none = True ) series = fields . List ( fields . Str , default =[]) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . Nested ( GeoJSONSchema , required = False , allow_none = True ) Ancestors (in MRO) marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages geometry opts refresh series timeref times Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"Query"},{"location":"reference/hielen2/api/query/#module-hielen2apiquery","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 #!/usr/bin/env python # coding=utf-8 import hug import falcon import json from marshmallow import Schema , fields from numpy import nan , unique from pandas import DataFrame , to_datetime from hielen2 import db from hielen2.query import Series from hielen2.utils import hug_output_format_conten_type , JsonValidable , Selection from himada.api import ResponseFormatter import asyncio from marshmallow_geojson import GeoJSONSchema data_out_handler = hug_output_format_conten_type ( [ hug . output_format . json , hug . output_format . text ] ) CSV = \"text/plain; charset=utf-8\" JSON = \"application/json; charset=utf-8\" class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , reuired = False , allow_none = True ) series = fields . List ( fields . Str , default = []) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . Nested ( GeoJSONSchema , required = False , allow_none = True ) ####### API DATATABLE ####### @hug . get ( \"/ {capability} \" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ): series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys (): series [ p ] = [] try : series [ p ] . append ( Series ( p , orient = capability ) . thdata ( ** query ), ** kwargs ) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items (): ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ) . sort_index () idx = unique ( ser . index . values , return_index = True )[ 1 ] ser = ser . iloc [ idx ] #ser.columns = [param] ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ) . content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" )) @hug . get ( \"/ {capability} / {feature} /\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ): try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft [ \"parameters\" ][ par ]] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , refresh = refresh ) datamap = DataMapSchema () . loads ( json . dumps ( datamap )) return tabular_data ( capability = capability , datamap = [ datamap ], content_type = content_type , request = request , response = response , ** kwargs ) @hug . get ( \"/ {capability} / {feature} / {par} \" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ): return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , content_type = content_type , request = request , response = response , ** kwargs )","title":"Module hielen2.api.query"},{"location":"reference/hielen2/api/query/#variables","text":"CSV JSON db nan","title":"Variables"},{"location":"reference/hielen2/api/query/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/api/query/#data_out_handler","text":"def data_out_handler ( data , request , response ) Supports any of the following formats: JSON (Javascript Serialized Object Notation), Free form UTF-8 text View Source def output_type ( data , request , response ): handler = requested_output_type ( request ) response . content_type = handler . content_type return handler ( data , request = request , response = response )","title":"data_out_handler"},{"location":"reference/hielen2/api/query/#tabular_data","text":"def tabular_data ( capability , datamap : < hielen2 . utils . JsonValidable object at 0x7f4dd605ac40 > , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}\" , examples = \"\" , output = data_out_handler ) def tabular_data ( capability , datamap : JsonValidable ( DataMapSchema ( many = True )), content_type = None , request = None , response = None , ** kwargs ) : series = {} for query in datamap : ss = query . pop ( 'series' ) for p in ss : if p not in series . keys () : series [ p ] = [] try : series [ p ] . append ( Series ( p , orient = capability ). thdata ( ** query ), ** kwargs ) except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return out = DataFrame () for param , sers in series . items () : ser = None for r in sers : s = r . result () if ser is None : ser = s else : ser = ser . append ( s ). sort_index () idx = unique ( ser . index . values , return_index = True ) [ 1 ] ser = ser . iloc [ idx ] #ser . columns = [ param ] ser . name = param out = out . join ( ser , how = \"outer\" ) out . index . name = \"timestamp\" requested = data_out_handler . requested ( request ). content_type if requested == CSV : return hug . types . text ( out . to_csv ( sep = ';' )) if requested == JSON : return hug . types . json ( out . to_json ( orient = \"table\" ))","title":"tabular_data"},{"location":"reference/hielen2/api/query/#tabular_data_el","text":"def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/\" , output = data_out_handler ) def tabular_data_el ( capability , feature , par = None , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) : try : ft = db [ \"features_info\" ][ feature ] except KeyError : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( feature ) + \" not found\" response = out . format ( response = response , request = request ) return try : if par is None : series = list ( ft [ \"parameters\" ] . values ()) else : series = [ ft[\"parameters\" ][ par ] ] except KeyError as e : out = ResponseFormatter ( status = falcon . HTTP_NOT_FOUND ) out . message = str ( e ) + \" not found\" response = out . format ( response = response , request = request ) return datamap = dict ( series = series , times = times , timeref = timeref , refresh = refresh ) datamap = DataMapSchema (). loads ( json . dumps ( datamap )) return tabular_data ( capability = capability , datamap =[ datamap ] , content_type = content_type , request = request , response = response , ** kwargs )","title":"tabular_data_el"},{"location":"reference/hielen2/api/query/#tabular_data_par","text":"def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) View Source @hug . get ( \"/{capability}/{feature}/{par}\" , output = data_out_handler ) def tabular_data_par ( capability , feature , par , times = None , timeref = None , refresh = None , content_type = None , request = None , response = None , ** kwargs ) : return tabular_data_el ( capability = capability , feature = feature , par = par , times = times , timeref = timeref , refresh = refresh , content_type = content_type , request = request , response = response , ** kwargs )","title":"tabular_data_par"},{"location":"reference/hielen2/api/query/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/api/query/#datamapschema","text":"class DataMapSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) View Source class DataMapSchema ( Schema ): \"\"\"\"\"\" times = Selection ( missing = slice ( None ), default = slice ( None ), required = False , allow_none = True ) timeref = fields . Str ( default = None , reuired = False , allow_none = True ) series = fields . List ( fields . Str , default =[]) refresh = fields . Bool ( default = False , required = False , allow_none = True ) geometry = fields . Nested ( GeoJSONSchema , required = False , allow_none = True )","title":"DataMapSchema"},{"location":"reference/hielen2/api/query/#ancestors-in-mro","text":"marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/api/query/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages geometry opts refresh series timeref times","title":"Class variables"},{"location":"reference/hielen2/api/query/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/api/query/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/api/query/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/api/query/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/api/query/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/api/query/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/api/query/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/api/query/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/api/query/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/api/query/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/api/query/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/api/query/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/data/","text":"Module hielen2.data Sub-modules hielen2.data.calculation hielen2.data.data_access_layer","title":"Index"},{"location":"reference/hielen2/data/#module-hielen2data","text":"","title":"Module hielen2.data"},{"location":"reference/hielen2/data/#sub-modules","text":"hielen2.data.calculation hielen2.data.data_access_layer","title":"Sub-modules"},{"location":"reference/hielen2/data/calculation/","text":"Module hielen2.data.calculation View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 #!/usr/bin/env python # coding=utf-8 __name__ = \"hielen2.series.calculation\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"hub for hielen calculations\" __license__ = \"MIT\" __uri__ = \"\" from pandas import DataFrame , Series import math import numpy as np #### CUSTOM LIBRARY #### def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) return f \" { w } *S0** { k } \" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = S0 [ 0 ] . apply ( lambda x : math . sin ( math . radians ( x ))) return S0 * radius def aligned ( func ): def wrap_align ( left , right ): left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna ()[ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ], right [ mask ]) return wrap_align @aligned def add ( left , right ): right = right . fillna ( 0 ) return left + right @aligned def sub ( left , right ): right = right . fillna ( 0 ) return left - right def filter ( b ): d = abs ( b - b . rolling ( window = 50 , center = True , min_periods = 1 ) . apply ( np . mean )) std = abs ( b . rolling ( window = 50 , center = True , min_periods = 1 ) . apply ( np . std )) return b [ d < 3 * std ] def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"poly_trans\" , \"add\" , \"sub\" , \"slope\" ] Functions add def add ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] ) poly_trans def poly_trans ( S0 , ** kwargs ) View Source def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) return f \"{w}*S0**{k}\" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) slope def slope ( S0 , unit , radius ) View Source def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = S0 [ 0 ]. apply ( lambda x : math . sin ( math . radians ( x ))) return S0 * radius sub def sub ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"Calculation"},{"location":"reference/hielen2/data/calculation/#module-hielen2datacalculation","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 #!/usr/bin/env python # coding=utf-8 __name__ = \"hielen2.series.calculation\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"hub for hielen calculations\" __license__ = \"MIT\" __uri__ = \"\" from pandas import DataFrame , Series import math import numpy as np #### CUSTOM LIBRARY #### def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) return f \" { w } *S0** { k } \" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator ) def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = S0 [ 0 ] . apply ( lambda x : math . sin ( math . radians ( x ))) return S0 * radius def aligned ( func ): def wrap_align ( left , right ): left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna ()[ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ], right [ mask ]) return wrap_align @aligned def add ( left , right ): right = right . fillna ( 0 ) return left + right @aligned def sub ( left , right ): right = right . fillna ( 0 ) return left - right def filter ( b ): d = abs ( b - b . rolling ( window = 50 , center = True , min_periods = 1 ) . apply ( np . mean )) std = abs ( b . rolling ( window = 50 , center = True , min_periods = 1 ) . apply ( np . std )) return b [ d < 3 * std ] def int_or_str ( value ): try : return int ( value ) except ValueError : return value VERSION = tuple ( map ( int_or_str , __version__ . split ( \".\" ))) __all__ = [ \"poly_trans\" , \"add\" , \"sub\" , \"slope\" ]","title":"Module hielen2.data.calculation"},{"location":"reference/hielen2/data/calculation/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/data/calculation/#add","text":"def add ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"add"},{"location":"reference/hielen2/data/calculation/#poly_trans","text":"def poly_trans ( S0 , ** kwargs ) View Source def poly_trans ( S0 , ** kwargs ): def _parse ( k , w ): k = k . replace ( \"E\" , \"\" ) return f \"{w}*S0**{k}\" operator = \"+\" . join ( _parse ( * x ) for x in kwargs . items () if x [ 0 ][ 0 ] in [ \"E\" , \"e\" ]) return eval ( operator )","title":"poly_trans"},{"location":"reference/hielen2/data/calculation/#slope","text":"def slope ( S0 , unit , radius ) View Source def slope ( S0 , unit , radius ): if unit == \"\u00b0\" : S0 = S0 [ 0 ]. apply ( lambda x : math . sin ( math . radians ( x ))) return S0 * radius","title":"slope"},{"location":"reference/hielen2/data/calculation/#sub","text":"def sub ( left , right ) View Source def wrap_align ( left , right ) : left = left . copy () right = right . copy () try : left . columns = list ( range ( len ( left . columns ))) except AttributeError : left . name = 0 try : right . columns = list ( range ( len ( right . columns ))) except AttributeError : right . name = 0 left , right = left . align ( right , axis = 0 , copy = False ) mask = left . notna () [ 0 ] right = right . fillna ( method = \"pad\" ) return func ( left [ mask ] , right [ mask ] )","title":"sub"},{"location":"reference/hielen2/data/data_access_layer/","text":"Module hielen2.data.data_access_layer View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique from importlib import import_module from hielen2 import db from hielen2.utils import isot2ut , ut2isot def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class Series : def __init__ ( self , uid ): series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo ) @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ): return self . data ( timefrom , timeto ) def data ( self , timefrom = None , timeto = None ): if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(isot2ut(timefrom2),isot2ut(timefrom) or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , modules = None , operator = None , operands = None ): self . operator = operator or \"DataFrame()\" self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} if operands is not None : self . operands = dict ( Generator . _parse_operand ( * op ) for op in operands . items () ) def _parse_operand ( key , value ): \"\"\" trying to extract a series \"\"\" try : return ( key , Series ( value )) except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 return ( key , db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]]) except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" return ( key , value ) def _generate ( self , timefrom , timeto ): operands = dict ( timefrom = timefrom , timeto = timeto ) operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series )} ) runners = { k : w . thdata ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ({ k : w . result () for k , w in runners . items ()}) # operands.update( { k:w.data(timefrom,timeto) for k,w in self.operands.items() if isinstance(w,Series) } ) # print('OPERANDI',operands) # print('OPERATORE', self.operator) return eval ( self . operator ) Variables db nan Classes Generator class Generator ( modules = None , operator = None , operands = None ) View Source class Generator : def __init__ ( self , modules = None , operator = None , operands = None ) : self . operator = operator or \"DataFrame()\" self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} if operands is not None : self . operands = dict ( Generator . _parse_operand ( * op ) for op in operands . items () ) def _parse_operand ( key , value ) : \"\"\" trying to extract a series \"\"\" try : return ( key , Series ( value )) except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 return ( key , db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] ) except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" return ( key , value ) def _generate ( self , timefrom , timeto ) : operands = dict ( timefrom = timefrom , timeto = timeto ) operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series ) } ) runners = { k : w . thdata ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ( { k : w . result () for k , w in runners . items () } ) # operands . update ( { k : w . data ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } ) # print ( 'OPERANDI' , operands ) # print ( 'OPERATORE' , self . operator ) return eval ( self . operator ) Series class Series ( uid ) View Source class Series : def __init__ ( self , uid ) : series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo ) @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) : return self . data ( timefrom , timeto ) def data ( self , timefrom = None , timeto = None ) : if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out Methods data def data ( self , timefrom = None , timeto = None ) View Source def data ( self , timefrom = None , timeto = None ) : if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out thdata def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) View Source @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) : return self . data ( timefrom , timeto )","title":"Data Access Layer"},{"location":"reference/hielen2/data/data_access_layer/#module-hielen2datadata_access_layer","text":"View Source 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 #!/usr/bin/env python # coding=utf-8 from pandas import DataFrame from time import time from concurrent.futures import ThreadPoolExecutor from functools import wraps from numpy import nan , unique from importlib import import_module from hielen2 import db from hielen2.utils import isot2ut , ut2isot def _threadpool ( f ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class Series : def __init__ ( self , uid ): series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo ) @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ): return self . data ( timefrom , timeto ) def data ( self , timefrom = None , timeto = None ): if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self . uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom : timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max(isot2ut(timefrom2),isot2ut(timefrom) or 1) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ) . sort_index () idx = unique ( out . index . values , return_index = True )[ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out class Generator : def __init__ ( self , modules = None , operator = None , operands = None ): self . operator = operator or \"DataFrame()\" self . modules = {} if not modules is None : for k , m in modules . items (): self . operator = self . operator . replace ( k , f \"self.modules[ { k !r} ]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} if operands is not None : self . operands = dict ( Generator . _parse_operand ( * op ) for op in operands . items () ) def _parse_operand ( key , value ): \"\"\" trying to extract a series \"\"\" try : return ( key , Series ( value )) except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 return ( key , db [ \"features\" ][ v [ 0 ]][ \"properties\" ][ v [ 1 ]]) except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" return ( key , value ) def _generate ( self , timefrom , timeto ): operands = dict ( timefrom = timefrom , timeto = timeto ) operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series )} ) runners = { k : w . thdata ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ({ k : w . result () for k , w in runners . items ()}) # operands.update( { k:w.data(timefrom,timeto) for k,w in self.operands.items() if isinstance(w,Series) } ) # print('OPERANDI',operands) # print('OPERATORE', self.operator) return eval ( self . operator )","title":"Module hielen2.data.data_access_layer"},{"location":"reference/hielen2/data/data_access_layer/#variables","text":"db nan","title":"Variables"},{"location":"reference/hielen2/data/data_access_layer/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/data/data_access_layer/#generator","text":"class Generator ( modules = None , operator = None , operands = None ) View Source class Generator : def __init__ ( self , modules = None , operator = None , operands = None ) : self . operator = operator or \"DataFrame()\" self . modules = {} if not modules is None : for k , m in modules . items () : self . operator = self . operator . replace ( k , f \"self.modules[{k!r}]\" ) self . modules [ k ] = import_module ( m ) self . operands = {} if operands is not None : self . operands = dict ( Generator . _parse_operand ( * op ) for op in operands . items () ) def _parse_operand ( key , value ) : \"\"\" trying to extract a series \"\"\" try : return ( key , Series ( value )) except KeyError : pass \"\"\" trying to extract element attribute \"\"\" #TODO modificare per utilizare configurazione try : v = value . split ( \".\" ) assert v . __len__ () == 2 return ( key , db [ \"features\" ][ v[0 ] ] [ \"properties\" ][ v[1 ] ] ) except Exception : pass \"\"\" giving up. It should be a scalar. return it \"\"\" return ( key , value ) def _generate ( self , timefrom , timeto ) : operands = dict ( timefrom = timefrom , timeto = timeto ) operands . update ( { k : w for k , w in self . operands . items () if not isinstance ( w , Series ) } ) runners = { k : w . thdata ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } operands . update ( { k : w . result () for k , w in runners . items () } ) # operands . update ( { k : w . data ( timefrom , timeto ) for k , w in self . operands . items () if isinstance ( w , Series ) } ) # print ( 'OPERANDI' , operands ) # print ( 'OPERATORE' , self . operator ) return eval ( self . operator )","title":"Generator"},{"location":"reference/hielen2/data/data_access_layer/#series","text":"class Series ( uid ) View Source class Series : def __init__ ( self , uid ) : series_info = db [ \"series\" ][ uid ] self . __dict__ . update ( series_info ) geninfo = dict ( ( k , w ) for k , w in series_info . items () if k in ( \"modules\" , \"operator\" , \"operands\" ) ) self . generator = Generator ( ** geninfo ) @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) : return self . data ( timefrom , timeto ) def data ( self , timefrom = None , timeto = None ) : if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out","title":"Series"},{"location":"reference/hielen2/data/data_access_layer/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/data/data_access_layer/#data","text":"def data ( self , timefrom = None , timeto = None ) View Source def data ( self , timefrom = None , timeto = None ) : if timefrom is not None : if self . first is not None : timefrom = max ( self . first , timefrom ) else : timefrom = self . first if timeto is not None : if self . last is not None : timeto = min ( self . last , timeto ) else : timeto = self . last try : out = db [ \"datacache\" ][ self.uid ] . to_frame () if timefrom is not None and out . index . max () < timefrom : out = out . tail ( 1 ) else : out = out [ timefrom:timeto ] except KeyError : out = DataFrame () timefrom2 = out . index . max () if timefrom2 is nan : timefrom2 = timefrom else : # timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = max ( isot2ut ( timefrom2 ), isot2ut ( timefrom ) or 1 ) timefrom2 = ut2isot ( timefrom2 ) gen = self . generator . _generate ( timefrom = timefrom2 , timeto = timeto ) try : gen = gen . to_frame () except AttributeError : pass gen . columns = list ( range ( gen . columns . __len__ ())) out = out . append ( gen ). sort_index () idx = unique ( out . index . values , return_index = True ) [ 1 ] out = out . iloc [ idx ] out . index . name = \"timestamp\" return out","title":"data"},{"location":"reference/hielen2/data/data_access_layer/#thdata","text":"def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) View Source @_threadpool def thdata ( self , timefrom = None , timeto = None , * args , ** kwargs ) : return self . data ( timefrom , timeto )","title":"thdata"},{"location":"reference/hielen2/ext/","text":"Module hielen2.ext Sub-modules hielen2.ext.source_csv hielen2.ext.source_photomonitoring hielen2.ext.source_smori hielen2.ext.source_tinsar hielen2.ext.source_winecap","title":"Index"},{"location":"reference/hielen2/ext/#module-hielen2ext","text":"","title":"Module hielen2.ext"},{"location":"reference/hielen2/ext/#sub-modules","text":"hielen2.ext.source_csv hielen2.ext.source_photomonitoring hielen2.ext.source_smori hielen2.ext.source_tinsar hielen2.ext.source_winecap","title":"Sub-modules"},{"location":"reference/hielen2/ext/source_csv/","text":"Module hielen2.ext.source_csv View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime , read_csv import json import requests def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ) . getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ): self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ): out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col = [ 0 ], )[ column ] # out.index=to_datetime(out.index) out = out . loc [ timefrom : timeto ] return out Functions get_ch def get_ch ( path = './incomes' , restype = None , resource = None , filename = 'last_load.csv' , column = None , timefrom = None , timeto = None ) View Source def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ). getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) Classes GWO class GWO ( path = './incomes' , restype = None , filename = 'last_load.csv' ) View Source class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ) : self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out Methods getDataSeries def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) View Source def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"Source Csv"},{"location":"reference/hielen2/ext/source_csv/#module-hielen2extsource_csv","text":"View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime , read_csv import json import requests def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ) . getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto ) class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ): self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ): out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col = [ 0 ], )[ column ] # out.index=to_datetime(out.index) out = out . loc [ timefrom : timeto ] return out","title":"Module hielen2.ext.source_csv"},{"location":"reference/hielen2/ext/source_csv/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_csv/#get_ch","text":"def get_ch ( path = './incomes' , restype = None , resource = None , filename = 'last_load.csv' , column = None , timefrom = None , timeto = None ) View Source def get_ch ( path = \"./incomes\" , restype = None , resource = None , filename = \"last_load.csv\" , column = None , timefrom = None , timeto = None , ): return GWO ( path , restype , filename ). getDataSeries ( resource = resource , column = column , timefrom = timefrom , timeto = timeto )","title":"get_ch"},{"location":"reference/hielen2/ext/source_csv/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_csv/#gwo","text":"class GWO ( path = './incomes' , restype = None , filename = 'last_load.csv' ) View Source class GWO : def __init__ ( self , path = \"./incomes\" , restype = None , filename = \"last_load.csv\" ) : self . path = path self . restype = restype self . filename = filename def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"GWO"},{"location":"reference/hielen2/ext/source_csv/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_csv/#getdataseries","text":"def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) View Source def getDataSeries ( self , resource = None , column = None , timefrom = None , timeto = None ) : out = read_csv ( f \"{self.path}/{self.restype}/{resource}/{self.filename}\" , header = None , index_col =[ 0 ] , ) [ column ] # out . index = to_datetime ( out . index ) out = out . loc [ timefrom:timeto ] return out","title":"getDataSeries"},{"location":"reference/hielen2/ext/source_smori/","text":"Module hielen2.ext.source_smori View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime import json import requests def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO () . getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) class GWO : def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out Functions get_ch def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO (). getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) Classes GWO class GWO ( uri = 'https://www.smori.it/tisma/api/v1/sensor_data.php' ) View Source class GWO: def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None: params [ \"aggr\" ] = aggr if timefrom is not None: params [ \"dal\" ] = timefrom if timefrom is not None: params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty: return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out Methods getDataSeries def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print ( r . url ) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"Source Smori"},{"location":"reference/hielen2/ext/source_smori/#module-hielen2extsource_smori","text":"View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime import json import requests def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO () . getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , ) class GWO : def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"Module hielen2.ext.source_smori"},{"location":"reference/hielen2/ext/source_smori/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_smori/#get_ch","text":"def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def get_ch ( sito = None , id_stazione = None , id_unita = None , id_sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): return GWO (). getDataSeries ( sito = sito , stazione = id_stazione , unita = id_unita , sensore = id_sensore , aggr = \"avg\" , timefrom = timefrom , timeto = timeto , )","title":"get_ch"},{"location":"reference/hielen2/ext/source_smori/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_smori/#gwo","text":"class GWO ( uri = 'https://www.smori.it/tisma/api/v1/sensor_data.php' ) View Source class GWO: def __init__ ( self , uri = \"https://www.smori.it/tisma/api/v1/sensor_data.php\" ): self . uri = uri def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None: params [ \"aggr\" ] = aggr if timefrom is not None: params [ \"dal\" ] = timefrom if timefrom is not None: params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print (r.url) if out . empty: return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"GWO"},{"location":"reference/hielen2/ext/source_smori/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_smori/#getdataseries","text":"def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = 'avg' , timefrom = None , timeto = None ) View Source def getDataSeries ( self , sito = None , stazione = None , unita = None , sensore = None , aggr = \"avg\" , timefrom = None , timeto = None , ): params = dict ( sito = sito , stazione = stazione , unita = unita , sensore = sensore , ) if aggr is not None : params [ \"aggr\" ] = aggr if timefrom is not None : params [ \"dal\" ] = timefrom if timefrom is not None : params [ \"al\" ] = timeto r = requests . get ( url = self . uri , params = params ) out = DataFrame ( json . loads ( r . text )[ \"data\" ]) # print ( r . url ) if out . empty : return out out = out . set_index ([ \"timestamp\" ])[ \"valore\" ] out = out . astype ( float , copy = False , errors = \"ignore\" ) out . name = f \"{stazione}_{unita}_{sensore}\" out . index = to_datetime ( out . index ) return out","title":"getDataSeries"},{"location":"reference/hielen2/ext/source_winecap/","text":"Module hielen2.ext.source_winecap View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime from zeep import Client from zeep.helpers import serialize_object from concurrent.futures import ThreadPoolExecutor from functools import wraps from time import time from hielen.utils import isot2ut \"\"\" sudo apt-get install libxml2-dev libxslt1-dev pip install lxml==4.2.5 zeep \"\"\" # key='80d373db820fea6f8c5f57d125eb509d' key = \"04a71268d386d61801824863ad7e2a5d\" GWOmac = \"00009DEA\" def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ) . getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) def threadpool ( f , executor = None ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ): self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ): return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ] Variables GWOmac key Functions get_ch def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ) View Source def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ). getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) threadpool def threadpool ( f , executor = None ) View Source def threadpool ( f , executor = None ) : @wraps ( f ) def wrap ( * args , ** kwargs ) : return ThreadPoolExecutor (). submit ( f , * args , ** kwargs ) return wrap Classes GWO class GWO ( key = '04a71268d386d61801824863ad7e2a5d' , mac = '00009DEA' , wsdl = 'http://www.winecap.it/winecapws.wsdl' ) View Source class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ) : self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ) : return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) : if not isinstance ( timefrom , int ) : timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ) : timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ( [ \"timeStamp\" ] ) [ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [] , timefrom = None , timeto = None ) : thds = [ self.getThreadedSeries(*x, timefrom, timeto) for x in reqser ] return [ x.result() for x in thds ] def getDataFrameSE ( self , reqser = [] , timefrom = None , timeto = None ) : return [ self.getDataSeries(*x, timefrom, timeto) for x in reqser ] Methods getDataFrame def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] getDataFrameSE def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ] getDataSeries def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) View Source def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out getSensorsList def getSensorsList ( self ) View Source def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) getThreadedSeries def getThreadedSeries ( self , * args , ** kwargs ) View Source @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs )","title":"Source Winecap"},{"location":"reference/hielen2/ext/source_winecap/#module-hielen2extsource_winecap","text":"View Source # coding: utf-8 from pandas import DataFrame , Series , to_datetime from zeep import Client from zeep.helpers import serialize_object from concurrent.futures import ThreadPoolExecutor from functools import wraps from time import time from hielen.utils import isot2ut \"\"\" sudo apt-get install libxml2-dev libxslt1-dev pip install lxml==4.2.5 zeep \"\"\" # key='80d373db820fea6f8c5f57d125eb509d' key = \"04a71268d386d61801824863ad7e2a5d\" GWOmac = \"00009DEA\" def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ) . getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto ) def threadpool ( f , executor = None ): @wraps ( f ) def wrap ( * args , ** kwargs ): return ThreadPoolExecutor () . submit ( f , * args , ** kwargs ) return wrap class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ): self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ): return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ] def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ]","title":"Module hielen2.ext.source_winecap"},{"location":"reference/hielen2/ext/source_winecap/#variables","text":"GWOmac key","title":"Variables"},{"location":"reference/hielen2/ext/source_winecap/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_winecap/#get_ch","text":"def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ) View Source def get_ch ( GW = None , LG = None , CH = None , timefrom = None , timeto = None ): return GWO ( mac = GW ). getDataSeries ( mac = LG , ch = CH , timefrom = timefrom , timeto = timeto )","title":"get_ch"},{"location":"reference/hielen2/ext/source_winecap/#threadpool","text":"def threadpool ( f , executor = None ) View Source def threadpool ( f , executor = None ) : @wraps ( f ) def wrap ( * args , ** kwargs ) : return ThreadPoolExecutor (). submit ( f , * args , ** kwargs ) return wrap","title":"threadpool"},{"location":"reference/hielen2/ext/source_winecap/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_winecap/#gwo","text":"class GWO ( key = '04a71268d386d61801824863ad7e2a5d' , mac = '00009DEA' , wsdl = 'http://www.winecap.it/winecapws.wsdl' ) View Source class GWO : def __init__ ( self , key = key , mac = GWOmac , wsdl = \"http://www.winecap.it/winecapws.wsdl\" ) : self . key = key self . mac = mac self . client = Client ( wsdl = wsdl ) self . _gch = self . client . service . getChannelHistory self . _gsh = self . client . service . getSystemHistory self . _gsl = self . client . service . getSensorList def getSensorsList ( self ) : return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac ))) def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) : if not isinstance ( timefrom , int ) : timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ) : timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ( [ \"timeStamp\" ] ) [ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs ) def getDataFrame ( self , reqser = [] , timefrom = None , timeto = None ) : thds = [ self.getThreadedSeries(*x, timefrom, timeto) for x in reqser ] return [ x.result() for x in thds ] def getDataFrameSE ( self , reqser = [] , timefrom = None , timeto = None ) : return [ self.getDataSeries(*x, timefrom, timeto) for x in reqser ]","title":"GWO"},{"location":"reference/hielen2/ext/source_winecap/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_winecap/#getdataframe","text":"def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrame ( self , reqser = [], timefrom = None , timeto = None ): thds = [ self . getThreadedSeries ( * x , timefrom , timeto ) for x in reqser ] return [ x . result () for x in thds ]","title":"getDataFrame"},{"location":"reference/hielen2/ext/source_winecap/#getdataframese","text":"def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ) View Source def getDataFrameSE ( self , reqser = [], timefrom = None , timeto = None ): return [ self . getDataSeries ( * x , timefrom , timeto ) for x in reqser ]","title":"getDataFrameSE"},{"location":"reference/hielen2/ext/source_winecap/#getdataseries","text":"def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ) View Source def getDataSeries ( self , mac , ch , timefrom = None , timeto = None ): if not isinstance ( timefrom , int ): timefrom = isot2ut ( timefrom ) if timeto is None : timeto = int ( time ()) if not isinstance ( timeto , int ): timeto = isot2ut ( timeto ) ahead = True out = Series () while ahead : u = DataFrame ( serialize_object ( self . _gch ( self . key , self . mac , mac , ch , timefrom , timeto ) ) ) if u . __len__ () < 1024 : ahead = False if u . __len__ () > 0 : u = u . set_index ([ \"timeStamp\" ])[ \"value\" ] u . index . names = [ \"timestamp\" ] timefrom = u . index . max () + 1 out = out . append ( u ) out = out . sort_index () out . name = f \"{mac}_{ch}\" out . sort_index () out . index = to_datetime ( out . index , unit = \"s\" ) return out","title":"getDataSeries"},{"location":"reference/hielen2/ext/source_winecap/#getsensorslist","text":"def getSensorsList ( self ) View Source def getSensorsList ( self ): return DataFrame ( serialize_object ( self . _gsl ( self . key , self . mac )))","title":"getSensorsList"},{"location":"reference/hielen2/ext/source_winecap/#getthreadedseries","text":"def getThreadedSeries ( self , * args , ** kwargs ) View Source @threadpool def getThreadedSeries ( self , * args , ** kwargs ) : return self . getDataSeries ( * args , ** kwargs )","title":"getThreadedSeries"},{"location":"reference/hielen2/ext/source_photomonitoring/","text":"Module hielen2.ext.source_photomonitoring View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .phm import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ] Sub-modules hielen2.ext.source_photomonitoring.phm hielen2.ext.source_photomonitoring.rendering hielen2.ext.source_photomonitoring.struct hielen2.ext.source_photomonitoring.struct_ok Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) 'master_image' (required): the base image used as reference grid for elaboration. It can be any image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image' View Source class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_image opts step_size window_size_change Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) reference_time: timestamp of the reference \"master_image\". If Null assumes last \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info View Source class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \" master_image \". If Null assumes last \\ \" master_image \" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def hasher ( self , * args , **kwargs ) : h = [ * args ] h . extend ( list ( kwargs . values ())) h='' . join ([ str ( a ) for a in h ]) return re . sub ( \" [ ^\\d ] \",\"\",h) def ncfile(self,timestamp): return self.filecache / f\" { self . hasher ( timestamp )}. nc \" def config_last_before(self,timestamp): c=self.getActionValues('config',slice(None,timestamp)) try: return c[-1] except Exception as e: return None def config(self, **kwargs): out={} timestamp=kwargs['timestamp'] mapname=self.hasher(timestamp) temp_base_file=kwargs['master_image'] temp_georef_file=kwargs['geo_reference_file'] crs=kwargs['crs'] mapmanager=Multiraster(self.uid,mapname) mapbase = mapmanager.mapcache / mapbasename mapmanager.mapcache.mkdir() \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try: temp_base_name_parts=str(temp_base_file).split(\" . \") #Temporary georef file with open(temp_georef_file) as trf: ''' trying to match reference file type (wld or aux.wml) if exists ''' try: float(trf.readline()) def_georef_file=Path(\" . \".join([*temp_base_name_parts[0:-1],\" wld \"])) except Exception as e: def_georef_file=Path(\" . \".join([*temp_base_name_parts,\" aux \",\" xml \"])) temp_georef_file.replace(def_georef_file) except Exception as e: pass # traceback.print_exc() try: ''' trying to define crs from income parameters ''' crs=rasterio.crs.CRS.from_string(crs) except Exception: crs=None try: with rasterio.open(temp_base_file) as src: meta = src.meta.copy() if crs is not None: meta['crs']=crs meta['transform']=list(meta['transform'])[0:6] try: meta['crs']=meta['crs'].to_string() except AttributeError: meta['crs']=None meta['count']=3 meta['compress']='lzw' meta['dtype']='uint8' if src.count == 1: #trasformare da gray scale a rgb rgb = src.read(1).copy() rgb = (rgb/2**16)*255 rgb = rgb.astype('uint8') rgb = [rgb,rgb,rgb] else: rgb = src.read() minlon,minlat,maxlon,maxlat = transform_bounds(src.crs,'EPSG:4326',*src.bounds) with rasterio.open(mapbase, 'w', **meta) as dst: for i in range(0, rgb.__len__()): dst.write(rgb[i],i+1) bands=dst.meta['count'] outcrs=dst.meta['crs'] outum=outcrs.linear_units #Master_image is ok. Making mapfoile mapmanager.setMFparams(bands=bands,crs=outcrs,um=outum) except Exception as e: raise ValueError(e) x_offset=y_offset=kwargs['window_size_change'] or 0 step_size=kwargs['step_size'] or 1 self._set_map_info({ \" extent \":{ \" minlon \":minlon, \" minlat \":minlat, \" maxlon \":maxlon, \" maxlat \":maxlat, }, \" center \":{ \" lon \":(maxlon+minlon)/2, \" lat \":(maxlat+minlat)/2 }, \" zoom \":{ \" default \":int(20/(sqrt((maxlat-minlat)**2+(maxlon-minlon)**2))) } }) out['master_image']=magic.from_file(str(mapbase)) out['timestamp']=timestamp out['step_size']=step_size out['window_size_change']=x_offset out['meta']=meta x_values=arange(y_offset,meta['width'],step_size)*meta['transform'][0]+meta['transform'][2] y_values=arange(x_offset,meta['height'],step_size)*meta['transform'][4]+meta['transform'][5] self.filecache.mkdir() ncpath=self.ncfile(timestamp) config_NC(ncpath,timestamp,x_values,y_values).close() return out def cleanConfig(self,timestamp): timestamp=self.hasher(timestamp) os.unlink(self.ncfile(timestamp)) Multiraster(self.uid,timestamp).mapcache.rmdir() def feed(self, **kwargs): fileNS=Path(kwargs[\" NS_displacement \"]) fileEW=Path(kwargs[\" EW_displacement \"]) try: fileCORR=Path(kwargs[\" CORR \"]) except Exception as e: fileCORR=None timestamp=kwargs[\" timestamp \"] reftime=self.config_last_before(timestamp)['timestamp'] ncpath=self.ncfile(reftime) frames={\" ns \":None,\" ew \":None,\" corr \":None} frames[\" ns \"] = read_csv(fileNS,header=None) frames[\" ew \"] = read_csv(fileEW,header=None) if fileCORR is None: frames[\" corr \"] = DataFrame(full((frames[\" ns \"].shape),0.99)) else: frames[\" corr \"] = read_csv(fileCORR,header=None) feed_NC(ncpath,timestamp,**frames).close() self._timeline_add(timestamp) return kwargs def cleanFeed(self, timestamp): pass def data( self, times=None, timeref=None, geometry=None, **kwargs): return kwargs def map( self, times=None, timeref=None, geometry=None, output=\" RV \" ): timestamp=None if isinstance(times,slice): timestamp=times.stop else: timestamp=times conf=self.config_last_before(timestamp) reftimestamp=timeref or conf['timestamp'] mapname=self.hasher(reftimestamp) mapmanager= Multiraster(self.uid,mapname) ncfile=self.ncfile(mapname) mapfile=mapmanager.mapfile conf=conf['value'] h=conf['meta']['height'] w=conf['meta']['width'] wsc=int(conf['window_size_change']) imgout=zeros([h,w,4]) timestamp,imagearray=generate_map(ncfile,timestamp=timestamp,timeref=timeref,param=output,step_size=conf['step_size']) imgout[wsc:,wsc:]=imagearray[:h-wsc,:w-wsc] imgname=f\" { mapname } _ { self . hasher ( reftimestamp )} _ { output }. tif \" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] ='LZW' conf [ 'meta' ][ 'driver' ] ='GTiff' conf [ 'meta' ][ 'dtype' ] ='uint8' imagearray = imagearray [ :h - wsc , :w - wsc , 0 :conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , **conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]) : dst . write ( imagearray [ : , : , i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser Ancestors (in MRO) hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC Methods cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass config def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : out= {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback . print_exc () try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] ='lzw' meta [ 'dtype' ] ='uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units # Master_image is ok . Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () return out config_last_before def config_last_before ( self , timestamp ) View Source def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None data def data ( self , times = None , timeref = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), 0 . 99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) map def map ( self , times = None , timeref = None , geometry = None , output = 'RV' ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ] ) imgout = zeros ( [ h,w,4 ] ) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] ) imgout [ wsc:,wsc: ]= imagearray [ :h-wsc,:w-wsc ] imgname = f \"{mapname}_{self.hasher(reftimestamp)}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= 3 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imagearray = imagearray [ :h-wsc,:w-wsc,0:conf['meta' ][ 'count' ] ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ] ) : dst . write ( imagearray [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser ncfile def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"Index"},{"location":"reference/hielen2/ext/source_photomonitoring/#module-hielen2extsource_photomonitoring","text":"View Source # coding=utf-8 __name__ = \"Source_Photomonitoring\" __version__ = \"0.0.1\" __author__ = \"Alessandro Modesti\" __email__ = \"it@img-srl.com\" __description__ = \"HielenSource extensione\" __license__ = \"MIT\" __uri__ = \"\" from .phm import Source , ConfigSchema , FeedSchema __all__ = [ \"Source\" , \"ConfigSchema\" , \"FeedSchema\" ]","title":"Module hielen2.ext.source_photomonitoring"},{"location":"reference/hielen2/ext/source_photomonitoring/#sub-modules","text":"hielen2.ext.source_photomonitoring.phm hielen2.ext.source_photomonitoring.rendering hielen2.ext.source_photomonitoring.struct hielen2.ext.source_photomonitoring.struct_ok","title":"Sub-modules"},{"location":"reference/hielen2/ext/source_photomonitoring/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_photomonitoring/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) 'master_image' (required): the base image used as reference grid for elaboration. It can be any image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image' View Source class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True )","title":"ConfigSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/#ancestors-in-mro","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_image opts step_size window_size_change","title":"Class variables"},{"location":"reference/hielen2/ext/source_photomonitoring/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_photomonitoring/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_photomonitoring/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_photomonitoring/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_photomonitoring/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_photomonitoring/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_photomonitoring/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_photomonitoring/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_photomonitoring/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_photomonitoring/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_photomonitoring/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) reference_time: timestamp of the reference \"master_image\". If Null assumes last \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info View Source class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \" master_image \". If Null assumes last \\ \" master_image \" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/#ancestors-in-mro_1","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/#class-variables_1","text":"CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen2/ext/source_photomonitoring/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_photomonitoring/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_photomonitoring/#instance-variables_1","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_photomonitoring/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_photomonitoring/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_photomonitoring/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_photomonitoring/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_photomonitoring/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_photomonitoring/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_photomonitoring/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_photomonitoring/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def hasher ( self , * args , **kwargs ) : h = [ * args ] h . extend ( list ( kwargs . values ())) h='' . join ([ str ( a ) for a in h ]) return re . sub ( \" [ ^\\d ] \",\"\",h) def ncfile(self,timestamp): return self.filecache / f\" { self . hasher ( timestamp )}. nc \" def config_last_before(self,timestamp): c=self.getActionValues('config',slice(None,timestamp)) try: return c[-1] except Exception as e: return None def config(self, **kwargs): out={} timestamp=kwargs['timestamp'] mapname=self.hasher(timestamp) temp_base_file=kwargs['master_image'] temp_georef_file=kwargs['geo_reference_file'] crs=kwargs['crs'] mapmanager=Multiraster(self.uid,mapname) mapbase = mapmanager.mapcache / mapbasename mapmanager.mapcache.mkdir() \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try: temp_base_name_parts=str(temp_base_file).split(\" . \") #Temporary georef file with open(temp_georef_file) as trf: ''' trying to match reference file type (wld or aux.wml) if exists ''' try: float(trf.readline()) def_georef_file=Path(\" . \".join([*temp_base_name_parts[0:-1],\" wld \"])) except Exception as e: def_georef_file=Path(\" . \".join([*temp_base_name_parts,\" aux \",\" xml \"])) temp_georef_file.replace(def_georef_file) except Exception as e: pass # traceback.print_exc() try: ''' trying to define crs from income parameters ''' crs=rasterio.crs.CRS.from_string(crs) except Exception: crs=None try: with rasterio.open(temp_base_file) as src: meta = src.meta.copy() if crs is not None: meta['crs']=crs meta['transform']=list(meta['transform'])[0:6] try: meta['crs']=meta['crs'].to_string() except AttributeError: meta['crs']=None meta['count']=3 meta['compress']='lzw' meta['dtype']='uint8' if src.count == 1: #trasformare da gray scale a rgb rgb = src.read(1).copy() rgb = (rgb/2**16)*255 rgb = rgb.astype('uint8') rgb = [rgb,rgb,rgb] else: rgb = src.read() minlon,minlat,maxlon,maxlat = transform_bounds(src.crs,'EPSG:4326',*src.bounds) with rasterio.open(mapbase, 'w', **meta) as dst: for i in range(0, rgb.__len__()): dst.write(rgb[i],i+1) bands=dst.meta['count'] outcrs=dst.meta['crs'] outum=outcrs.linear_units #Master_image is ok. Making mapfoile mapmanager.setMFparams(bands=bands,crs=outcrs,um=outum) except Exception as e: raise ValueError(e) x_offset=y_offset=kwargs['window_size_change'] or 0 step_size=kwargs['step_size'] or 1 self._set_map_info({ \" extent \":{ \" minlon \":minlon, \" minlat \":minlat, \" maxlon \":maxlon, \" maxlat \":maxlat, }, \" center \":{ \" lon \":(maxlon+minlon)/2, \" lat \":(maxlat+minlat)/2 }, \" zoom \":{ \" default \":int(20/(sqrt((maxlat-minlat)**2+(maxlon-minlon)**2))) } }) out['master_image']=magic.from_file(str(mapbase)) out['timestamp']=timestamp out['step_size']=step_size out['window_size_change']=x_offset out['meta']=meta x_values=arange(y_offset,meta['width'],step_size)*meta['transform'][0]+meta['transform'][2] y_values=arange(x_offset,meta['height'],step_size)*meta['transform'][4]+meta['transform'][5] self.filecache.mkdir() ncpath=self.ncfile(timestamp) config_NC(ncpath,timestamp,x_values,y_values).close() return out def cleanConfig(self,timestamp): timestamp=self.hasher(timestamp) os.unlink(self.ncfile(timestamp)) Multiraster(self.uid,timestamp).mapcache.rmdir() def feed(self, **kwargs): fileNS=Path(kwargs[\" NS_displacement \"]) fileEW=Path(kwargs[\" EW_displacement \"]) try: fileCORR=Path(kwargs[\" CORR \"]) except Exception as e: fileCORR=None timestamp=kwargs[\" timestamp \"] reftime=self.config_last_before(timestamp)['timestamp'] ncpath=self.ncfile(reftime) frames={\" ns \":None,\" ew \":None,\" corr \":None} frames[\" ns \"] = read_csv(fileNS,header=None) frames[\" ew \"] = read_csv(fileEW,header=None) if fileCORR is None: frames[\" corr \"] = DataFrame(full((frames[\" ns \"].shape),0.99)) else: frames[\" corr \"] = read_csv(fileCORR,header=None) feed_NC(ncpath,timestamp,**frames).close() self._timeline_add(timestamp) return kwargs def cleanFeed(self, timestamp): pass def data( self, times=None, timeref=None, geometry=None, **kwargs): return kwargs def map( self, times=None, timeref=None, geometry=None, output=\" RV \" ): timestamp=None if isinstance(times,slice): timestamp=times.stop else: timestamp=times conf=self.config_last_before(timestamp) reftimestamp=timeref or conf['timestamp'] mapname=self.hasher(reftimestamp) mapmanager= Multiraster(self.uid,mapname) ncfile=self.ncfile(mapname) mapfile=mapmanager.mapfile conf=conf['value'] h=conf['meta']['height'] w=conf['meta']['width'] wsc=int(conf['window_size_change']) imgout=zeros([h,w,4]) timestamp,imagearray=generate_map(ncfile,timestamp=timestamp,timeref=timeref,param=output,step_size=conf['step_size']) imgout[wsc:,wsc:]=imagearray[:h-wsc,:w-wsc] imgname=f\" { mapname } _ { self . hasher ( reftimestamp )} _ { output }. tif \" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] ='LZW' conf [ 'meta' ][ 'driver' ] ='GTiff' conf [ 'meta' ][ 'dtype' ] ='uint8' imagearray = imagearray [ :h - wsc , :w - wsc , 0 :conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , **conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]) : dst . write ( imagearray [ : , : , i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser","title":"Source"},{"location":"reference/hielen2/ext/source_photomonitoring/#ancestors-in-mro_2","text":"hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir ()","title":"cleanConfig"},{"location":"reference/hielen2/ext/source_photomonitoring/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass","title":"cleanFeed"},{"location":"reference/hielen2/ext/source_photomonitoring/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : out= {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback . print_exc () try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] ='lzw' meta [ 'dtype' ] ='uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units # Master_image is ok . Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () return out","title":"config"},{"location":"reference/hielen2/ext/source_photomonitoring/#config_last_before","text":"def config_last_before ( self , timestamp ) View Source def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None","title":"config_last_before"},{"location":"reference/hielen2/ext/source_photomonitoring/#data","text":"def data ( self , times = None , timeref = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs","title":"data"},{"location":"reference/hielen2/ext/source_photomonitoring/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/ext/source_photomonitoring/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/ext/source_photomonitoring/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), 0 . 99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen2/ext/source_photomonitoring/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/ext/source_photomonitoring/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen2/ext/source_photomonitoring/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'RV' ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ] ) imgout = zeros ( [ h,w,4 ] ) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] ) imgout [ wsc:,wsc: ]= imagearray [ :h-wsc,:w-wsc ] imgname = f \"{mapname}_{self.hasher(reftimestamp)}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= 3 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imagearray = imagearray [ :h-wsc,:w-wsc,0:conf['meta' ][ 'count' ] ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ] ) : dst . write ( imagearray [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"map"},{"location":"reference/hielen2/ext/source_photomonitoring/#ncfile","text":"def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"ncfile"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/","text":"Module hielen2.ext.source_photomonitoring.phm View Source # coding=utf-8 from hielen2.source import MapSource , ActionSchema from hielen2.utils import LocalFile from hielen2.mapmanager import Multiraster from numpy import sqrt import rasterio from rasterio.warp import transform_bounds import magic import os import re from pathlib import Path from .struct import config_NC , feed_NC , generate_map from marshmallow import fields from numpy import arange , full , zeros from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback mapbasename = \"basemap.tif\" class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \"master_image\". If Null assumes last \\ \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True ) class Source ( MapSource ): ''' PhotoMonitoring source manager ''' def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) def ncfile ( self , timestamp ): return self . filecache / f \" { self . hasher ( timestamp ) } .nc\" def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None def config ( self , ** kwargs ): out = {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ) . split ( \".\" ) #Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 : - 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback.print_exc() try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ] . to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] = 'lzw' meta [ 'dtype' ] = 'uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ) . copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , ** meta ) as dst : for i in range ( 0 , rgb . __len__ ()): dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units #Master_image is ok. Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _set_map_info ({ \"extent\" :{ \"minlon\" : minlon , \"minlat\" : minlat , \"maxlon\" : maxlon , \"maxlat\" : maxlat , }, \"center\" :{ \"lon\" :( maxlon + minlon ) / 2 , \"lat\" :( maxlat + minlat ) / 2 }, \"zoom\" :{ \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ) . close () return out def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ) . mapcache . rmdir () def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), 0.99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ) . close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ]) imgout = zeros ([ h , w , 4 ]) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ]) imgout [ wsc :, wsc :] = imagearray [: h - wsc ,: w - wsc ] imgname = f \" { mapname } _ { self . hasher ( reftimestamp ) } _ { output } .tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] = 'LZW' conf [ 'meta' ][ 'driver' ] = 'GTiff' conf [ 'meta' ][ 'dtype' ] = 'uint8' imagearray = imagearray [: h - wsc ,: w - wsc , 0 : conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]): dst . write ( imagearray [:,:, i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser Variables mapbasename sqrt Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) 'master_image' (required): the base image used as reference grid for elaboration. It can be any image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image' View Source class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_image opts step_size window_size_change Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) reference_time: timestamp of the reference \"master_image\". If Null assumes last \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info View Source class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \" master_image \". If Null assumes last \\ \" master_image \" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def hasher ( self , * args , **kwargs ) : h = [ * args ] h . extend ( list ( kwargs . values ())) h='' . join ([ str ( a ) for a in h ]) return re . sub ( \" [ ^\\d ] \",\"\",h) def ncfile(self,timestamp): return self.filecache / f\" { self . hasher ( timestamp )}. nc \" def config_last_before(self,timestamp): c=self.getActionValues('config',slice(None,timestamp)) try: return c[-1] except Exception as e: return None def config(self, **kwargs): out={} timestamp=kwargs['timestamp'] mapname=self.hasher(timestamp) temp_base_file=kwargs['master_image'] temp_georef_file=kwargs['geo_reference_file'] crs=kwargs['crs'] mapmanager=Multiraster(self.uid,mapname) mapbase = mapmanager.mapcache / mapbasename mapmanager.mapcache.mkdir() \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try: temp_base_name_parts=str(temp_base_file).split(\" . \") #Temporary georef file with open(temp_georef_file) as trf: ''' trying to match reference file type (wld or aux.wml) if exists ''' try: float(trf.readline()) def_georef_file=Path(\" . \".join([*temp_base_name_parts[0:-1],\" wld \"])) except Exception as e: def_georef_file=Path(\" . \".join([*temp_base_name_parts,\" aux \",\" xml \"])) temp_georef_file.replace(def_georef_file) except Exception as e: pass # traceback.print_exc() try: ''' trying to define crs from income parameters ''' crs=rasterio.crs.CRS.from_string(crs) except Exception: crs=None try: with rasterio.open(temp_base_file) as src: meta = src.meta.copy() if crs is not None: meta['crs']=crs meta['transform']=list(meta['transform'])[0:6] try: meta['crs']=meta['crs'].to_string() except AttributeError: meta['crs']=None meta['count']=3 meta['compress']='lzw' meta['dtype']='uint8' if src.count == 1: #trasformare da gray scale a rgb rgb = src.read(1).copy() rgb = (rgb/2**16)*255 rgb = rgb.astype('uint8') rgb = [rgb,rgb,rgb] else: rgb = src.read() minlon,minlat,maxlon,maxlat = transform_bounds(src.crs,'EPSG:4326',*src.bounds) with rasterio.open(mapbase, 'w', **meta) as dst: for i in range(0, rgb.__len__()): dst.write(rgb[i],i+1) bands=dst.meta['count'] outcrs=dst.meta['crs'] outum=outcrs.linear_units #Master_image is ok. Making mapfoile mapmanager.setMFparams(bands=bands,crs=outcrs,um=outum) except Exception as e: raise ValueError(e) x_offset=y_offset=kwargs['window_size_change'] or 0 step_size=kwargs['step_size'] or 1 self._set_map_info({ \" extent \":{ \" minlon \":minlon, \" minlat \":minlat, \" maxlon \":maxlon, \" maxlat \":maxlat, }, \" center \":{ \" lon \":(maxlon+minlon)/2, \" lat \":(maxlat+minlat)/2 }, \" zoom \":{ \" default \":int(20/(sqrt((maxlat-minlat)**2+(maxlon-minlon)**2))) } }) out['master_image']=magic.from_file(str(mapbase)) out['timestamp']=timestamp out['step_size']=step_size out['window_size_change']=x_offset out['meta']=meta x_values=arange(y_offset,meta['width'],step_size)*meta['transform'][0]+meta['transform'][2] y_values=arange(x_offset,meta['height'],step_size)*meta['transform'][4]+meta['transform'][5] self.filecache.mkdir() ncpath=self.ncfile(timestamp) config_NC(ncpath,timestamp,x_values,y_values).close() return out def cleanConfig(self,timestamp): timestamp=self.hasher(timestamp) os.unlink(self.ncfile(timestamp)) Multiraster(self.uid,timestamp).mapcache.rmdir() def feed(self, **kwargs): fileNS=Path(kwargs[\" NS_displacement \"]) fileEW=Path(kwargs[\" EW_displacement \"]) try: fileCORR=Path(kwargs[\" CORR \"]) except Exception as e: fileCORR=None timestamp=kwargs[\" timestamp \"] reftime=self.config_last_before(timestamp)['timestamp'] ncpath=self.ncfile(reftime) frames={\" ns \":None,\" ew \":None,\" corr \":None} frames[\" ns \"] = read_csv(fileNS,header=None) frames[\" ew \"] = read_csv(fileEW,header=None) if fileCORR is None: frames[\" corr \"] = DataFrame(full((frames[\" ns \"].shape),0.99)) else: frames[\" corr \"] = read_csv(fileCORR,header=None) feed_NC(ncpath,timestamp,**frames).close() self._timeline_add(timestamp) return kwargs def cleanFeed(self, timestamp): pass def data( self, times=None, timeref=None, geometry=None, **kwargs): return kwargs def map( self, times=None, timeref=None, geometry=None, output=\" RV \" ): timestamp=None if isinstance(times,slice): timestamp=times.stop else: timestamp=times conf=self.config_last_before(timestamp) reftimestamp=timeref or conf['timestamp'] mapname=self.hasher(reftimestamp) mapmanager= Multiraster(self.uid,mapname) ncfile=self.ncfile(mapname) mapfile=mapmanager.mapfile conf=conf['value'] h=conf['meta']['height'] w=conf['meta']['width'] wsc=int(conf['window_size_change']) imgout=zeros([h,w,4]) timestamp,imagearray=generate_map(ncfile,timestamp=timestamp,timeref=timeref,param=output,step_size=conf['step_size']) imgout[wsc:,wsc:]=imagearray[:h-wsc,:w-wsc] imgname=f\" { mapname } _ { self . hasher ( reftimestamp )} _ { output }. tif \" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] ='LZW' conf [ 'meta' ][ 'driver' ] ='GTiff' conf [ 'meta' ][ 'dtype' ] ='uint8' imagearray = imagearray [ :h - wsc , :w - wsc , 0 :conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , **conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]) : dst . write ( imagearray [ : , : , i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser Ancestors (in MRO) hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC Methods cleanConfig def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir () cleanFeed def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass config def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : out= {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback . print_exc () try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] ='lzw' meta [ 'dtype' ] ='uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units # Master_image is ok . Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () return out config_last_before def config_last_before ( self , timestamp ) View Source def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None data def data ( self , times = None , timeref = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), 0 . 99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out hasher def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) map def map ( self , times = None , timeref = None , geometry = None , output = 'RV' ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ] ) imgout = zeros ( [ h,w,4 ] ) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] ) imgout [ wsc:,wsc: ]= imagearray [ :h-wsc,:w-wsc ] imgname = f \"{mapname}_{self.hasher(reftimestamp)}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= 3 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imagearray = imagearray [ :h-wsc,:w-wsc,0:conf['meta' ][ 'count' ] ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ] ) : dst . write ( imagearray [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser ncfile def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"Phm"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#module-hielen2extsource_photomonitoringphm","text":"View Source # coding=utf-8 from hielen2.source import MapSource , ActionSchema from hielen2.utils import LocalFile from hielen2.mapmanager import Multiraster from numpy import sqrt import rasterio from rasterio.warp import transform_bounds import magic import os import re from pathlib import Path from .struct import config_NC , feed_NC , generate_map from marshmallow import fields from numpy import arange , full , zeros from pandas import read_csv , DataFrame , Series , DatetimeIndex import traceback mapbasename = \"basemap.tif\" class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \"master_image\". If Null assumes last \\ \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True ) class Source ( MapSource ): ''' PhotoMonitoring source manager ''' def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h ) def ncfile ( self , timestamp ): return self . filecache / f \" { self . hasher ( timestamp ) } .nc\" def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None def config ( self , ** kwargs ): out = {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ) . split ( \".\" ) #Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 : - 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback.print_exc() try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ] . to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] = 'lzw' meta [ 'dtype' ] = 'uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ) . copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , ** meta ) as dst : for i in range ( 0 , rgb . __len__ ()): dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units #Master_image is ok. Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _set_map_info ({ \"extent\" :{ \"minlon\" : minlon , \"minlat\" : minlat , \"maxlon\" : maxlon , \"maxlat\" : maxlat , }, \"center\" :{ \"lon\" :( maxlon + minlon ) / 2 , \"lat\" :( maxlat + minlat ) / 2 }, \"zoom\" :{ \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ) . close () return out def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ) . mapcache . rmdir () def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ] . shape ), 0.99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ) . close () self . _timeline_add ( timestamp ) return kwargs def cleanFeed ( self , timestamp ): pass def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ): timestamp = None if isinstance ( times , slice ): timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ]) imgout = zeros ([ h , w , 4 ]) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ]) imgout [ wsc :, wsc :] = imagearray [: h - wsc ,: w - wsc ] imgname = f \" { mapname } _ { self . hasher ( reftimestamp ) } _ { output } .tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] = 'LZW' conf [ 'meta' ][ 'driver' ] = 'GTiff' conf [ 'meta' ][ 'dtype' ] = 'uint8' imagearray = imagearray [: h - wsc ,: w - wsc , 0 : conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]): dst . write ( imagearray [:,:, i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser","title":"Module hielen2.ext.source_photomonitoring.phm"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#variables","text":"mapbasename sqrt","title":"Variables"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) 'master_image' (required): the base image used as reference grid for elaboration. It can be any image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent elaboration images. It can be a standard world file (six lines text file) according to http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the 'geo_regerence_file' and/or embeded into the 'master_image' View Source class ConfigSchema ( ActionSchema ): \"\"\"'master_image' (required): the base image used as reference grid for elaboration. It can be any \\ image format managed by rasterio pyhton library (GeoTIFF, jpeg, ...). Any elaboration image based \\ on the 'master_image' will share geometry and reference system with it. 'step_size': Pixels sub samplig ratio expected for the elaboration grids compared to 'master_image'. \\ (see Feed Action) 'windows_size_change': Pixel expressed, upper-left corner position (both vertical and orizontal) expected \\ for the overlaying elaboration grids starting from the upper-left corner of the 'master_image' 'geo_reference_file': Reference file for the geolocalization of the 'master_image' and all the dependent \\ elaboration images. It can be a standard world file (six lines text file) according to \\ http://www.kralidis.ca/gis/worldfile.htm, as well an '.aux.xml' file according to \\ https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/auxiliary-files.htm \\ (just the Coordinate system, the Transformation and the Projection informations are here managed). IMPORTANT: When a valid 'geo_regerence_file' is provided, therein informations overwrite the ones \\ possibly embedded into the 'master_image' 'crs': the Coordinate Reference System of the master_image in the string form 'autority:code' \\ (i.e.: 'EPSG:3857'). IMPORTANT: If a valid 'crs' is provided, this value overwrites the ones possibly provided with the \\ 'geo_regerence_file' and/or embeded into the 'master_image' \"\"\" master_image = LocalFile ( required = True , allow_none = False ) step_size = fields . Number ( required = False , default = 1 , allow_none = True , as_string = False ) window_size_change = fields . Number ( required = False , default = 0 , allow_none = True , as_string = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True )","title":"ConfigSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#ancestors-in-mro","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_image opts step_size window_size_change","title":"Class variables"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) reference_time: timestamp of the reference \"master_image\". If Null assumes last \"master_image\" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info View Source class FeedSchema ( ActionSchema ): \"\"\"reference_time: timestamp of the reference \" master_image \". If Null assumes last \\ \" master_image \" configured. NS_displacement: textfile containing the grid of the North-South displacement. EW_displacement: textfile containing the grid of the East-Weast displacement. CORR: textfile containing the grid of the coerence info \"\"\" NS_displacement = LocalFile ( required = True , allow_none = False ) EW_displacement = LocalFile ( required = True , allow_none = False ) CORR = LocalFile ( required = False , allow_none = True )","title":"FeedSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#ancestors-in-mro_1","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#class-variables_1","text":"CORR EW_displacement Meta NS_displacement OPTIONS_CLASS TYPE_MAPPING error_messages opts","title":"Class variables"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#instance-variables_1","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#source","text":"class Source ( feature ) PhotoMonitoring source manager View Source class Source ( MapSource ) : ''' PhotoMonitoring source manager ''' def hasher ( self , * args , **kwargs ) : h = [ * args ] h . extend ( list ( kwargs . values ())) h='' . join ([ str ( a ) for a in h ]) return re . sub ( \" [ ^\\d ] \",\"\",h) def ncfile(self,timestamp): return self.filecache / f\" { self . hasher ( timestamp )}. nc \" def config_last_before(self,timestamp): c=self.getActionValues('config',slice(None,timestamp)) try: return c[-1] except Exception as e: return None def config(self, **kwargs): out={} timestamp=kwargs['timestamp'] mapname=self.hasher(timestamp) temp_base_file=kwargs['master_image'] temp_georef_file=kwargs['geo_reference_file'] crs=kwargs['crs'] mapmanager=Multiraster(self.uid,mapname) mapbase = mapmanager.mapcache / mapbasename mapmanager.mapcache.mkdir() \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try: temp_base_name_parts=str(temp_base_file).split(\" . \") #Temporary georef file with open(temp_georef_file) as trf: ''' trying to match reference file type (wld or aux.wml) if exists ''' try: float(trf.readline()) def_georef_file=Path(\" . \".join([*temp_base_name_parts[0:-1],\" wld \"])) except Exception as e: def_georef_file=Path(\" . \".join([*temp_base_name_parts,\" aux \",\" xml \"])) temp_georef_file.replace(def_georef_file) except Exception as e: pass # traceback.print_exc() try: ''' trying to define crs from income parameters ''' crs=rasterio.crs.CRS.from_string(crs) except Exception: crs=None try: with rasterio.open(temp_base_file) as src: meta = src.meta.copy() if crs is not None: meta['crs']=crs meta['transform']=list(meta['transform'])[0:6] try: meta['crs']=meta['crs'].to_string() except AttributeError: meta['crs']=None meta['count']=3 meta['compress']='lzw' meta['dtype']='uint8' if src.count == 1: #trasformare da gray scale a rgb rgb = src.read(1).copy() rgb = (rgb/2**16)*255 rgb = rgb.astype('uint8') rgb = [rgb,rgb,rgb] else: rgb = src.read() minlon,minlat,maxlon,maxlat = transform_bounds(src.crs,'EPSG:4326',*src.bounds) with rasterio.open(mapbase, 'w', **meta) as dst: for i in range(0, rgb.__len__()): dst.write(rgb[i],i+1) bands=dst.meta['count'] outcrs=dst.meta['crs'] outum=outcrs.linear_units #Master_image is ok. Making mapfoile mapmanager.setMFparams(bands=bands,crs=outcrs,um=outum) except Exception as e: raise ValueError(e) x_offset=y_offset=kwargs['window_size_change'] or 0 step_size=kwargs['step_size'] or 1 self._set_map_info({ \" extent \":{ \" minlon \":minlon, \" minlat \":minlat, \" maxlon \":maxlon, \" maxlat \":maxlat, }, \" center \":{ \" lon \":(maxlon+minlon)/2, \" lat \":(maxlat+minlat)/2 }, \" zoom \":{ \" default \":int(20/(sqrt((maxlat-minlat)**2+(maxlon-minlon)**2))) } }) out['master_image']=magic.from_file(str(mapbase)) out['timestamp']=timestamp out['step_size']=step_size out['window_size_change']=x_offset out['meta']=meta x_values=arange(y_offset,meta['width'],step_size)*meta['transform'][0]+meta['transform'][2] y_values=arange(x_offset,meta['height'],step_size)*meta['transform'][4]+meta['transform'][5] self.filecache.mkdir() ncpath=self.ncfile(timestamp) config_NC(ncpath,timestamp,x_values,y_values).close() return out def cleanConfig(self,timestamp): timestamp=self.hasher(timestamp) os.unlink(self.ncfile(timestamp)) Multiraster(self.uid,timestamp).mapcache.rmdir() def feed(self, **kwargs): fileNS=Path(kwargs[\" NS_displacement \"]) fileEW=Path(kwargs[\" EW_displacement \"]) try: fileCORR=Path(kwargs[\" CORR \"]) except Exception as e: fileCORR=None timestamp=kwargs[\" timestamp \"] reftime=self.config_last_before(timestamp)['timestamp'] ncpath=self.ncfile(reftime) frames={\" ns \":None,\" ew \":None,\" corr \":None} frames[\" ns \"] = read_csv(fileNS,header=None) frames[\" ew \"] = read_csv(fileEW,header=None) if fileCORR is None: frames[\" corr \"] = DataFrame(full((frames[\" ns \"].shape),0.99)) else: frames[\" corr \"] = read_csv(fileCORR,header=None) feed_NC(ncpath,timestamp,**frames).close() self._timeline_add(timestamp) return kwargs def cleanFeed(self, timestamp): pass def data( self, times=None, timeref=None, geometry=None, **kwargs): return kwargs def map( self, times=None, timeref=None, geometry=None, output=\" RV \" ): timestamp=None if isinstance(times,slice): timestamp=times.stop else: timestamp=times conf=self.config_last_before(timestamp) reftimestamp=timeref or conf['timestamp'] mapname=self.hasher(reftimestamp) mapmanager= Multiraster(self.uid,mapname) ncfile=self.ncfile(mapname) mapfile=mapmanager.mapfile conf=conf['value'] h=conf['meta']['height'] w=conf['meta']['width'] wsc=int(conf['window_size_change']) imgout=zeros([h,w,4]) timestamp,imagearray=generate_map(ncfile,timestamp=timestamp,timeref=timeref,param=output,step_size=conf['step_size']) imgout[wsc:,wsc:]=imagearray[:h-wsc,:w-wsc] imgname=f\" { mapname } _ { self . hasher ( reftimestamp )} _ { output }. tif \" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ] = 3 conf [ 'meta' ][ 'compress' ] ='LZW' conf [ 'meta' ][ 'driver' ] ='GTiff' conf [ 'meta' ][ 'dtype' ] ='uint8' imagearray = imagearray [ :h - wsc , :w - wsc , 0 :conf [ 'meta' ][ 'count' ]] with rasterio . open ( path_image , 'w' , **conf [ 'meta' ]) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ]) : dst . write ( imagearray [ : , : , i ], i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ([ url ], index = DatetimeIndex ([ timestamp ])) return ser","title":"Source"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#ancestors-in-mro_2","text":"hielen2.source.MapSource hielen2.source.DataSource hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#cleanconfig","text":"def cleanConfig ( self , timestamp ) View Source def cleanConfig ( self , timestamp ): timestamp = self . hasher ( timestamp ) os . unlink ( self . ncfile ( timestamp )) Multiraster ( self . uid , timestamp ). mapcache . rmdir ()","title":"cleanConfig"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#cleanfeed","text":"def cleanFeed ( self , timestamp ) View Source def cleanFeed ( self , timestamp ): pass","title":"cleanFeed"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , **kwargs ) : out= {} timestamp = kwargs [ 'timestamp' ] mapname = self . hasher ( timestamp ) temp_base_file = kwargs [ 'master_image' ] temp_georef_file = kwargs [ 'geo_reference_file' ] crs = kwargs [ 'crs' ] mapmanager = Multiraster ( self . uid , mapname ) mapbase = mapmanager . mapcache / mapbasename mapmanager . mapcache . mkdir () \"\"\" associo il file dei riferimenti se esite a quello dei dati \"\"\" try : temp_base_name_parts = str ( temp_base_file ). split ( \".\" ) # Temporary georef file with open ( temp_georef_file ) as trf : ''' trying to match reference file type (wld or aux.wml) if exists ''' try : float ( trf . readline ()) def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts [ 0 :- 1 ], \"wld\" ])) except Exception as e : def_georef_file = Path ( \".\" . join ([ * temp_base_name_parts , \"aux\" , \"xml\" ])) temp_georef_file . replace ( def_georef_file ) except Exception as e : pass # traceback . print_exc () try : ''' trying to define crs from income parameters ''' crs = rasterio . crs . CRS . from_string ( crs ) except Exception : crs = None try : with rasterio . open ( temp_base_file ) as src : meta = src . meta . copy () if crs is not None : meta [ 'crs' ] = crs meta [ 'transform' ] = list ( meta [ 'transform' ])[ 0 : 6 ] try : meta [ 'crs' ] = meta [ 'crs' ]. to_string () except AttributeError : meta [ 'crs' ] = None meta [ 'count' ] = 3 meta [ 'compress' ] ='lzw' meta [ 'dtype' ] ='uint8' if src . count == 1 : #trasformare da gray scale a rgb rgb = src . read ( 1 ). copy () rgb = ( rgb / 2 ** 16 ) * 255 rgb = rgb . astype ( 'uint8' ) rgb = [ rgb , rgb , rgb ] else : rgb = src . read () minlon , minlat , maxlon , maxlat = transform_bounds ( src . crs , 'EPSG:4326' , * src . bounds ) with rasterio . open ( mapbase , 'w' , **meta ) as dst : for i in range ( 0 , rgb . __ len__ ()) : dst . write ( rgb [ i ], i + 1 ) bands = dst . meta [ 'count' ] outcrs = dst . meta [ 'crs' ] outum = outcrs . linear_units # Master_image is ok . Making mapfoile mapmanager . setMFparams ( bands = bands , crs = outcrs , um = outum ) except Exception as e : raise ValueError ( e ) x_offset = y_offset = kwargs [ 'window_size_change' ] or 0 step_size = kwargs [ 'step_size' ] or 1 self . _ set_map_info ({ \"extent\" : { \"minlon\" :minlon , \"minlat\" :minlat , \"maxlon\" :maxlon , \"maxlat\" :maxlat , }, \"center\" : { \"lon\" : ( maxlon + minlon ) / 2 , \"lat\" : ( maxlat + minlat ) / 2 }, \"zoom\" : { \"default\" : int ( 20 / ( sqrt (( maxlat - minlat ) ** 2 + ( maxlon - minlon ) ** 2 ))) } }) out [ 'master_image' ] = magic . from_file ( str ( mapbase )) out [ 'timestamp' ] = timestamp out [ 'step_size' ] = step_size out [ 'window_size_change' ] = x_offset out [ 'meta' ] = meta x_values = arange ( y_offset , meta [ 'width' ], step_size ) * meta [ 'transform' ][ 0 ] + meta [ 'transform' ][ 2 ] y_values = arange ( x_offset , meta [ 'height' ], step_size ) * meta [ 'transform' ][ 4 ] + meta [ 'transform' ][ 5 ] self . filecache . mkdir () ncpath = self . ncfile ( timestamp ) config_NC ( ncpath , timestamp , x_values , y_values ). close () return out","title":"config"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#config_last_before","text":"def config_last_before ( self , timestamp ) View Source def config_last_before ( self , timestamp ): c = self . getActionValues ( 'config' , slice ( None , timestamp )) try : return c [ - 1 ] except Exception as e : return None","title":"config_last_before"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#data","text":"def data ( self , times = None , timeref = None , geometry = None , ** kwargs ) View Source def data ( self , times = None , timeref = None , geometry = None , ** kwargs ): return kwargs","title":"data"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): fileNS = Path ( kwargs [ \"NS_displacement\" ]) fileEW = Path ( kwargs [ \"EW_displacement\" ]) try : fileCORR = Path ( kwargs [ \"CORR\" ]) except Exception as e : fileCORR = None timestamp = kwargs [ \"timestamp\" ] reftime = self . config_last_before ( timestamp )[ 'timestamp' ] ncpath = self . ncfile ( reftime ) frames = { \"ns\" : None , \"ew\" : None , \"corr\" : None } frames [ \"ns\" ] = read_csv ( fileNS , header = None ) frames [ \"ew\" ] = read_csv ( fileEW , header = None ) if fileCORR is None : frames [ \"corr\" ] = DataFrame ( full (( frames [ \"ns\" ]. shape ), 0 . 99 )) else : frames [ \"corr\" ] = read_csv ( fileCORR , header = None ) feed_NC ( ncpath , timestamp , ** frames ). close () self . _timeline_add ( timestamp ) return kwargs","title":"feed"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#hasher","text":"def hasher ( self , * args , ** kwargs ) View Source def hasher ( self , * args , ** kwargs ): h = [ * args ] h . extend ( list ( kwargs . values ())) h = '' . join ([ str ( a ) for a in h ]) return re . sub ( \"[^\\d]\" , \"\" , h )","title":"hasher"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#map","text":"def map ( self , times = None , timeref = None , geometry = None , output = 'RV' ) View Source def map ( self , times = None , timeref = None , geometry = None , output = \"RV\" ) : timestamp = None if isinstance ( times , slice ) : timestamp = times . stop else : timestamp = times conf = self . config_last_before ( timestamp ) reftimestamp = timeref or conf [ 'timestamp' ] mapname = self . hasher ( reftimestamp ) mapmanager = Multiraster ( self . uid , mapname ) ncfile = self . ncfile ( mapname ) mapfile = mapmanager . mapfile conf = conf [ 'value' ] h = conf [ 'meta' ][ 'height' ] w = conf [ 'meta' ][ 'width' ] wsc = int ( conf [ 'window_size_change' ] ) imgout = zeros ( [ h,w,4 ] ) timestamp , imagearray = generate_map ( ncfile , timestamp = timestamp , timeref = timeref , param = output , step_size = conf [ 'step_size' ] ) imgout [ wsc:,wsc: ]= imagearray [ :h-wsc,:w-wsc ] imgname = f \"{mapname}_{self.hasher(reftimestamp)}_{output}.tif\" path_image = mapmanager . mapcache / imgname conf [ 'meta' ][ 'count' ]= 3 conf [ 'meta' ][ 'compress' ]= 'LZW' conf [ 'meta' ][ 'driver' ]= 'GTiff' conf [ 'meta' ][ 'dtype' ]= 'uint8' imagearray = imagearray [ :h-wsc,:w-wsc,0:conf['meta' ][ 'count' ] ] with rasterio . open ( path_image , 'w' , ** conf [ 'meta' ] ) as dst : for i in range ( 0 , conf [ 'meta' ][ 'count' ] ) : dst . write ( imagearray [ :,:,i ] , i + 1 ) url = mapmanager . geturl ( imgname ) ser = Series ( [ url ] , index = DatetimeIndex ( [ timestamp ] )) return ser","title":"map"},{"location":"reference/hielen2/ext/source_photomonitoring/phm/#ncfile","text":"def ncfile ( self , timestamp ) View Source def ncfile ( self , timestamp ): return self . filecache / f \"{self.hasher(timestamp)}.nc\"","title":"ncfile"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/","text":"Module hielen2.ext.source_photomonitoring.rendering View Source # coding: utf-8 import numpy as np import matplotlib.pyplot as plt import xarray as xr , datetime import scipy.ndimage as snd import pandas as pd from matplotlib.colors import LinearSegmentedColormap def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t class Render (): def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ): self . dataset = xr . open_dataset ( targetfile ) self . gridratio = gridratio #CASS METHOD def _open_matrix ( ns = None , ew = None , corr = None , output = \"RV\" , gridratio = 8 ): ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di coerenza e faccio zoom if corr is not None : ns = ns . where ( corr >= 0 ) ew = ew . where ( corr >= 0 ) if output in ( \"RV\" , \"R\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if output in ( \"EW\" ): h = ew if output in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , gridratio , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), gridratio , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _print_image ( heatmap = None , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 , dims = None ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = dims [ 1 ] #+64 H = dims [ 0 ] #+64 dpi = 72 plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = dpi fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () if heatmap is not None : ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] return data @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def generate_map ( self , timestamp = None , timeref = None , output = \"RV\" ): timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ] . values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ): dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ): colors = [ \"blue\" , \"green\" , \"red\" ] vmin =- 2.5 vmax = 2.5 managed = Render . _open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _print_image ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t Classes Render class Render ( targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) View Source class Render () : def __ init__ ( self , targetfile='./incomes/sag.nc' , gridratio = 8 , **kwargs ) : self . dataset = xr . open_dataset ( targetfile ) self . gridratio = gridratio # CASS METHOD def _ open_matrix ( ns = None , ew = None , corr = None , output= \"RV\" , gridratio = 8 ) : ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di coerenza e faccio zoom if corr is not None : ns = ns . where ( corr >= 0 ) ew = ew . where ( corr >= 0 ) if output in ( \"RV\" , \"R\" , \"V\" ) : h = np . sqrt ( ns** 2 + ew** 2 ) if output in ( \"EW\" ) : h = ew if output in ( \"NS\" ) : h = ns # upsampling h = snd . zoom ( h , gridratio , order = 0 , mode='nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ) : return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), gridratio , order = 0 , mode='nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 # CON MEDIA # https : // stackoverflow . com / questions / 52886703 / xarray - multidimensional - binning - array - reduction - on - sample - dataset - of - 4 - x4 - to coeff = heatmap . rolling ( x = rollingside ). construct ( 'tmp' ). isel ( x = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ). construct ( 'tmp' ). isel ( y = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ). construct ( 'tmp' ). isel ( x = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ). construct ( 'tmp' ). isel ( y = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) # SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro ** ARBITRARIAMENTE ** quelli che superano il 2 sigma # coeff = coeff . where ( coeff < coeff . mean () + coeff . std () * 2 ) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ) : heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors= ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _ print_image ( heatmap = None , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 , dims = None ) : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = dims [ 1 ] #+ 64 H = dims [ 0 ] #+ 64 dpi = 72 plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = dpi fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor= \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () if heatmap is not None : ax . imshow ( heatmap , alpha = 0.20 , origin='upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color='white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[ ::- 1 ] + ( 4 ,))[ : , : , [ 3 , 2 , 1 , 0 ]] return data @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def generate_map ( self , timestamp = None , timeref = None , output= \"RV\" ) : timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ]. values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ) : dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ) : colors = [ \"blue\" , \"green\" , \"red\" ] vmin=- 2.5 vmax = 2.5 managed = Render . _ open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _ print_image ( **managed , colors = colors , vmin = vmin , vmax = vmax ) def extract_data ( self , geom= ( 0 , 0 ), timefrom = None , timeto = None , output= \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method='nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method='nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns** 2 + dst . ew** 2 ) if output in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out Instance variables reftime timeline Methods extract_data def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out generate_map def generate_map ( self , timestamp = None , timeref = None , output = 'RV' ) View Source def generate_map ( self , timestamp = None , timeref = None , output = \"RV\" ): timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ]. values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ): dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ): colors = [ \"blue\" , \"green\" , \"red\" ] vmin =- 2 . 5 vmax = 2 . 5 managed = Render . _open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _print_image ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) isbasetime def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"Rendering"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#module-hielen2extsource_photomonitoringrendering","text":"View Source # coding: utf-8 import numpy as np import matplotlib.pyplot as plt import xarray as xr , datetime import scipy.ndimage as snd import pandas as pd from matplotlib.colors import LinearSegmentedColormap def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t class Render (): def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ): self . dataset = xr . open_dataset ( targetfile ) self . gridratio = gridratio #CASS METHOD def _open_matrix ( ns = None , ew = None , corr = None , output = \"RV\" , gridratio = 8 ): ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di coerenza e faccio zoom if corr is not None : ns = ns . where ( corr >= 0 ) ew = ew . where ( corr >= 0 ) if output in ( \"RV\" , \"R\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if output in ( \"EW\" ): h = ew if output in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , gridratio , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), gridratio , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _print_image ( heatmap = None , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 , dims = None ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = dims [ 1 ] #+64 H = dims [ 0 ] #+64 dpi = 72 plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = dpi fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () if heatmap is not None : ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] return data @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def generate_map ( self , timestamp = None , timeref = None , output = \"RV\" ): timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ] . values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ): dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ): colors = [ \"blue\" , \"green\" , \"red\" ] vmin =- 2.5 vmax = 2.5 managed = Render . _open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _print_image ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out","title":"Module hielen2.ext.source_photomonitoring.rendering"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#render","text":"class Render ( targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) View Source class Render () : def __ init__ ( self , targetfile='./incomes/sag.nc' , gridratio = 8 , **kwargs ) : self . dataset = xr . open_dataset ( targetfile ) self . gridratio = gridratio # CASS METHOD def _ open_matrix ( ns = None , ew = None , corr = None , output= \"RV\" , gridratio = 8 ) : ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di coerenza e faccio zoom if corr is not None : ns = ns . where ( corr >= 0 ) ew = ew . where ( corr >= 0 ) if output in ( \"RV\" , \"R\" , \"V\" ) : h = np . sqrt ( ns** 2 + ew** 2 ) if output in ( \"EW\" ) : h = ew if output in ( \"NS\" ) : h = ns # upsampling h = snd . zoom ( h , gridratio , order = 0 , mode='nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ) : return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), gridratio , order = 0 , mode='nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 # CON MEDIA # https : // stackoverflow . com / questions / 52886703 / xarray - multidimensional - binning - array - reduction - on - sample - dataset - of - 4 - x4 - to coeff = heatmap . rolling ( x = rollingside ). construct ( 'tmp' ). isel ( x = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ). construct ( 'tmp' ). isel ( y = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ). construct ( 'tmp' ). isel ( x = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ). construct ( 'tmp' ). isel ( y = slice ( 1 , None , rollingside )). mean ( 'tmp' , skipna = False ) # SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro ** ARBITRARIAMENTE ** quelli che superano il 2 sigma # coeff = coeff . where ( coeff < coeff . mean () + coeff . std () * 2 ) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ) : heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors= ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _ print_image ( heatmap = None , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 , dims = None ) : cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = dims [ 1 ] #+ 64 H = dims [ 0 ] #+ 64 dpi = 72 plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = dpi fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor= \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () if heatmap is not None : ax . imshow ( heatmap , alpha = 0.20 , origin='upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color='white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[ ::- 1 ] + ( 4 ,))[ : , : , [ 3 , 2 , 1 , 0 ]] return data @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def generate_map ( self , timestamp = None , timeref = None , output= \"RV\" ) : timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ]. values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ) : dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ) : colors = [ \"blue\" , \"green\" , \"red\" ] vmin=- 2.5 vmax = 2.5 managed = Render . _ open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _ print_image ( **managed , colors = colors , vmin = vmin , vmax = vmax ) def extract_data ( self , geom= ( 0 , 0 ), timefrom = None , timeto = None , output= \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method='nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method='nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns** 2 + dst . ew** 2 ) if output in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out","title":"Render"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#instance-variables","text":"reftime timeline","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#extract_data","text":"def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out","title":"extract_data"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#generate_map","text":"def generate_map ( self , timestamp = None , timeref = None , output = 'RV' ) View Source def generate_map ( self , timestamp = None , timeref = None , output = \"RV\" ): timestamp = agoodtime ( timestamp ) timeref = agoodtime ( timeref ) if timestamp is None : timestamp = str ( self . dataset . time [ - 1 ]. values ) dataset = self . dataset . sel ( time = timestamp ) corr = dataset . corr if timeref is not None and not self . isbasetime ( timeref ): dataref = self . dataset . sel ( time = timeref ) dataset = dataset - dataref corr = None colors = [ \"green\" , \"red\" , \"blue\" ] vmin = 0 vmax = 5 if output in ( \"NS\" , \"EW\" ): colors = [ \"blue\" , \"green\" , \"red\" ] vmin =- 2 . 5 vmax = 2 . 5 managed = Render . _open_matrix ( ns = dataset . ns , ew = dataset . ew , corr = corr , output = output , gridratio = self . gridratio ) return Render . _print_image ( ** managed , colors = colors , vmin = vmin , vmax = vmax )","title":"generate_map"},{"location":"reference/hielen2/ext/source_photomonitoring/rendering/#isbasetime","text":"def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"isbasetime"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/","text":"Module hielen2.ext.source_photomonitoring.struct View Source # coding: utf-8 import numpy as np import pandas as pd import matplotlib matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap import xarray as xr , datetime import scipy.ndimage as snd import re from netCDF4 import Dataset , date2num import os import PIL def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = 1 , param = \"RV\" ): ''' params dataset: dataset at fixed time param: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa ns = dataset . ns ew = dataset . ew if param in ( \"D\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if param in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 6 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / ( coeff . mean () * 4 ) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( np . abs ( coeff ) > np . abs ( coeff . mean ())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if param in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] plt . close () return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ): if timestamp is None : pass if param is None : param = \"R\" if step_size is None : stap_size = 1 if colors is None : colors = [ \"red\" , \"green\" , \"blue\" ] if vmin is None : vmin =- 150 if vmax is None : vmax = 150 dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) ds1 = ds1 . where ( ds1 . corr > 0 ) if timeref is not None : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds2 = ds2 . where ( ds2 . corr > 0 ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size ) return [ timestamp , _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax )] class Render (): @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if param in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ): out = dst . ns if param in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t config_NC def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset feed_NC def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset generate_map def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ): if timestamp is None : pass if param is None : param = \"R\" if step_size is None : stap_size = 1 if colors is None : colors = [ \"red\" , \"green\" , \"blue\" ] if vmin is None : vmin =- 150 if vmax is None : vmax = 150 dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) ds1 = ds1 . where ( ds1 . corr > 0 ) if timeref is not None : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds2 = ds2 . where ( ds2 . corr > 0 ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size ) return [ timestamp , _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax )] Classes Render class Render ( / , * args , ** kwargs ) View Source class Render () : @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , time = timeref , method = 'nearest' ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if param in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ) : out = dst . ns if param in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns =[ 'xxx' ] ). dropna () return out Instance variables reftime timeline Methods extract_data def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if param in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ): out = dst . ns if param in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out isbasetime def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"Struct"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#module-hielen2extsource_photomonitoringstruct","text":"View Source # coding: utf-8 import numpy as np import pandas as pd import matplotlib matplotlib . use ( 'Agg' ) import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap import xarray as xr , datetime import scipy.ndimage as snd import re from netCDF4 import Dataset , date2num import os import PIL def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" #zf=np.zeros((y_values.__len__(),x_values.__len__())) #feed_NC(dataset,timestamp,ns=zf,ew=zf,corr=zf) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : raise ( e ) pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , step_size = 1 , param = \"RV\" ): ''' params dataset: dataset at fixed time param: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa ns = dataset . ns ew = dataset . ew if param in ( \"D\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if param in ( \"EW\" ): h = ew if param in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if param in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = int ( step_size * 6 ) #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / ( coeff . mean () * 4 ) # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( np . abs ( coeff ) > np . abs ( coeff . mean ())) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if param in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY )) # CLASS METHOD def _render ( heatmap , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 0 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / fig . dpi , H / fig . dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] plt . close () return data def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ): if timestamp is None : pass if param is None : param = \"R\" if step_size is None : stap_size = 1 if colors is None : colors = [ \"red\" , \"green\" , \"blue\" ] if vmin is None : vmin =- 150 if vmax is None : vmax = 150 dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) ds1 = ds1 . where ( ds1 . corr > 0 ) if timeref is not None : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds2 = ds2 . where ( ds2 . corr > 0 ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size ) return [ timestamp , _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax )] class Render (): @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if param in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ): out = dst . ns if param in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out","title":"Module hielen2.ext.source_photomonitoring.struct"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#config_nc","text":"def config_NC ( target , timestamp , x_values , y_values ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ][:] = x_values # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = 1 , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) # feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset","title":"config_NC"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#feed_nc","text":"def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : raise ( e ) pass return dataset","title":"feed_NC"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#generate_map","text":"def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , param = None , step_size = None , colors = None , vmin = None , vmax = None ): if timestamp is None : pass if param is None : param = \"R\" if step_size is None : stap_size = 1 if colors is None : colors = [ \"red\" , \"green\" , \"blue\" ] if vmin is None : vmin =- 150 if vmax is None : vmax = 150 dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) ds1 = dataset . sel ( time = timestamp ) ds1 = ds1 . where ( ds1 . corr > 0 ) if timeref is not None : timeref = agoodtime ( timeref ) ds2 = dataset . sel ( time = timeref ) ds2 = ds2 . where ( ds2 . corr > 0 ) ds1 = ds1 - ds2 ds1 . attrs = dataset . attrs managed = _open_matrix ( dataset = ds1 , param = param , step_size = step_size ) return [ timestamp , _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax )]","title":"generate_map"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#render","text":"class Render ( / , * args , ** kwargs ) View Source class Render () : @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , time = timeref , method = 'nearest' ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if param in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ) : out = dst . ns if param in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns =[ 'xxx' ] ). dropna () return out","title":"Render"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#instance-variables","text":"reftime timeline","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#extract_data","text":"def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , param = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit param: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if param in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if param in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if param in ( \"NS\" ): out = dst . ns if param in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out","title":"extract_data"},{"location":"reference/hielen2/ext/source_photomonitoring/struct/#isbasetime","text":"def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"isbasetime"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/","text":"Module hielen2.ext.source_photomonitoring.struct_ok View Source # coding: utf-8 import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap import xarray as xr , datetime import scipy.ndimage as snd import re from netCDF4 import Dataset , date2num import os def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" try : step_size = int ( step_size ) except Exception as e : step_size = 1 try : x_offset = int ( step_size ) except Exception as e : x_offset = 0 try : y_offset = int ( step_size ) except Exception as e : y_offset = 0 y_values = y_values [ y_offset :: step_size ] x_values = x_values [ x_offset :: step_size ] dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) dataset . step_size = step_size # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ] . pixel_offset = y_offset dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ] . pixel_offset = x_offset dataset . variables [ \"x\" ][:] = x_values # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , output = \"RV\" , correlation = 0 ): ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa if correlation and not ns . corr . isnull () . min (): ns = dataset . ns . where ( dataset . corr >= correlation ) ew = dataset . ew . where ( dataset . corr >= correlation ) else : ns = dataset . ns ew = dataset . ew step_size = dataset . step_size if output in ( \"RV\" , \"R\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if output in ( \"EW\" ): h = ew if output in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _render ( heatmap , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 1 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] return data def generate_map ( targetfile , timestamp = None , timeref = None , output = \"RV\" , cmap = [ \"green\" , \"red\" , \"blue\" ], vmin =- 2.5 , vmax = 2 - 5 ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) if timeref is None : timeref = str ( dataset . time [ 0 ] . values ) correlation = 0.01 else : timeref = agoodtime ( timeref ) correlation = 0 print ( \"a\" ) #Nel caso di ref zero il risultato \u00e8 dato dal dataset in \"timestamp\" d1 = dataset . sel ( time = timestamp ) . compute () d2 = dataset . sel ( time = timeref ) . compute () d3 = ( d1 - d2 ) . compute () print ( d2 ) managed = _open_matrix ( dataset = dataset , output = output , correlation = correlation ) print ( \"c\" ) imgarray = _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) print ( \"\" ) # void=xr.DataArray(h, coords=[(\"y\", Y), (\"x\", X)]) # result = PIL.Image.fromarray(imgarray) # img = PIL.Image.new(result.mode, (width, height), (0,0,0,0)) # img.paste(result, dataset.x.pixels_offset,dataset.y.pixels_offset) # filename=f\"{re.sub('[^\\d]','',timeref)}_{re.sub('[^\\d]','',timestamp)}.tiff\" class Render (): def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ): self . gridratio = gridratio @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out Functions agoodtime def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t config_NC def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" try : step_size = int ( step_size ) except Exception as e : step_size = 1 try : x_offset = int ( step_size ) except Exception as e : x_offset = 0 try : y_offset = int ( step_size ) except Exception as e : y_offset = 0 y_values = y_values [ y_offset :: step_size ] x_values = x_values [ x_offset :: step_size ] dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) dataset . step_size = step_size # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ]. pixel_offset = y_offset dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ]. pixel_offset = x_offset dataset . variables [ \"x\" ][:] = x_values # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset feed_NC def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : pass return dataset generate_map def generate_map ( targetfile , timestamp = None , timeref = None , output = 'RV' , cmap = [ 'green' , 'red' , 'blue' ], vmin =- 2.5 , vmax =- 3 ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , output = \"RV\" , cmap = [ \"green\" , \"red\" , \"blue\" ], vmin =- 2 . 5 , vmax = 2 - 5 ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) if timeref is None : timeref = str ( dataset . time [ 0 ]. values ) correlation = 0 . 01 else : timeref = agoodtime ( timeref ) correlation = 0 print ( \"a\" ) # Nel caso di ref zero il risultato \u00e8 dato dal dataset in \"timestamp\" d1 = dataset . sel ( time = timestamp ). compute () d2 = dataset . sel ( time = timeref ). compute () d3 = ( d1 - d2 ). compute () print ( d2 ) managed = _open_matrix ( dataset = dataset , output = output , correlation = correlation ) print ( \"c\" ) imgarray = _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) print ( \"\" ) Classes Render class Render ( targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) View Source class Render () : def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) : self . gridratio = gridratio @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , time = timeref , method = 'nearest' ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if output in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns =[ 'xxx' ] ). dropna () return out Instance variables reftime timeline Methods extract_data def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out isbasetime def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"Struct Ok"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#module-hielen2extsource_photomonitoringstruct_ok","text":"View Source # coding: utf-8 import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib.colors import LinearSegmentedColormap import xarray as xr , datetime import scipy.ndimage as snd import re from netCDF4 import Dataset , date2num import os def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" try : step_size = int ( step_size ) except Exception as e : step_size = 1 try : x_offset = int ( step_size ) except Exception as e : x_offset = 0 try : y_offset = int ( step_size ) except Exception as e : y_offset = 0 y_values = y_values [ y_offset :: step_size ] x_values = x_values [ x_offset :: step_size ] dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) dataset . step_size = step_size # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ] . units = f \"hours since { timestamp } \" dataset . variables [ \"time\" ] . calendar = \"standard\" dataset . variables [ \"time\" ] . long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ] . units = \"1\" dataset . variables [ \"y\" ] . long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ] . pixel_offset = y_offset dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ] . units = \"1\" dataset . variables [ \"x\" ] . long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ] . pixel_offset = x_offset dataset . variables [ \"x\" ][:] = x_values # ns (north-south) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ] . units = \"px\" dataset . variables [ \"ns\" ] . long_name = \"north_south_axis_displacement\" # ew (east-west) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ] . units = \"px\" dataset . variables [ \"ew\" ] . long_name = \"east_west_axis_displacement\" # corr (correlation coefficient) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ] . units = \"1\" dataset . variables [ \"corr\" ] . long_name = \"correlation_coefficient\" zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset def feed_NC ( target , time , ** kwargs ): \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ): dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ) . tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ]) except TypeError : position = timevar . shape [ 0 ] timevar [ position ] = time for k , w in kwargs . items (): if w is not None : y_slice = slice ( 0 , w . shape [ 0 ]) x_slice = slice ( 0 , w . shape [ 1 ]) try : dataset . variables [ k ][ position , y_slice , x_slice ] = w except KeyError as e : pass return dataset def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t #CASS METHOD def _open_matrix ( dataset , output = \"RV\" , correlation = 0 ): ''' params dataset: dataset at fixed time output: \"RV\" result + vector \"R\" results \"V\" vector \"NS\" North-South\" \"EW\" East-West ''' # filtro con maschera di correlazione # se tutte le celle di corr sono null il minimo \u00e8 TRUE altrimenti FALSE. # Inverto la condizione per sapere se c'\u00e8 qualcosa if correlation and not ns . corr . isnull () . min (): ns = dataset . ns . where ( dataset . corr >= correlation ) ew = dataset . ew . where ( dataset . corr >= correlation ) else : ns = dataset . ns ew = dataset . ew step_size = dataset . step_size if output in ( \"RV\" , \"R\" , \"V\" ): h = np . sqrt ( ns ** 2 + ew ** 2 ) if output in ( \"EW\" ): h = ew if output in ( \"NS\" ): h = ns # upsampling h = snd . zoom ( h , step_size , order = 0 , mode = 'nearest' ) Y = np . arange ( 0 , h . shape [ 0 ]) X = np . arange ( 0 , h . shape [ 1 ]) heatmap = xr . DataArray ( h , coords = [( \"y\" , Y ), ( \"x\" , X )]) if output in ( \"R\" , \"NS\" , \"EW\" ): return dict ( heatmap = heatmap , vectors = None , dims = h . shape ) # A questo punto solo RV o V # Elaboro i versori # upsampling a = snd . zoom ( np . arctan2 ( ns , ew ), step_size , order = 0 , mode = 'nearest' ) angle = xr . DataArray ( a , coords = [( \"y\" , Y ), ( \"x\" , X )]) #riduco il versore rollingside = 100 #CON MEDIA #https://stackoverflow.com/questions/52886703/xarray-multidimensional-binning-array-reduction-on-sample-dataset-of-4-x4-to coeff = heatmap . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) coeff = heatmap . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( x = rollingside ) . construct ( 'tmp' ) . isel ( x = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) angle = angle . rolling ( y = rollingside ) . construct ( 'tmp' ) . isel ( y = slice ( 1 , None , rollingside )) . mean ( 'tmp' , skipna = False ) #SENZA MEDIA ''' coeff=coeff[::rollingside,::rollingside] ''' # filtro **ARBITRARIAMENTE** quelli che superano il 2 sigma # coeff=coeff.where(coeff<coeff.mean()+coeff.std()*2) # normalizzo su un valore adeguato coeff = coeff / coeff . mean () # applico il logaritmo per enfatizzare gli spostamenti minimi e # ridurre l'impatto visivo degli outlayers # coeff=np.log(1+coeff) # filtro l'angolo in base al grid del coefficiente angle = angle . where ( coeff ) X , Y = np . meshgrid ( angle [ 'x' ], angle [ 'y' ]) dY = np . sin ( angle ) * coeff dX = np . cos ( angle ) * coeff if output in ( \"V\" ): heatmap = heatmap . where ( heatmap is np . nan ) return dict ( heatmap = heatmap , vectors = ( X , Y , dX , dY ), dims = h . shape ) # CLASS METHOD def _render ( heatmap , vectors = None , colors = [ \"green\" , \"red\" , \"blue\" ], vmin = 0 , vmax = 5 ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , colors ) W = heatmap . shape [ 1 ] H = heatmap . shape [ 1 ] plt . tight_layout = dict ( pad = 0 ) fig = plt . figure () fig . tight_layout = dict ( pad = 0 ) fig . frameon = False fig . dpi = 72 fig . set_size_inches ( W / dpi , H / dpi ) fig . facecolor = \"None\" fig . linewidth = 0 ax = plt . Axes ( fig ,[ 0 , 0 , 1 , 1 ]) ax . set_axis_off () ax . imshow ( heatmap , alpha = 0.20 , origin = 'upper' , cmap = cmap , norm = None , vmin = vmin , vmax = vmax ) if vectors is not None : ax . quiver ( * vectors , width = 0.0008 , color = 'white' , scale = 100 ) fig . add_axes ( ax ) fig . canvas . draw () data = np . frombuffer ( fig . canvas . tostring_argb (), dtype = np . uint8 ) data = data . reshape ( fig . canvas . get_width_height ()[:: - 1 ] + ( 4 ,))[:, :, [ 3 , 2 , 1 , 0 ]] return data def generate_map ( targetfile , timestamp = None , timeref = None , output = \"RV\" , cmap = [ \"green\" , \"red\" , \"blue\" ], vmin =- 2.5 , vmax = 2 - 5 ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ] . values ) else : timestamp = agoodtime ( timestamp ) if timeref is None : timeref = str ( dataset . time [ 0 ] . values ) correlation = 0.01 else : timeref = agoodtime ( timeref ) correlation = 0 print ( \"a\" ) #Nel caso di ref zero il risultato \u00e8 dato dal dataset in \"timestamp\" d1 = dataset . sel ( time = timestamp ) . compute () d2 = dataset . sel ( time = timeref ) . compute () d3 = ( d1 - d2 ) . compute () print ( d2 ) managed = _open_matrix ( dataset = dataset , output = output , correlation = correlation ) print ( \"c\" ) imgarray = _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) print ( \"\" ) # void=xr.DataArray(h, coords=[(\"y\", Y), (\"x\", X)]) # result = PIL.Image.fromarray(imgarray) # img = PIL.Image.new(result.mode, (width, height), (0,0,0,0)) # img.paste(result, dataset.x.pixels_offset,dataset.y.pixels_offset) # filename=f\"{re.sub('[^\\d]','',timeref)}_{re.sub('[^\\d]','',timestamp)}.tiff\" class Render (): def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ): self . gridratio = gridratio @property def timeline ( self ): times = self . dataset . time . values return list ( map ( lambda x : str ( x ) . replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ): return self . dataset . timestamp def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ) . sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]) . dropna () return out","title":"Module hielen2.ext.source_photomonitoring.struct_ok"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#agoodtime","text":"def agoodtime ( t ) View Source def agoodtime ( t ): try : t = np . datetime64 ( t ) assert not np . isnat ( t ) t = str ( t ) except Exception : t = None return t","title":"agoodtime"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#config_nc","text":"def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ) Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x View Source def config_NC ( target , timestamp , x_values , y_values , step_size = None , x_offset = None , y_offset = None ): \"\"\" Crea il file netCDF secondo un formato standard returns: la struttura dati del file NetCDF params tagetfile: nome del file refitime: tempo zero y_values: array delle y x_values: array delle x \"\"\" try : step_size = int ( step_size ) except Exception as e : step_size = 1 try : x_offset = int ( step_size ) except Exception as e : x_offset = 0 try : y_offset = int ( step_size ) except Exception as e : y_offset = 0 y_values = y_values [ y_offset :: step_size ] x_values = x_values [ x_offset :: step_size ] dataset = Dataset ( target , 'w' , format = \"NETCDF4\" ) dataset . Conventions = \"CF-1.7\" dataset . timestamp = agoodtime ( timestamp ) dataset . step_size = step_size # time informations dataset . createDimension ( \"time\" , None ) dataset . createVariable ( \"time\" , \"f8\" ,( \"time\" ,)) dataset . variables [ \"time\" ]. units = f \"hours since {timestamp}\" dataset . variables [ \"time\" ]. calendar = \"standard\" dataset . variables [ \"time\" ]. long_name = \"observation_time\" # y informations dataset . createDimension ( \"y\" , y_values . __len__ ()) dataset . createVariable ( \"y\" , \"f4\" ,( \"y\" ,)) dataset . variables [ \"y\" ]. units = \"1\" dataset . variables [ \"y\" ]. long_name = \"projection_y_coordinate\" dataset . variables [ \"y\" ]. pixel_offset = y_offset dataset . variables [ \"y\" ][:] = y_values # x informations dataset . createDimension ( \"x\" , x_values . __len__ ()) dataset . createVariable ( \"x\" , \"f4\" ,( \"x\" ,)) dataset . variables [ \"x\" ]. units = \"1\" dataset . variables [ \"x\" ]. long_name = \"projection_x_coordinate\" dataset . variables [ \"x\" ]. pixel_offset = x_offset dataset . variables [ \"x\" ][:] = x_values # ns ( north - south ) informations dataset . createVariable ( \"ns\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ns\" ]. units = \"px\" dataset . variables [ \"ns\" ]. long_name = \"north_south_axis_displacement\" # ew ( east - west ) informations dataset . createVariable ( \"ew\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"ew\" ]. units = \"px\" dataset . variables [ \"ew\" ]. long_name = \"east_west_axis_displacement\" # corr ( correlation coefficient ) informations dataset . createVariable ( \"corr\" , \"f4\" ,( \"time\" , \"y\" , \"x\" ,), fill_value = np . nan , zlib = True , least_significant_digit = 3 ) dataset . variables [ \"corr\" ]. units = \"1\" dataset . variables [ \"corr\" ]. long_name = \"correlation_coefficient\" zf = np . zeros (( y_values . __len__ (), x_values . __len__ ())) feed_NC ( dataset , timestamp , ns = zf , ew = zf , corr = zf ) return dataset","title":"config_NC"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#feed_nc","text":"def feed_NC ( target , time , ** kwargs ) Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid View Source def feed_NC ( target , time , ** kwargs ) : \"\"\" Appende i grid al file netCDF target: netCDF4.Dataset or path to a valid .nc file time: timestamp del dato kwarg: dict nomevariabile:datagrid \"\"\" if isinstance ( target , Dataset ) : dataset = target else : dataset = Dataset ( target , 'a' , format = \"NETCDF4\" ) timevar = dataset . variables [ 'time' ] time = date2num ( np . datetime64 ( time ). tolist (), timevar . units ) # If exists substitute position = np . where ( timevar == time ) try : position = int ( position [ 0 ] ) except TypeError : position = timevar . shape [ 0 ] timevar [ position ]= time for k , w in kwargs . items () : if w is not None : y_slice = slice ( 0 , w . shape [ 0 ] ) x_slice = slice ( 0 , w . shape [ 1 ] ) try : dataset . variables [ k ][ position,y_slice,x_slice ] = w except KeyError as e : pass return dataset","title":"feed_NC"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#generate_map","text":"def generate_map ( targetfile , timestamp = None , timeref = None , output = 'RV' , cmap = [ 'green' , 'red' , 'blue' ], vmin =- 2.5 , vmax =- 3 ) View Source def generate_map ( targetfile , timestamp = None , timeref = None , output = \"RV\" , cmap = [ \"green\" , \"red\" , \"blue\" ], vmin =- 2 . 5 , vmax = 2 - 5 ): dataset = xr . open_dataset ( targetfile ) if timestamp is None : timestamp = str ( dataset . time [ - 1 ]. values ) else : timestamp = agoodtime ( timestamp ) if timeref is None : timeref = str ( dataset . time [ 0 ]. values ) correlation = 0 . 01 else : timeref = agoodtime ( timeref ) correlation = 0 print ( \"a\" ) # Nel caso di ref zero il risultato \u00e8 dato dal dataset in \"timestamp\" d1 = dataset . sel ( time = timestamp ). compute () d2 = dataset . sel ( time = timeref ). compute () d3 = ( d1 - d2 ). compute () print ( d2 ) managed = _open_matrix ( dataset = dataset , output = output , correlation = correlation ) print ( \"c\" ) imgarray = _render ( ** managed , colors = colors , vmin = vmin , vmax = vmax ) print ( \"\" )","title":"generate_map"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#render","text":"class Render ( targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) View Source class Render () : def __init__ ( self , targetfile = './incomes/sag.nc' , gridratio = 8 , ** kwargs ) : self . gridratio = gridratio @property def timeline ( self ) : times = self . dataset . time . values return list ( map ( lambda x : str ( x ). replace ( '.000000000' , '' ),( times ))) @property def reftime ( self ) : return self . dataset . timestamp def isbasetime ( self , time ) : try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ) : ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ) : ref = self . dataset . sel ( x = geom [ 0 ] , y = geom [ 1 ] , time = timeref , method = 'nearest' ) dst [ 'ns' ]= dst . ns - ref . ns dst [ 'ew' ]= dst . ew - ref . ew if output in ( \"R\" , \"RV\" ) : out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ) : out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ) : out = dst . ns if output in ( \"EW\" ) : out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns =[ 'xxx' ] ). dropna () return out","title":"Render"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#instance-variables","text":"reftime timeline","title":"Instance variables"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#extract_data","text":"def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = 'R' , timeref = None ) params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component View Source def extract_data ( self , geom = ( 0 , 0 ), timefrom = None , timeto = None , output = \"R\" , timeref = None ): ''' params geom: point to extract timefrom: time lower limit timeto: time upper limit output: \"R\" result (the module itself) \"NS\" North-South component \"EW\" Eeast-West component ''' timefrom = agoodtime ( timefrom ) timeto = agoodtime ( timeto ) timeref = agoodtime ( timeref ) dst = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], method = 'nearest' ). sel ( time = slice ( timefrom , timeto )) if timeref is not None and not self . isbasetime ( timeref ): ref = self . dataset . sel ( x = geom [ 0 ], y = geom [ 1 ], time = timeref , method = 'nearest' ) dst [ 'ns' ] = dst . ns - ref . ns dst [ 'ew' ] = dst . ew - ref . ew if output in ( \"R\" , \"RV\" ): out = np . sqrt ( dst . ns ** 2 + dst . ew ** 2 ) if output in ( \"V\" ): out = np . rad2deg ( np . arctan2 ( dst . ns , dst . ew )) if output in ( \"NS\" ): out = dst . ns if output in ( \"EW\" ): out = dst . ew out = pd . DataFrame ( out , index = out . time . values , columns = [ 'xxx' ]). dropna () return out","title":"extract_data"},{"location":"reference/hielen2/ext/source_photomonitoring/struct_ok/#isbasetime","text":"def isbasetime ( self , time ) View Source def isbasetime ( self , time ): try : return np . datetime64 ( time ) == np . datetime64 ( self . reftime ) except Exception : return False","title":"isbasetime"},{"location":"reference/hielen2/ext/source_tinsar/","text":"Module hielen2.ext.source_tinsar View Source # coding=utf-8 from hielen2.source import HielenSource from hielen2.source import HielenSource , ActionSchema from hielen2.utils import LocalFile from marshmallow import fields class ConfigSchema ( ActionSchema ): master_cloud = LocalFile ( required = True , allow_none = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) class FeedSchema ( ActionSchema ): scanner_file = LocalFile ( required = True , allow_none = False ) class Source ( HielenSource ): def config ( self , ** kwargs ): return kwargs def feed ( self , ** kwargs ): return kwargs def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs Sub-modules hielen2.ext.source_tinsar.cloudpainter Classes ConfigSchema class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): master_cloud = LocalFile ( required = True , allow_none = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_cloud opts Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} FeedSchema class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): scanner_file = LocalFile ( required = True , allow_none = False ) Ancestors (in MRO) hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC Class variables Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts scanner_file Static methods from_dict def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls Instance variables dict_class set_class Methods dump def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result dumps def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs ) get_attribute def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default ) handle_error def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass load def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True ) loads def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown ) on_bind_field def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None validate def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {} Source class Source ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Source ( HielenSource ): def config ( self , ** kwargs ): return kwargs def feed ( self , ** kwargs ): return kwargs def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs Ancestors (in MRO) hielen2.source.HielenSource abc.ABC Methods config def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return kwargs data def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ) View Source def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs deleteActionValues def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out execAction def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e ) feed def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): return kwargs getActionSchema def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action ) getActionValues def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"Index"},{"location":"reference/hielen2/ext/source_tinsar/#module-hielen2extsource_tinsar","text":"View Source # coding=utf-8 from hielen2.source import HielenSource from hielen2.source import HielenSource , ActionSchema from hielen2.utils import LocalFile from marshmallow import fields class ConfigSchema ( ActionSchema ): master_cloud = LocalFile ( required = True , allow_none = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True ) class FeedSchema ( ActionSchema ): scanner_file = LocalFile ( required = True , allow_none = False ) class Source ( HielenSource ): def config ( self , ** kwargs ): return kwargs def feed ( self , ** kwargs ): return kwargs def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs","title":"Module hielen2.ext.source_tinsar"},{"location":"reference/hielen2/ext/source_tinsar/#sub-modules","text":"hielen2.ext.source_tinsar.cloudpainter","title":"Sub-modules"},{"location":"reference/hielen2/ext/source_tinsar/#classes","text":"","title":"Classes"},{"location":"reference/hielen2/ext/source_tinsar/#configschema","text":"class ConfigSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class ConfigSchema ( ActionSchema ): master_cloud = LocalFile ( required = True , allow_none = False ) geo_reference_file = LocalFile ( required = False , default = None , allow_none = True ) crs = fields . Str ( required = False , default = None , allow_none = True )","title":"ConfigSchema"},{"location":"reference/hielen2/ext/source_tinsar/#ancestors-in-mro","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_tinsar/#class-variables","text":"Meta OPTIONS_CLASS TYPE_MAPPING crs error_messages geo_reference_file master_cloud opts","title":"Class variables"},{"location":"reference/hielen2/ext/source_tinsar/#static-methods","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_tinsar/#from_dict","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_tinsar/#instance-variables","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_tinsar/#methods","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_tinsar/#dump","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_tinsar/#dumps","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_tinsar/#get_attribute","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_tinsar/#handle_error","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_tinsar/#load","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_tinsar/#loads","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_tinsar/#on_bind_field","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_tinsar/#validate","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_tinsar/#feedschema","text":"class FeedSchema ( * , only : Union [ Sequence [ str ], Set [ str ], NoneType ] = None , exclude : Union [ Sequence [ str ], Set [ str ]] = (), many : bool = False , context : Union [ Dict , NoneType ] = None , load_only : Union [ Sequence [ str ], Set [ str ]] = (), dump_only : Union [ Sequence [ str ], Set [ str ]] = (), partial : Union [ bool , Sequence [ str ], Set [ str ]] = False , unknown : Union [ str , NoneType ] = None ) Minimal ActionSchema object. Used to define at least a timestamp View Source class FeedSchema ( ActionSchema ): scanner_file = LocalFile ( required = True , allow_none = False )","title":"FeedSchema"},{"location":"reference/hielen2/ext/source_tinsar/#ancestors-in-mro_1","text":"hielen2.source.ActionSchema marshmallow.schema.Schema marshmallow.base.SchemaABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_tinsar/#class-variables_1","text":"Meta OPTIONS_CLASS TYPE_MAPPING error_messages opts scanner_file","title":"Class variables"},{"location":"reference/hielen2/ext/source_tinsar/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/hielen2/ext/source_tinsar/#from_dict_1","text":"def from_dict ( fields : Dict [ str , Union [ marshmallow . fields . Field , type ]], * , name : str = 'GeneratedSchema' ) -> type Generate a Schema class given a dictionary of fields. .. code-block:: python from marshmallow import Schema , fields PersonSchema = Schema . from_dict ({ \"name\" : fields . Str ()}) print ( PersonSchema () . load ({ \"name\" : \"David\" })) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in Nested fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the repr for the class. .. versionadded:: 3.0.0 View Source @classmethod def from_dict ( cls , fields : typing . Dict [ str , typing . Union [ ma_fields . Field , type ]], * , name : str = \"GeneratedSchema\" ) -> type : \"\"\"Generate a `Schema` class given a dictionary of fields. .. code-block:: python from marshmallow import Schema, fields PersonSchema = Schema.from_dict({\"name\": fields.Str()}) print(PersonSchema().load({\"name\": \"David\"})) # => {'name': 'David'} Generated schemas are not added to the class registry and therefore cannot be referred to by name in `Nested` fields. :param dict fields: Dictionary mapping field names to field instances. :param str name: Optional name for the class, which will appear in the ``repr`` for the class. .. versionadded:: 3.0.0 \"\"\" attrs = fields . copy () attrs [ \"Meta\" ] = type ( \"GeneratedMeta\" , ( getattr ( cls , \"Meta\" , object ),), { \"register\" : False } ) schema_cls = type ( name , ( cls ,), attrs ) return schema_cls","title":"from_dict"},{"location":"reference/hielen2/ext/source_tinsar/#instance-variables_1","text":"dict_class set_class","title":"Instance variables"},{"location":"reference/hielen2/ext/source_tinsar/#methods_1","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_tinsar/#dump_1","text":"def dump ( self , obj : Any , * , many : Union [ bool , NoneType ] = None ) Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. View Source def dump ( self , obj : typing . Any , * , many : typing . Optional [ bool ] = None ): \"\"\"Serialize an object to native Python data types according to this Schema's fields. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A dict of serialized data :rtype: dict .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. .. versionchanged:: 3.0.0rc9 Validation no longer occurs upon serialization. \"\"\" many = self . many if many is None else bool ( many ) if many and is_iterable_but_not_string ( obj ): obj = list ( obj ) if self . _has_processors ( PRE_DUMP ): processed_obj = self . _invoke_dump_processors ( PRE_DUMP , obj , many = many , original_data = obj ) else : processed_obj = obj result = self . _serialize ( processed_obj , many = many ) if self . _has_processors ( POST_DUMP ): result = self . _invoke_dump_processors ( POST_DUMP , result , many = many , original_data = obj ) return result","title":"dump"},{"location":"reference/hielen2/ext/source_tinsar/#dumps_1","text":"def dumps ( self , obj : Any , * args , many : Union [ bool , NoneType ] = None , ** kwargs ) Same as :meth: dump , except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize obj as a collection. If None , the value for self.many is used. :return: A json string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if obj is invalid. View Source def dumps ( self , obj : typing . Any , * args , many : typing . Optional [ bool ] = None , ** kwargs ): \"\"\"Same as :meth:`dump`, except return a JSON-encoded string. :param obj: The object to serialize. :param many: Whether to serialize `obj` as a collection. If `None`, the value for `self.many` is used. :return: A ``json`` string :rtype: str .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the serialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if ``obj`` is invalid. \"\"\" serialized = self . dump ( obj , many = many ) return self . opts . render_module . dumps ( serialized , * args , ** kwargs )","title":"dumps"},{"location":"reference/hielen2/ext/source_tinsar/#get_attribute_1","text":"def get_attribute ( self , obj : Any , attr : str , default : Any ) Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of obj and attr . View Source def get_attribute ( self , obj : typing . Any , attr : str , default : typing . Any ): \"\"\"Defines how to pull values from an object to serialize. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0a1 Changed position of ``obj`` and ``attr``. \"\"\" return get_value ( obj , attr , default )","title":"get_attribute"},{"location":"reference/hielen2/ext/source_tinsar/#handle_error_1","text":"def handle_error ( self , error : marshmallow . exceptions . ValidationError , data : Any , * , many : bool , ** kwargs ) Custom error handler function for the schema. :param error: The ValidationError raised during (de)serialization. :param data: The original input data. :param many: Value of many on dump or load. :param partial: Value of partial on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives many and partial (on deserialization) as keyword arguments. View Source def handle_error ( self , error : ValidationError , data : typing . Any , * , many : bool , ** kwargs ): \"\"\"Custom error handler function for the schema. :param error: The `ValidationError` raised during (de)serialization. :param data: The original input data. :param many: Value of ``many`` on dump or load. :param partial: Value of ``partial`` on load. .. versionadded:: 2.0.0 .. versionchanged:: 3.0.0rc9 Receives `many` and `partial` (on deserialization) as keyword arguments. \"\"\" pass","title":"handle_error"},{"location":"reference/hielen2/ext/source_tinsar/#load_1","text":"def load ( self , data : Union [ Mapping [ str , Any ], Iterable [ Mapping [ str , Any ]]], * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None ) Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def load ( self , data : typing . Union [ typing . Mapping [ str , typing . Any ], typing . Iterable [ typing . Mapping [ str , typing . Any ]], ], * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None ): \"\"\"Deserialize a data structure to an object defined by this Schema's fields. :param data: The data to deserialize. :param many: Whether to deserialize `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" return self . _do_load ( data , many = many , partial = partial , unknown = unknown , postprocess = True )","title":"load"},{"location":"reference/hielen2/ext/source_tinsar/#loads_1","text":"def loads ( self , json_data : str , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None , unknown : Union [ str , NoneType ] = None , ** kwargs ) Same as :meth: load , except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize obj as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use EXCLUDE , INCLUDE or RAISE . If None , the value for self.unknown is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a (data, errors) duple. A :exc: ValidationError <marshmallow.exceptions.ValidationError> is raised if invalid data are passed. View Source def loads ( self , json_data : str , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None , unknown : typing . Optional [ str ] = None , ** kwargs ): \"\"\"Same as :meth:`load`, except it takes a JSON string as input. :param json_data: A JSON string of the data to deserialize. :param many: Whether to deserialize `obj` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :param unknown: Whether to exclude, include, or raise an error for unknown fields in the data. Use `EXCLUDE`, `INCLUDE` or `RAISE`. If `None`, the value for `self.unknown` is used. :return: Deserialized data .. versionadded:: 1.0.0 .. versionchanged:: 3.0.0b7 This method returns the deserialized data rather than a ``(data, errors)`` duple. A :exc:`ValidationError <marshmallow.exceptions.ValidationError>` is raised if invalid data are passed. \"\"\" data = self . opts . render_module . loads ( json_data , ** kwargs ) return self . load ( data , many = many , partial = partial , unknown = unknown )","title":"loads"},{"location":"reference/hielen2/ext/source_tinsar/#on_bind_field_1","text":"def on_bind_field ( self , field_name : str , field_obj : marshmallow . fields . Field ) -> None Hook to modify a field when it is bound to the Schema . No-op by default. View Source def on_bind_field ( self , field_name : str , field_obj : ma_fields . Field ) -> None : \"\"\"Hook to modify a field when it is bound to the `Schema`. No-op by default. \"\"\" return None","title":"on_bind_field"},{"location":"reference/hielen2/ext/source_tinsar/#validate_1","text":"def validate ( self , data : Mapping , * , many : Union [ bool , NoneType ] = None , partial : Union [ bool , Sequence [ str ], Set [ str ], NoneType ] = None ) -> Dict [ str , List [ str ]] Validate data against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate data as a collection. If None , the value for self.many is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to Nested fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 View Source def validate ( self , data : typing . Mapping , * , many : typing . Optional [ bool ] = None , partial : typing . Optional [ typing . Union [ bool , types . StrSequenceOrSet ]] = None ) -> typing . Dict [ str , typing . List [ str ]]: \"\"\"Validate `data` against the schema, returning a dictionary of validation errors. :param data: The data to validate. :param many: Whether to validate `data` as a collection. If `None`, the value for `self.many` is used. :param partial: Whether to ignore missing fields and not require any fields declared. Propagates down to ``Nested`` fields as well. If its value is an iterable, only missing fields listed in that iterable will be ignored. Use dot delimiters to specify nested fields. :return: A dictionary of validation errors. .. versionadded:: 1.1.0 \"\"\" try : self . _do_load ( data , many = many , partial = partial , postprocess = False ) except ValidationError as exc : return typing . cast ( typing . Dict [ str , typing . List [ str ]], exc . messages ) return {}","title":"validate"},{"location":"reference/hielen2/ext/source_tinsar/#source","text":"class Source ( feature ) Helper class that provides a standard way to create an ABC using inheritance. View Source class Source ( HielenSource ): def config ( self , ** kwargs ): return kwargs def feed ( self , ** kwargs ): return kwargs def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs","title":"Source"},{"location":"reference/hielen2/ext/source_tinsar/#ancestors-in-mro_2","text":"hielen2.source.HielenSource abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/hielen2/ext/source_tinsar/#methods_2","text":"","title":"Methods"},{"location":"reference/hielen2/ext/source_tinsar/#config","text":"def config ( self , ** kwargs ) View Source def config ( self , ** kwargs ): return kwargs","title":"config"},{"location":"reference/hielen2/ext/source_tinsar/#data","text":"def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ) View Source def data ( self , timefrom = None , timeto = None , geom = None , ** kwargs ): return kwargs","title":"data"},{"location":"reference/hielen2/ext/source_tinsar/#deleteactionvalues","text":"def deleteActionValues ( self , action = None , timestamp = None ) View Source def deleteActionValues ( self , action = None , timestamp = None ) : out = self . getActionValues ( action , timestamp ) if not isinstance ( out , list ) : out =[ out ] for act in out : a = act [ 'action' ] t = act [ 'timestamp' ] try : self . __getattribute__ ( f \"clean{a.capitalize()}\" )( t ) except Exception as e : traceback . print_exc () pass try : db [ 'actions' ][ self.uid,a,t ]= None except Exception as e : raise ValueError ( e ) return out","title":"deleteActionValues"},{"location":"reference/hielen2/ext/source_tinsar/#execaction","text":"def execAction ( self , action , ** kwargs ) View Source def execAction ( self , action , ** kwargs ): aclass = getActionSchemaClass ( self . module , action ) try : kwargs = aclass (). load ( kwargs ) return self . __getattribute__ ( action )( ** kwargs ) except Exception as e : raise ValueError ( e )","title":"execAction"},{"location":"reference/hielen2/ext/source_tinsar/#feed","text":"def feed ( self , ** kwargs ) View Source def feed ( self , ** kwargs ): return kwargs","title":"feed"},{"location":"reference/hielen2/ext/source_tinsar/#getactionschema","text":"def getActionSchema ( self , action ) View Source def getActionSchema ( self , action ): return getActionSchema ( self . module , action )","title":"getActionSchema"},{"location":"reference/hielen2/ext/source_tinsar/#getactionvalues","text":"def getActionValues ( self , action = None , timestamp = None ) View Source def getActionValues ( self , action = None , timestamp = None ) : if action is None : action = slice ( None , None ) if timestamp is None : timestamp = slice ( None , None ) try : out = db [ 'actions' ][ self.uid,action,timestamp ] if not isinstance ( out , list ) : out = [ out ] except KeyError : return [] return out","title":"getActionValues"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/","text":"Module hielen2.ext.source_tinsar.cloudpainter View Source # coding: utf-8 import pandas as pd import numpy as np import laspy from scipy.spatial import KDTree from matplotlib.colors import Normalize , Colormap , LinearSegmentedColormap from matplotlib.cm import ScalarMappable import getopt import sys import open3d as o3d def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance (dist) and value clouds relative ## ids (idsv). the position of each cell in the arrays reflects the cells ## in the base cloud. k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]] . values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ) . stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ) . stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud (base cloud index) and his neighbous (value cloud ids, ## distance and neighbour group progressive). Then we clean the infinite ## distances (points with no neighbours) values = dist . to_frame () . join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv', allows to join with the value cloud and add the 'v' # info values = values . reset_index () . set_index ( \"idsv\" ) . sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance', allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]) . sort_index () ## Here we calculte the [distance based, weighted] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ) . apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) vmin = vmin or vals . min () vmax = vmax or vals . max () norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) if not isinstance ( cmap , Colormap ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None , ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , vmin = vmin , vmax = vmax ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ \"r\" , \"g\" , \"b\" ]] if basecld is not None : result = basecld . join ( colors , how = \"left\" ) . replace ( np . nan , 0.9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] #65536 def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] * coordmult y = frame [ 'y' ] * coordmult z = frame [ 'z' ] * coordmult r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult #outfile.header.min=[ np.floor(np.min(x)), np.floor(np.min(y)), np.floor(np.min(z)) ] #outfile.header.max=[ np.ceil(np.max(x)), np.ceil(np.max(y)), np.ceil(np.max(z)) ] #outfile.header.offset=outfile.header.min outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () def openpcl ( res ): #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d . geometry . PointCloud () pcl . points = o3d . utility . Vector3dVector ( res [[ \"x\" , \"y\" , \"z\" ]] . values ) pcl . colors = o3d . utility . Vector3dVector ( res [[ \"r\" , \"g\" , \"b\" ]] . values ) o3d . visualization . draw_geometries ([ pcl ]) def usage (): helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) if __name__ == \"__main__\" : #DEFAULTS datacloud = None basecloud = None group = 1 distance = 5 degree = 0 colors = [ 'violet' , 'blue' , 'cyan' , 'green' , 'yellow' , 'orange' , 'red' ] outfile = None output = 'las' vmin =- 500 vmax = 500 try : opts , args = getopt . getopt ( sys . argv [ 1 :], \"b:g:d:D:c:o:O:v:V:\" , [ \"basecloud=\" , \"group=\" , \"distance=\" , \"degree=\" , \"colors=\" , \"outfile=\" , \"output=\" , \"vmin=\" , \"vmax=\" ]) for o , a in opts : if o in ( \"-b\" , \"--basecloud\" ): basecloud = a elif o in ( \"-g\" , \"--group\" ): group = a elif o in ( \"-d\" , \"--distance\" ): distance = a elif o in ( \"-D\" , \"--degree\" ): degree = a elif o in ( \"-c\" , \"--colors\" ): colors = a . split ( \",\" ) elif o in ( \"-o\" , \"--outfile\" ): outfile = a elif o in ( \"-O\" , \"--output\" ): output = a elif o in ( \"-v\" , \"--vmin\" ): vmin = a elif o in ( \"-V\" , \"--vmax\" ): vmax = a else : assert False , \"unhandled option\" try : infile = args [ 0 ] except Exception : raise Exception ( f \"No file\" ) datacloud = pd . read_csv ( infile ) datacloud = datacloud [ datacloud . columns [ 0 : 4 ]] datacloud . columns = [ \"X\" , \"Y\" , \"Z\" , \"V\" ] if basecloud is not None : basecloud = pd . read_csv ( basecloud ) basecloud = basecloud [ basecloud . columns [ 0 : 3 ]] basecloud . columns = [ \"X\" , \"Y\" , \"Z\" ] result = paint ( valcld = datacloud , basecld = basecloud , distance = distance , degree = degree , group = group , cmap = colors , vmin = vmin , vmax = vmax ) print ( output ) if outfile is None : outfile = '.' . join ([ infile , output ]) if output == 'las' : makelaz ( result [[ \"x\" , \"y\" , \"z\" , \"r\" , \"g\" , \"b\" ]], outfile ) elif output == 'csv' : result . to_csv ( outfile , index = False ) elif output == 'view' : openpcl ( result ) else : raise Exception ( f 'unkwnown output type: { output } ' ) except Exception as err : # print help information and exit: print ( err ) usage () sys . exit ( 2 ) Functions colorize def colorize ( vals , cmap = [ 'red' , 'green' , 'blue' ], vmin = None , vmax = None ) Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) vmin = vmin or vals . min () vmax = vmax or vals . max () norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) if not isinstance ( cmap , Colormap ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols makelaz def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ) View Source def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] * coordmult y = frame [ 'y' ] * coordmult z = frame [ 'z' ] * coordmult r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult # outfile . header . min = [ np . floor ( np . min ( x )), np . floor ( np . min ( y )), np . floor ( np . min ( z )) ] # outfile . header . max = [ np . ceil ( np . max ( x )), np . ceil ( np . max ( y )), np . ceil ( np . max ( z )) ] # outfile . header . offset = outfile . header . min outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () openpcl def openpcl ( res ) View Source def openpcl ( res ) : #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d . geometry . PointCloud () pcl . points = o3d . utility . Vector3dVector ( res [ [\"x\", \"y\", \"z\" ] ] . values ) pcl . colors = o3d . utility . Vector3dVector ( res [ [\"r\", \"g\", \"b\" ] ] . values ) o3d . visualization . draw_geometries ( [ pcl ] ) paint def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ 'red' , 'green' , 'blue' ], vmin = None , vmax = None ) Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None , ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , vmin = vmin , vmax = vmax ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ \"r\" , \"g\" , \"b\" ]] if basecld is not None : result = basecld . join ( colors , how = \"left\" ). replace ( np . nan , 0 . 9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] usage def usage ( ) View Source def usage () : helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) valorize def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ) Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . i . e : N1 ----------P----N2 Given two neighbours , N1 and N2 , for a fixed point P where : d ( N1 ) = 10 ; v ( N1 ) =- 15 d ( N2 ) = 4 ; v ( N2 ) = 3 v ( P ) = ( - 15 / 10 ** d + 3 / 4 ** d ) / ( 1 / 10 ** d + 1 / 4 ** d ) being d the degree , we have : d = 0 : v ( P ) = - 6 < -- arimetic mean d = 1 : v ( P ) = - 2 . 14 d = 2 : v ( P ) = 0 . 51 d = 3 : v ( P ) = 1 . 91 d = 4 : v ( P ) = 2 . 55 d = 5 : v ( P ) = 2 . 81 .. d = 9 : v ( P ) = 2 . 99 .. d ( x ): v ( P ) = 3 < -- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. View Source def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance ( dist ) and value clouds relative ## ids ( idsv ). the position of each cell in the arrays reflects the cells ## in the base cloud . k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]]. values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ). stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ). stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud ( base cloud index ) and his neighbous ( value cloud ids , ## distance and neighbour group progressive ). Then we clean the infinite ## distances ( points with no neighbours ) values = dist . to_frame (). join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv' , allows to join with the value cloud and add the 'v' # info values = values . reset_index (). set_index ( \"idsv\" ). sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance' , allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]). sort_index () ## Here we calculte the [ distance based , weighted ] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ). apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values","title":"Cloudpainter"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#module-hielen2extsource_tinsarcloudpainter","text":"View Source # coding: utf-8 import pandas as pd import numpy as np import laspy from scipy.spatial import KDTree from matplotlib.colors import Normalize , Colormap , LinearSegmentedColormap from matplotlib.cm import ScalarMappable import getopt import sys import open3d as o3d def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance (dist) and value clouds relative ## ids (idsv). the position of each cell in the arrays reflects the cells ## in the base cloud. k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]] . values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ) . stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ) . stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud (base cloud index) and his neighbous (value cloud ids, ## distance and neighbour group progressive). Then we clean the infinite ## distances (points with no neighbours) values = dist . to_frame () . join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv', allows to join with the value cloud and add the 'v' # info values = values . reset_index () . set_index ( \"idsv\" ) . sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance', allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]) . sort_index () ## Here we calculte the [distance based, weighted] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ) . apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) vmin = vmin or vals . min () vmax = vmax or vals . max () norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) if not isinstance ( cmap , Colormap ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None , ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , vmin = vmin , vmax = vmax ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ \"r\" , \"g\" , \"b\" ]] if basecld is not None : result = basecld . join ( colors , how = \"left\" ) . replace ( np . nan , 0.9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]] #65536 def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] * coordmult y = frame [ 'y' ] * coordmult z = frame [ 'z' ] * coordmult r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult #outfile.header.min=[ np.floor(np.min(x)), np.floor(np.min(y)), np.floor(np.min(z)) ] #outfile.header.max=[ np.ceil(np.max(x)), np.ceil(np.max(y)), np.ceil(np.max(z)) ] #outfile.header.offset=outfile.header.min outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close () def openpcl ( res ): #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d . geometry . PointCloud () pcl . points = o3d . utility . Vector3dVector ( res [[ \"x\" , \"y\" , \"z\" ]] . values ) pcl . colors = o3d . utility . Vector3dVector ( res [[ \"r\" , \"g\" , \"b\" ]] . values ) o3d . visualization . draw_geometries ([ pcl ]) def usage (): helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext ) if __name__ == \"__main__\" : #DEFAULTS datacloud = None basecloud = None group = 1 distance = 5 degree = 0 colors = [ 'violet' , 'blue' , 'cyan' , 'green' , 'yellow' , 'orange' , 'red' ] outfile = None output = 'las' vmin =- 500 vmax = 500 try : opts , args = getopt . getopt ( sys . argv [ 1 :], \"b:g:d:D:c:o:O:v:V:\" , [ \"basecloud=\" , \"group=\" , \"distance=\" , \"degree=\" , \"colors=\" , \"outfile=\" , \"output=\" , \"vmin=\" , \"vmax=\" ]) for o , a in opts : if o in ( \"-b\" , \"--basecloud\" ): basecloud = a elif o in ( \"-g\" , \"--group\" ): group = a elif o in ( \"-d\" , \"--distance\" ): distance = a elif o in ( \"-D\" , \"--degree\" ): degree = a elif o in ( \"-c\" , \"--colors\" ): colors = a . split ( \",\" ) elif o in ( \"-o\" , \"--outfile\" ): outfile = a elif o in ( \"-O\" , \"--output\" ): output = a elif o in ( \"-v\" , \"--vmin\" ): vmin = a elif o in ( \"-V\" , \"--vmax\" ): vmax = a else : assert False , \"unhandled option\" try : infile = args [ 0 ] except Exception : raise Exception ( f \"No file\" ) datacloud = pd . read_csv ( infile ) datacloud = datacloud [ datacloud . columns [ 0 : 4 ]] datacloud . columns = [ \"X\" , \"Y\" , \"Z\" , \"V\" ] if basecloud is not None : basecloud = pd . read_csv ( basecloud ) basecloud = basecloud [ basecloud . columns [ 0 : 3 ]] basecloud . columns = [ \"X\" , \"Y\" , \"Z\" ] result = paint ( valcld = datacloud , basecld = basecloud , distance = distance , degree = degree , group = group , cmap = colors , vmin = vmin , vmax = vmax ) print ( output ) if outfile is None : outfile = '.' . join ([ infile , output ]) if output == 'las' : makelaz ( result [[ \"x\" , \"y\" , \"z\" , \"r\" , \"g\" , \"b\" ]], outfile ) elif output == 'csv' : result . to_csv ( outfile , index = False ) elif output == 'view' : openpcl ( result ) else : raise Exception ( f 'unkwnown output type: { output } ' ) except Exception as err : # print help information and exit: print ( err ) usage () sys . exit ( 2 )","title":"Module hielen2.ext.source_tinsar.cloudpainter"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#functions","text":"","title":"Functions"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#colorize","text":"def colorize ( vals , cmap = [ 'red' , 'green' , 'blue' ], vmin = None , vmax = None ) Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def colorize ( vals , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None ): \"\"\" Maps each value in the input array with the appropriate RGBA color. See matplotlib.colors.Colormap returns: ndarray with shape (n,4) containing the color tuples ['r','g','b','a'] color channels values are normalized in range (0,1) params: vals - array of values. cmap - See matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" print ( \"CHECK: Enter Colorize\" ) vmin = vmin or vals . min () vmax = vmax or vals . max () norm = Normalize ( vmin = vmin , vmax = vmax , clip = True ) if not isinstance ( cmap , Colormap ): cmap = LinearSegmentedColormap . from_list ( \"mycmap\" , cmap ) mapper = ScalarMappable ( norm = norm , cmap = cmap ) cols = mapper . to_rgba ( vals ) return cols","title":"colorize"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#makelaz","text":"def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ) View Source def makelaz ( frame , filetowrite , coordmult = 1 , colormult = 1 , scale = [ 1 , 1 , 1 ], framevalues = None ): hdr = laspy . header . Header ( point_format = 2 ) frame . columns = [ 'x' , 'y' , 'z' , 'r' , 'g' , 'b' ] outfile = laspy . file . File ( filetowrite , mode = 'w' , header = hdr ) x = frame [ 'x' ] * coordmult y = frame [ 'y' ] * coordmult z = frame [ 'z' ] * coordmult r = frame [ 'r' ] * colormult g = frame [ 'g' ] * colormult b = frame [ 'b' ] * colormult # outfile . header . min = [ np . floor ( np . min ( x )), np . floor ( np . min ( y )), np . floor ( np . min ( z )) ] # outfile . header . max = [ np . ceil ( np . max ( x )), np . ceil ( np . max ( y )), np . ceil ( np . max ( z )) ] # outfile . header . offset = outfile . header . min outfile . header . scale = scale outfile . x = x . values outfile . y = y . values outfile . z = z . values outfile . Red = r . values outfile . Green = g . values outfile . Blue = b . values outfile . header . offset = outfile . header . min outfile . close ()","title":"makelaz"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#openpcl","text":"def openpcl ( res ) View Source def openpcl ( res ) : #QUI USO open3d perch\u00e8 \u00e8 molto comodo pcl = o3d . geometry . PointCloud () pcl . points = o3d . utility . Vector3dVector ( res [ [\"x\", \"y\", \"z\" ] ] . values ) pcl . colors = o3d . utility . Vector3dVector ( res [ [\"r\", \"g\", \"b\" ] ] . values ) o3d . visualization . draw_geometries ( [ pcl ] )","title":"openpcl"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#paint","text":"def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ 'red' , 'green' , 'blue' ], vmin = None , vmax = None ) Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped View Source def paint ( valcld , basecld = None , distance = 10 , group = 1 , degree = 0 , cmap = [ \"red\" , \"green\" , \"blue\" ], vmin = None , vmax = None , ): \"\"\" Assigns a color to each point of a base cloud, merging the information of a second valorized cloud overlapping the first one. See cloudpainter.valorize and cloudpainter.colorize for futher informations result: pandas.DataFrame containing ['x','y','z','v','r','g','b'] tuples for each point in the base cloud. Points with no neighbours will be assigned with [0.9,0.9,0.9] for ['r','g','b'] and np.nan for ['v'] params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. cmap - matplotlib.colors.Colormap object or colour list. default ['red','green','blue']. vmax - max limit value for colormap. If None is passed, vals.max(). will be assumed, otherwise vals exceding this parameter will be clipped vmin - min limit value for colormap. If None is passed, vals.min() will be assumed, otherwise vals under this parameter will be clipped \"\"\" valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] values = None if basecld is not None : basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] values = valorize ( basecld , valcld , distance = distance , group = group , degree = degree ) values . name = \"v\" else : values = valcld [ \"v\" ] colors = pd . DataFrame ( colorize ( values , cmap = cmap , vmin = vmin , vmax = vmax ), columns = [ \"r\" , \"g\" , \"b\" , \"a\" ], index = values . index , )[[ \"r\" , \"g\" , \"b\" ]] if basecld is not None : result = basecld . join ( colors , how = \"left\" ). replace ( np . nan , 0 . 9 ) result = result . join ( values , how = \"left\" ) else : result = valcld . join ( colors , how = \"left\" ) return result [[ \"x\" , \"y\" , \"z\" , \"v\" , \"r\" , \"g\" , \"b\" ]]","title":"paint"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#usage","text":"def usage ( ) View Source def usage () : helptext = r \"\"\"usage: cloudainter.py [option] path/to/radar/result.csv parmeters: path/to/radar/result.csv : path for csv based radar cloud in the format X,Y,Z,V,... options: -b path --basecloud=path : path for csv based reference cloud in the format X,Y,Z,... -g number --group=number : max number of neighbours to interpolate -d number --distance=number : nearest neighbour max radius -D number --degree=number : neighbour contribute attenuation degree along distance -c csv --colors=csv : colormap as comma separated colors names -o path --outfile=path : output file name. Ignored when --output=view -O type --output=type : output types: [laz|csv|view]. Default laz -v number --vmin=number : min value for the colormap range -V number --vmax=numner : max value for the colormap range\"\"\" print ( helptext )","title":"usage"},{"location":"reference/hielen2/ext/source_tinsar/cloudpainter/#valorize","text":"def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ) Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1 / d ** degree where d is the distance between the neighbour and the base cloud point . Degree 0 implies the arithmetic mean of all the neighbour values found , regardless the relative distance . i . e : N1 ----------P----N2 Given two neighbours , N1 and N2 , for a fixed point P where : d ( N1 ) = 10 ; v ( N1 ) =- 15 d ( N2 ) = 4 ; v ( N2 ) = 3 v ( P ) = ( - 15 / 10 ** d + 3 / 4 ** d ) / ( 1 / 10 ** d + 1 / 4 ** d ) being d the degree , we have : d = 0 : v ( P ) = - 6 < -- arimetic mean d = 1 : v ( P ) = - 2 . 14 d = 2 : v ( P ) = 0 . 51 d = 3 : v ( P ) = 1 . 91 d = 4 : v ( P ) = 2 . 55 d = 5 : v ( P ) = 2 . 81 .. d = 9 : v ( P ) = 2 . 99 .. d ( x ): v ( P ) = 3 < -- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. View Source def valorize ( basecld , valcld , distance = 10 , group = 1 , degree = 0 ): \"\"\" Assigns values to input base cloud points, overlapping the input values cloud and calculating, for each point in base cloud, the [distance based, weighted] mean of the values of N nearest neighbours, taken from the input values cloud. returns: pandas.Series containing calculated values for all the points in the base cloud which has at least one neighbour within the fixed distance params: basecld - pandas.DataFrame or numpy.ndarray with shape (n,3), representing the coordinates of the points of the base cloud. ['x','y','z'] valcld - pandas.DataFrame or numpy.ndarray with shape (n,4), representing the coordinates of the points of the value cloud and the value of each of them. ['x','y','z','v'] distance - maximum search range for neighbours group - maximum number of neighbours to search for degree - degree of contribution loss over the distance for each neighbour value. Each value of the neighbours is weighted as: 1/d**degree where d is the distance between the neighbour and the base cloud point. Degree 0 implies the arithmetic mean of all the neighbour values found, regardless the relative distance. i.e: N1----------P----N2 Given two neighbours, N1 and N2, for a fixed point P where: d(N1)=10; v(N1)=-15 d(N2)=4; v(N2)=3 v(P) = (-15/10**d+3/4**d)/(1/10**d+1/4**d) being d the degree, we have: d=0 : v(P) = -6 <-- arimetic mean d=1 : v(P) = -2.14 d=2 : v(P) = 0.51 d=3 : v(P) = 1.91 d=4 : v(P) = 2.55 d=5 : v(P) = 2.81 .. d=9 : v(P) = 2.99 .. d(x): v(P) = 3 <-- convergence to the closest's value Note: with group=1 and degree=0, each base cloud point assumes the exact value of the unique closest neighbour, if it exists. \"\"\" print ( \"CHECK: Enter Valorize\" ) basecld = pd . DataFrame ( basecld ) basecld . columns = [ \"x\" , \"y\" , \"z\" ] valcld = pd . DataFrame ( valcld ) valcld . columns = [ \"x\" , \"y\" , \"z\" , \"v\" ] ## Calculating the Series of distance ( dist ) and value clouds relative ## ids ( idsv ). the position of each cell in the arrays reflects the cells ## in the base cloud . k = KDTree ( valcld [[ \"x\" , \"y\" , \"z\" ]]. values ) dist , idsv = k . query ( basecld . values , group , distance_upper_bound = distance ) dist = pd . DataFrame ( dist ). stack () dist . name = \"dist\" idsv = pd . DataFrame ( idsv ). stack () idsv . name = \"idsv\" print ( \"CHECK: Distance calculation done\" ) ## Here we construct the DataFrame contains relation beetween each point ## in base cloud ( base cloud index ) and his neighbous ( value cloud ids , ## distance and neighbour group progressive ). Then we clean the infinite ## distances ( points with no neighbours ) values = dist . to_frame (). join ( idsv ) values = values [ values [ \"dist\" ] != np . inf ] # Indexind on 'idsv' , allows to join with the value cloud and add the 'v' # info values = values . reset_index (). set_index ( \"idsv\" ). sort_index () values = values . join ( valcld [ \"v\" ], how = \"left\" ) values . columns = [ \"cldid\" , \"instance\" , \"dist\" , \"displ\" ] ## Indexing on 'cldid' and 'instance' , allow to make DataFrame comparable ## with base cloud values = values . set_index ([ \"cldid\" , \"instance\" ]). sort_index () ## Here we calculte the [ distance based , weighted ] mean values [ \"weight\" ] = 1 / np . power ( values [ \"dist\" ], degree ) values [ \"contrib\" ] = values [ \"displ\" ] * values [ \"weight\" ] values = values . groupby ( \"cldid\" ). apply ( lambda x : sum ( x [ \"contrib\" ]) / sum ( x [ \"weight\" ]) ) print ( \"CHECK: Weight calculation done\" ) return values","title":"valorize"}]}